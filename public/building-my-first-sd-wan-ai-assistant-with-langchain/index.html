<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Building my first SD-WAN AI Assistant with LangChain | NetWithAlex</title>
<meta name="keywords" content="">
<meta name="description" content="Introduction
It has been a while since I wanted to hop on to the LLM train and learn how to use one of the popular frameworks. A few months back, I saw a great Cisco Live presentation by my good friend Jesus, and it gave me the determination I needed to finally dive deeper into the topic.
Since then, I have been doing research and thinking about a nice use case for me to put as objective of my learning process. After considering different options, I decided to build an SD-WAN AI assistant that could help me troubleshoot an SD-WAN issue. Taking advantage of the available tools, I decided that my assistant would be an expert on the Net work Wide Path Insights functionality.">
<meta name="author" content="alex">
<link rel="canonical" href="https://netwithalex.netlify.app/building-my-first-sd-wan-ai-assistant-with-langchain/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk&#43;4bvpN&#43;sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://netwithalex.netlify.app/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://netwithalex.netlify.app/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://netwithalex.netlify.app/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://netwithalex.netlify.app/apple-touch-icon.png">
<link rel="mask-icon" href="https://netwithalex.netlify.app/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://netwithalex.netlify.app/building-my-first-sd-wan-ai-assistant-with-langchain/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://netwithalex.netlify.app/building-my-first-sd-wan-ai-assistant-with-langchain/">
  <meta property="og:site_name" content="NetWithAlex">
  <meta property="og:title" content="Building my first SD-WAN AI Assistant with LangChain">
  <meta property="og:description" content="Introduction It has been a while since I wanted to hop on to the LLM train and learn how to use one of the popular frameworks. A few months back, I saw a great Cisco Live presentation by my good friend Jesus, and it gave me the determination I needed to finally dive deeper into the topic.
Since then, I have been doing research and thinking about a nice use case for me to put as objective of my learning process. After considering different options, I decided to build an SD-WAN AI assistant that could help me troubleshoot an SD-WAN issue. Taking advantage of the available tools, I decided that my assistant would be an expert on the Net work Wide Path Insights functionality.">
  <meta property="og:locale" content="en-US">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-10T18:51:08+00:00">
    <meta property="article:modified_time" content="2024-07-10T18:51:08+00:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Building my first SD-WAN AI Assistant with LangChain">
<meta name="twitter:description" content="Introduction
It has been a while since I wanted to hop on to the LLM train and learn how to use one of the popular frameworks. A few months back, I saw a great Cisco Live presentation by my good friend Jesus, and it gave me the determination I needed to finally dive deeper into the topic.
Since then, I have been doing research and thinking about a nice use case for me to put as objective of my learning process. After considering different options, I decided to build an SD-WAN AI assistant that could help me troubleshoot an SD-WAN issue. Taking advantage of the available tools, I decided that my assistant would be an expert on the Net work Wide Path Insights functionality.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://netwithalex.netlify.app/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Building my first SD-WAN AI Assistant with LangChain",
      "item": "https://netwithalex.netlify.app/building-my-first-sd-wan-ai-assistant-with-langchain/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Building my first SD-WAN AI Assistant with LangChain",
  "name": "Building my first SD-WAN AI Assistant with LangChain",
  "description": "Introduction It has been a while since I wanted to hop on to the LLM train and learn how to use one of the popular frameworks. A few months back, I saw a great Cisco Live presentation by my good friend Jesus, and it gave me the determination I needed to finally dive deeper into the topic.\nSince then, I have been doing research and thinking about a nice use case for me to put as objective of my learning process. After considering different options, I decided to build an SD-WAN AI assistant that could help me troubleshoot an SD-WAN issue. Taking advantage of the available tools, I decided that my assistant would be an expert on the Net work Wide Path Insights functionality.\n",
  "keywords": [
    
  ],
  "articleBody": "Introduction It has been a while since I wanted to hop on to the LLM train and learn how to use one of the popular frameworks. A few months back, I saw a great Cisco Live presentation by my good friend Jesus, and it gave me the determination I needed to finally dive deeper into the topic.\nSince then, I have been doing research and thinking about a nice use case for me to put as objective of my learning process. After considering different options, I decided to build an SD-WAN AI assistant that could help me troubleshoot an SD-WAN issue. Taking advantage of the available tools, I decided that my assistant would be an expert on the Net work Wide Path Insights functionality.\nIn this post, I want to share a bit of my experience building it and of course show some of the results. For a better understanding I suggest to have the G ithub repo opened as you go through the post.\nAbout the setup My SD-WAN Lab is running 20.12.3 on the Manager and the Wan Edges are using 17.9.4a. I have a very simple topology that looks something like this:\nThe programming language used is Python and the framework I chose to interact with the LLM is LangChain. I used OpenAI model gpt-4o and a Webex bot for the interaction. The repo can be found here.\nMy objective For the sake of context, troubleshooting inside a SD-WAN fabric is not easy because traffic is encrypted, policies dictate how traffic will flow, there could be multiple paths to a destination, next hops can be changed with policies, there are multiple hops involved, and more. Figuring out all this information is time consuming and not a straightforward process.\nNWPI Trace is a tool that greatly improves the troubleshooting process as it will give hop-by-hop information and visibility. It can be easily started from the Manager‚Äôs UI, it will detect flows based on specified filters and you can browse around to get all the visibility you need. It is a very complex and complete tool. As I described before, I wanted to use this project as a playground to learn and since I didn‚Äôt have prior experience with LLMs or LangChain I set a simple objective:\nBuild an assistant that can start a NWPI trace and give me details of the flows.\nPlanning and Building Ok, I had my objective, but how to start?\nI took a hands-on approach which meant that I didn‚Äôt learn LangChain from scratch and instead took the Cisco Live session repo as a base and built on top of that. The reasons to choose this repo were simple:\nIt was explained on the sessions so I had a general idea of the technologies and its purpose. I thought it would be easy to adjust to my use case (Eg. I also use Webex, I will be interacting with network devices, I saw how the tools could be replaced with my own) I had to do some cleaning before starting, this required me to understand what was essential to host the LLM and interact with it. Luckily, the repo had an organized structure that made it easy to understand.\nFrom the session, I learned about LangChain Tools, so I knew I could create functions that my agent could use to perform different actions. In this case, actions would be something like starting those traces and getting info from them\nChallenge 1 I needed to get familiar with the NWPI API, at this point I knew I had seen somewhere on the API documentation that some operations were available, but never had taken the time to analyze them. To my surprise, the specific actions of starting a trace and getting details of it, were not included‚Ä¶ There was information about starting a ‚Äútask‚Äù a.k.a ‚ÄúAuto-on Task‚Äù, which is not the same as the ‚ÄúTrace‚Äù I had in mind. At this point, I needed to decide if I would go for the ‚Äúofficial‚Äù and maybe easier way or exploring an alternative to achieve exactly what I wanted.\nKnowing that almost everything is API driven, I used the inspect tab of my browser and started exploring the APIs triggered when I started a trace through the UI. After a first quick pass, I determined it was doable and started gathering the information I needed.\nChallenge 2 I already knew I would have to do some analysis to make my idea a reality, but I underestimated how much I would need to do. In fact, the difficulty of this task kept me away from the project for some time as it became increasingly complex.\nIn my mind there were only 3 ‚Äúsimple‚Äù tasks:\nFind the API to start the trace Find the API to confirm the trace is running Find the API to give me details of the flows Find the API to start the trace Starting a trace from the UI is very simple, you just need a Site ID and a VPN ID. However, there are underlying verifications happening that we take for granted.\nThe site ID is really needed to identify the devices to start the trace on. There are a bunch of options (QoS insights, ART visibility, APP visibility, DIA, etc) that are version dependent. The VPN needs to exist. To get this done I created the function get_device_details_from_site so I could find related information of the devices to start the trace. I needed:\nversions serial numbers names reachability status. Then, I created the start_trace function that would receive the information previously obtained and other filters. I kept the filters as simple as possible, leaving only an option to specify a source and destination subnet. There are a lot of trace options for which I didn‚Äôt do any type of version verification before running it, I just did it for the QoS insights that requires version 17.9 or later. This function returns some information needed later to verify the status.\nFind the API to confirm the trace is running This was probably the easiest task. I created the verify_trace_state function and with the help of the LLM it can be ran some seconds after starting the trace. It returns the state, which is also needed to get information later on.\nFind the API to give me details of the flows This was the most complex and time consuming task. In my mind checking the result of a trace is very simple, however when we receive the information in chunks, through different calls it starts getting tricky.\nI tried to replicate the process I go through on the UI:\nView the insights of the trace and check the flows that were captured (if any) For the list of flows, look for the one that had the ‚Äúreadout‚Äù button in red (problem detected) and click to get more details. Expand the flow view to get access to the advanced functionalities so I can determine the features that the packet is going through on each of the hops. To get the flows captured for the trace I created the function get_flow_summary. This function will return the list of captured flows, You will see details like src/dst, application and protocol. This is useful to identify the flow id that you are interested in getting more details.\nI created the trace_readout function to get a summary of the events that the trace captured along with the affected path. For example, you could see that an SSH flow is not working between Device X and Device Y.\nOk, once you have identified the flow and events you are interested in, you can get detailed information of the flow with the function get_flow_detail. This will give you hop by hop information like:\nHop Event Local/Remote colors Ingress/Egress interfaces Ingress/Egress features applied to packets Feature making the forward decision With this information is possible to see all sort of things, like ACLs, type of policies applied, why a packet was routed through a specific color, drops, confirm your policy is working as expected, etc.\nOk, I think that‚Äôs it!\nDemo I started by creating an ACL to block communication and applied it on the DC side.\nMunich_DC100-1 - ACL configuration sdwan interface GigabitEthernet2 access-list ACL_Drop_172_16_10_0 out policy access-list ACL_Drop_172_16_10_0 sequence 1 match source-ip 172.16.10.0/24 destination-ip 172.16.100.0/24 ! action drop count dropCounter ! ! default-action accept ! Will my assistant detect this? ü§î\nNext, I start the application and request the LLM to start a trace. I can confirm on the UI that it is created.\nI start a couple of SSH connections from branch to DC\nThen, I ask the assistant if flows have been captured, it responds with this\nWe can see flows were captured and also it gave me more information of the events detected and the path with device names. The first event seem to be related to our issue. So far the information looks accurate, let‚Äôs get more details.\nWith this, we can see that the client sent multiple ssh attempts, we can dig further into one of the flows. Let‚Äôs see what else it gives.\nFinally, the assistant provides detailed information about the features that each of the hops apply to the traffic. On the second hop in Munich DC we can see that egress features show the SD-WAN ACL and a Drop Report. The assistant provides its own conclusion and it is also suspecting that Munich router is dropping the traffic. With a little bit more work, the agent could be able to tell the name of the ACL and sequence number that is dropping the traffic. We have successfully identified the root of the issue!! üòÄ üéâ\nLessons learned When I started, I wanted to be super cautious with the credits ($$) so I was using gpt-3.5-turbo-16k that is cheaper but also less intelligent. At some point, I faced issues with the LLM getting into a loop of problems, I decided to test out gpt-4o and felt a difference on the way the agent was reasoning. Initially, I was using an LLM temperature = 0, this was ok, but the responses were lacking variety and details, I needed to make it more chatty. Tweaking the temperature = 0.9 gave me a good balance between chattiness and correctness (although sometimes the agent still gives information that is questionable based on the outputs) Troubleshooting problems could be difficult at times, mostly I relied on printing outputs while the functions were executed and the agent outputs on the terminal. It let me understand what tools the agent was using and the order. Also, I could see what the tools were returning. Here is an example: The text in green indicate the tools the agent is accessing. The yellow text is the information returned by a function. In this case, we can see that the agent called \"get_entry_time_and_state\" function so it can get information needed to call the next function \"get_flow_detail\"\nThere are better tools available to help with troubleshooting like LangSmith Tr acing, I will explore it for future use.\nThe system prompt of my agent had to be refined several times, I often found that I needed to provide more details to handle certain situations correctly, especially when the output of a function was needed to call another one or to handle unexpected situations. I think it can still be improved, in fact I want to write a totally different prompt to try and make the agent run all of the tools by itself and just return a conclusion after analyzing all the outputs. Conclusion All in all, it was a good (and long) exercise to learn and build my first assistant. I feel happy with the result as I was able to get to me objective. At the same time, I recognize there are a lot of things that could be improved to make the results more reliable and meaningful. Also, there is much more information that NWPI can show, so the tools can definitely be extended.\nAs a next step, I am planning to learn LangChain properly and understand how can I implement multiple agents to enhance the functionality and reliability of my assistant.\nI hope this post will help you in the same way that Cisco Live presentation helped me!\n",
  "wordCount" : "2046",
  "inLanguage": "en",
  "datePublished": "2024-07-10T18:51:08Z",
  "dateModified": "2024-07-10T18:51:08Z",
  "author":{
    "@type": "Person",
    "name": "alex"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://netwithalex.netlify.app/building-my-first-sd-wan-ai-assistant-with-langchain/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "NetWithAlex",
    "logo": {
      "@type": "ImageObject",
      "url": "https://netwithalex.netlify.app/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://netwithalex.netlify.app/" accesskey="h" title="NetWithAlex (Alt + H)">NetWithAlex</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://netwithalex.blog" title="Home">
                    <span>Home</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
            <li>
                <a href="https://netwithalex.netlify.app/posts/" title="Blogs">
                    <span>Blogs</span>
                </a>
            </li>
            <li>
                <a href="https://netwithalex.netlify.app/about/" title="About me.">
                    <span>About me.</span>
                </a>
            </li>
            <li>
                <a href="https://netwithalex.netlify.app/search/" title="üîç">
                    <span>üîç</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://netwithalex.netlify.app/">Home</a>&nbsp;¬ª&nbsp;<a href="https://netwithalex.netlify.app/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Building my first SD-WAN AI Assistant with LangChain
    </h1>
    <div class="post-meta"><span title='2024-07-10 18:51:08 +0000 +0000'>July 10, 2024</span>&nbsp;¬∑&nbsp;10 min&nbsp;¬∑&nbsp;alex

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#about-the-setup" aria-label="About the setup">About the setup</a></li>
                <li>
                    <a href="#my-objective" aria-label="My objective">My objective</a></li>
                <li>
                    <a href="#planning-and-building" aria-label="Planning and Building">Planning and Building</a><ul>
                        
                <li>
                    <a href="#challenge-1" aria-label="Challenge 1">Challenge 1</a></li>
                <li>
                    <a href="#challenge-2" aria-label="Challenge 2">Challenge 2</a><ul>
                        
                <li>
                    <a href="#find-the-api-to-start-the-trace" aria-label="Find the API to start the trace">Find the API to start the trace</a></li>
                <li>
                    <a href="#find-the-api-to-confirm-the-trace-is-running" aria-label="Find the API to confirm the trace is running">Find the API to confirm the trace is running</a></li>
                <li>
                    <a href="#find-the-api-to-give-me-details-of-the-flows" aria-label="Find the API to give me details of the flows">Find the API to give me details of the flows</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#demo" aria-label="Demo">Demo</a></li>
                <li>
                    <a href="#lessons-learned" aria-label="Lessons learned">Lessons learned</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>It has been a while since I wanted to hop on to the LLM train and learn how to use one of the popular frameworks. A few months back, I saw a great <a href="https://www.ciscolive.com/on-demand/on-demand-library.html?search=jesus&amp;search=jesus#/session/1707505627331001pilj">Cisco Live presentation</a> by my good friend Jesus, and it gave me the determination I needed to finally dive deeper into the topic.</p>
<p>Since then, I have been doing research and thinking about a nice use case for me to put as objective of my learning process. After considering different options, I decided to build an SD-WAN AI assistant that could help me troubleshoot an SD-WAN issue. Taking advantage of the available tools, I decided that my assistant would be an expert on the <a href="/network-wide-path-insights-an-introduction/">Net</a> <a href="/network-wide-path-insights-an-introduction/">work Wide Path Insights</a> functionality.</p>
<p>In this post, I want to share a bit of my experience building it and of course show some of the results. For a better understanding I suggest to have the <a href="https://github.com/aruiz-p/sdwan-assistant">G</a> <a href="https://github.com/aruiz-p/sdwan-assistant">ithub repo</a> opened as you go through the post.</p>
<h2 id="about-the-setup">About the setup<a hidden class="anchor" aria-hidden="true" href="#about-the-setup">#</a></h2>
<p>My SD-WAN Lab is running 20.12.3 on the Manager and the Wan Edges are using 17.9.4a. I have a very simple topology that looks something like this:</p>
<p><img loading="lazy" src="/wp-content/uploads/2024/07/Topology-2.png"></p>
<p>The programming language used is Python and the framework I chose to interact with the LLM is LangChain. I used OpenAI model gpt-4o and a Webex bot for the interaction. The repo can be found <a href="https://github.com/aruiz-p/sdwan-assistant">here</a>.</p>
<h2 id="my-objective">My objective<a hidden class="anchor" aria-hidden="true" href="#my-objective">#</a></h2>
<p>For the sake of context, troubleshooting inside a SD-WAN fabric is not easy because traffic is encrypted, policies dictate how traffic will flow, there could be multiple paths to a destination, next hops can be changed with policies, there are multiple hops involved, and more. Figuring out all this information is time consuming and not a straightforward process.</p>
<p><a href="/network-wide-path-insights-an-introduction/">NWPI</a> Trace is a tool that greatly improves the troubleshooting process as it will give hop-by-hop information and visibility. It can be easily started from the Manager&rsquo;s UI, it will detect flows based on specified filters and you can browse around to get all the visibility you need. It is a very complex and complete tool. As I described before, I wanted to use this project as a playground to learn and since I didn&rsquo;t have prior experience with LLMs or LangChain I set a simple objective:</p>
<p><em><strong>Build an assistant that can start a NWPI trace and give me details of the flows.</strong></em></p>
<h2 id="planning-and-building">Planning and Building<a hidden class="anchor" aria-hidden="true" href="#planning-and-building">#</a></h2>
<p>Ok, I had my objective, but how to start?</p>
<p>I took a hands-on approach which meant that I didn&rsquo;t learn LangChain from scratch and instead took the <a href="https://github.com/jillesca/CLEUR-DEVNET-3707">Cisco Live session repo</a> as a base and built on top of that. The reasons to choose this repo were simple:</p>
<ol>
<li>It was explained on the sessions so I had a general idea of the technologies and its purpose.</li>
<li>I thought it would be easy to adjust to my use case (Eg. I also use Webex, I will be interacting with network devices, I saw how the tools could be replaced with my own)</li>
</ol>
<p>I had to do some cleaning before starting, this required me to understand what was essential to host the LLM and interact with it. Luckily, the repo had an organized structure that made it easy to understand.</p>
<p>From the session, I learned about <a href="https://python.langchain.com/v0.1/docs/modules/tools/">LangChain Tools</a>, so I knew I could create functions that my agent could use to perform different actions. In this case, actions would be something like starting those traces and getting info from them</p>
<h3 id="challenge-1">Challenge 1<a hidden class="anchor" aria-hidden="true" href="#challenge-1">#</a></h3>
<p>I needed to get familiar with the NWPI API, at this point I knew I had seen somewhere on the API documentation that some operations were available, but never had taken the time to analyze them. To my surprise, the specific actions of starting a trace and getting details of it, were not included&hellip; There was information about starting a &ldquo;task&rdquo; a.k.a &ldquo;Auto-on Task&rdquo;, which is not the same as the &ldquo;Trace&rdquo; I had in mind. At this point, I needed to decide if I would go for the &ldquo;official&rdquo; and maybe easier way or exploring an alternative to achieve exactly what I wanted.</p>
<p>Knowing that almost everything is API driven, I used the inspect tab of my browser and started exploring the APIs triggered when I started a trace through the UI. After a first quick pass, I determined it was doable and started gathering the information I needed.</p>
<h3 id="challenge-2">Challenge 2<a hidden class="anchor" aria-hidden="true" href="#challenge-2">#</a></h3>
<p>I already knew I would have to do some analysis to make my idea a reality, but I underestimated how much I would need to do. In fact, the difficulty of this task kept me away from the project for some time as it became increasingly complex.</p>
<p>In my mind there were only 3 &ldquo;simple&rdquo; tasks:</p>
<ol>
<li>Find the API to start the trace</li>
<li>Find the API to confirm the trace is running</li>
<li>Find the API to give me details of the flows</li>
</ol>
<h4 id="find-the-api-to-start-the-trace">Find the API to start the trace<a hidden class="anchor" aria-hidden="true" href="#find-the-api-to-start-the-trace">#</a></h4>
<p>Starting a trace from the UI is very simple, you just need a Site ID and a VPN ID. However, there are underlying verifications happening that we take for granted.</p>
<ol>
<li>The site ID is really needed to identify the devices to start the trace on.</li>
<li>There are a bunch of options (QoS insights, ART visibility, APP visibility, DIA, etc) that are version dependent.</li>
<li>The VPN needs to exist.</li>
</ol>
<p>To get this done I created the function <code>get_device_details_from_site</code> so I could find related information of the devices to start the trace. I needed:</p>
<ul>
<li>versions</li>
<li>serial numbers</li>
<li>names</li>
<li>reachability status.</li>
</ul>
<p>Then, I created the <code>start_trace</code> function that would receive the information previously obtained and other filters. I kept the filters as simple as possible, leaving only an option to specify a source and destination subnet. There are a lot of trace options for which I didn&rsquo;t do any type of version verification before running it, I just did it for the QoS insights that requires version 17.9 or later. This function returns some information needed later to verify the status.</p>
<h4 id="find-the-api-to-confirm-the-trace-is-running">Find the API to confirm the trace is running<a hidden class="anchor" aria-hidden="true" href="#find-the-api-to-confirm-the-trace-is-running">#</a></h4>
<p>This was probably the easiest task. I created the <code>verify_trace_state</code> function and with the help of the LLM it can be ran some seconds after starting the trace. It returns the state, which is also needed to get information later on.</p>
<h4 id="find-the-api-to-give-me-details-of-the-flows">Find the API to give me details of the flows<a hidden class="anchor" aria-hidden="true" href="#find-the-api-to-give-me-details-of-the-flows">#</a></h4>
<p>This was the most complex and time consuming task. In my mind checking the result of a trace is very simple, however when we receive the information in chunks, through different calls it starts getting tricky.</p>
<p>I tried to replicate the process I go through on the UI:</p>
<ol>
<li>View the insights of the trace and check the flows that were captured (if any)</li>
<li>For the list of flows, look for the one that had the &ldquo;readout&rdquo; button in red (problem detected) and click to get more details.</li>
<li>Expand the flow view to get access to the advanced functionalities so I can determine the features that the packet is going through on each of the hops.</li>
</ol>
<p>To get the flows captured for the trace I created the function <code>get_flow_summary</code>. This function will return the list of captured flows, You will see details like src/dst, application and protocol. This is useful to identify the flow id that you are interested in getting more details.</p>
<p>I created the <code>trace_readout</code> function to get a summary of the events that the trace captured along with the affected path. For example, you could see that an SSH flow is not working between Device X and Device Y.</p>
<p>Ok, once you have identified the flow and events you are interested in, you can get detailed information of the flow with the function <code>get_flow_detail</code>. This will give you hop by hop information like:</p>
<ul>
<li>Hop</li>
<li>Event</li>
<li>Local/Remote colors</li>
<li>Ingress/Egress interfaces</li>
<li>Ingress/Egress features applied to packets</li>
<li>Feature making the forward decision</li>
</ul>
<p>With this information is possible to see all sort of things, like ACLs, type of policies applied, why a packet was routed through a specific color, drops, confirm your policy is working as expected, etc.</p>
<p>Ok, I think that&rsquo;s it!</p>
<h2 id="demo">Demo<a hidden class="anchor" aria-hidden="true" href="#demo">#</a></h2>
<p>I started by creating an ACL to block communication and applied it on the DC side.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>Munich_DC100-1 - ACL configuration
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sdwan
</span></span><span style="display:flex;"><span> interface GigabitEthernet2
</span></span><span style="display:flex;"><span>  access-list ACL_Drop_172_16_10_0 out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>policy
</span></span><span style="display:flex;"><span> access-list ACL_Drop_172_16_10_0
</span></span><span style="display:flex;"><span>  sequence 1
</span></span><span style="display:flex;"><span>   match
</span></span><span style="display:flex;"><span>    source-ip      172.16.10.0/24
</span></span><span style="display:flex;"><span>    destination-ip 172.16.100.0/24
</span></span><span style="display:flex;"><span>   !
</span></span><span style="display:flex;"><span>   action drop
</span></span><span style="display:flex;"><span>    count dropCounter
</span></span><span style="display:flex;"><span>   !
</span></span><span style="display:flex;"><span>  !
</span></span><span style="display:flex;"><span>  default-action accept
</span></span><span style="display:flex;"><span> !
</span></span></code></pre></div><p>Will my assistant detect this? ü§î</p>
<p>Next, I start the application and request the LLM to start a trace. I can confirm on the UI that it is created.</p>
<p><img loading="lazy" src="/wp-content/uploads/2024/07/StartTrace.png"><img loading="lazy" src="/wp-content/uploads/2024/07/UI-Trace.png"></p>
<p>I start a couple of SSH connections from branch to DC</p>
<p><img loading="lazy" src="/wp-content/uploads/2024/07/SSHs.png"></p>
<p>Then, I ask the assistant if flows have been captured, it responds with this</p>
<p><img loading="lazy" src="/wp-content/uploads/2024/07/Events.png"></p>
<p>We can see flows were captured and also it gave me more information of the events detected and the path with device names. The first event seem to be related to our issue. So far the information looks accurate, let&rsquo;s get more details.</p>
<p><img loading="lazy" src="/wp-content/uploads/2024/07/assistant-2-866x1024.png"></p>
<p>With this, we can see that the client sent multiple ssh attempts, we can dig further into one of the flows. Let&rsquo;s see what else it gives.</p>
<p><img loading="lazy" src="/wp-content/uploads/2024/07/details.png"></p>
<p>Finally, the assistant provides detailed information about the features that each of the hops apply to the traffic. On the second hop in Munich DC we can see that <code>egress features</code> show the <code>SD-WAN ACL</code> and a <code>Drop Report</code>. The assistant provides its own conclusion and it is also suspecting that Munich router is dropping the traffic. With a little bit more work, the agent could be able to tell the name of the ACL and sequence number that is dropping the traffic. We have successfully identified the root of the issue!! üòÄ üéâ</p>
<h2 id="lessons-learned">Lessons learned<a hidden class="anchor" aria-hidden="true" href="#lessons-learned">#</a></h2>
<ul>
<li>When I started, I wanted to be super cautious with the credits ($$) so I was using gpt-3.5-turbo-16k that is cheaper but also less intelligent. At some point, I faced issues with the LLM getting into a loop of problems, I decided to test out gpt-4o and felt a difference on the way the agent was reasoning.</li>
<li>Initially, I was using an LLM temperature = 0, this was ok, but the responses were lacking variety and details, I needed to make it more chatty. Tweaking the temperature = 0.9 gave me a good balance between chattiness and correctness (although sometimes the agent still gives information that is <em>questionable</em> based on the outputs)</li>
<li>Troubleshooting problems could be difficult at times, mostly I relied on printing outputs while the functions were executed and the agent outputs on the terminal. It let me understand what tools the agent was using and the order. Also, I could see what the tools were returning. Here is an example:</li>
</ul>
<p><img loading="lazy" src="/wp-content/uploads/2024/07/Terminal.png"></p>
<p>The text in green indicate the tools the agent is accessing. The yellow text is the information returned by a function. In this case, we can see that the agent called <code>&quot;get_entry_time_and_state&quot;</code> function so it can get information needed to call the next function <code>&quot;get_flow_detail&quot;</code></p>
<p>There are better tools available to help with troubleshooting like <a href="https://python.langchain.com/v0.2/docs/how_to/debugging/">LangSmith Tr</a> <a href="https://python.langchain.com/v0.2/docs/how_to/debugging/">acing</a>, I will explore it for future use.</p>
<ul>
<li>The system prompt of my agent had to be refined several times, I often found that I needed to provide more details to handle certain situations correctly, especially when the output of a function was needed to call another one or to handle unexpected situations. I think it can still be improved, in fact I want to write a totally different prompt to try and make the agent run all of the tools by itself and just return a conclusion after analyzing all the outputs.</li>
</ul>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>All in all, it was a good (and long) exercise to learn and build my first assistant. I feel happy with the result as I was able to get to me objective. At the same time, I recognize there are a lot of things that could be improved to make the results more reliable and meaningful. Also, there is much more information that NWPI can show, so the tools can definitely be extended.</p>
<p>As a next step, I am planning to learn LangChain properly and understand how can I implement multiple agents to enhance the functionality and reliability of my assistant.</p>
<p>I hope this post will help you in the same way that Cisco Live presentation helped me!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://netwithalex.netlify.app/">NetWithAlex</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
