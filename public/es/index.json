[{"content":"Introducción La idea de escribir esta publicación surgió tras presenciar un comportamiento inesperado en cómo los routers SD-WAN manejan diferentes operaciones que provocan un reinicio del router. De hecho, esto se descubrió \u0026ldquo;por accidente\u0026rdquo; al realizar actualizaciones de software en un par de routers SD-WAN y no fue detectado durante pruebas de failover. En la publicación de hoy voy a comparar cómo se trata un reinicio usando el comando reload en comparación con uno provocado por una actualización de software.\nTopología Una configuración SD-WAN tradicional con doble router, corriendo BGP hacia un router externo en el lado del servicio que proporciona conectividad a otros sitios. Algo simple como esto:\nLa configuración de BGP es súper simple y suficiente para ejemplificar este comportamiento. Los routers SD-WAN tienen configuraciones idénticas.\nGateway#show run | s r b router bgp 64002 bgp log-neighbor-changes neighbor 172.16.1.1 remote-as 64001 neighbor 172.16.1.2 remote-as 64001 BR1-1#sh run | s r b router bgp 64001 bgp log-neighbor-changes ! address-family ipv4 vrf 1 network 172.16.2.0 mask 255.255.255.0 neighbor 172.16.1.15 remote-as 64002 neighbor 172.16.1.15 activate neighbor 172.16.1.15 send-community both distance bgp 20 200 20 exit-address-family A nivel de enrutamiento, el router Gateway tiene dos rutas disponibles para llegar al servidor web, ambas iguales y aprendidas por BGP. Con la configuración actual, el Gateway elige BR1-1 como ruta principal y BR1-2 queda como respaldo.\nGateway# sh ip route | b Gateway Gateway of last resort is not set 172.16.0.0/16 is variably subnetted, 3 subnets, 2 masks C 172.16.1.0/24 is directly connected, Ethernet0/0 L 172.16.1.15/32 is directly connected, Ethernet0/0 B 172.16.2.0/24 [20/1000] via 172.16.1.1, 02:48:02 Gateway# sh ip bgp BGP table version is 3, local router ID is 192.168.1.15 Status codes: s suppressed, d damped, h history, * valid, \u0026gt; best, i - internal, r RIB-failure, S Stale, m multipath, b backup-path, f RT-Filter, x best-external, a additional-path, c RIB-compressed, t secondary path, L long-lived-stale, Origin codes: i - IGP, e - EGP, ? - incomplete RPKI validation codes: V valid, I invalid, N Not found Network Next Hop Metric LocPrf Weight Path * 172.16.2.0/24 172.16.1.2 1000 0 64001 i *\u0026gt; 172.16.1.1 1000 0 64001 i Comportamiento usando el comando reload Comencemos examinando qué hacen los routers SD-WAN al reiniciar con el comando reload. Reiniciaré BR1-1, ya que es el router primario.\n*18:08:35.380 UTC Wed Jul 30 2025 BR1-1#reload Proceed with reload? [confirm] Inicio un ping desde el router Gateway para verificar si la conectividad se ve afectada:\nGateway#sh clock *18:08:42.345 UTC Wed Jul 30 2025 Gateway#ping 172.16.2.2 rep 10000 Type escape sequence to abort. Sending 10000, 100-byte ICMP Echos to 172.16.2.2, timeout is 2 seconds: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! \u0026lt;...\u0026gt; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! *Jul 30 18:09:01.490: %BGP-5-NBR_RESET: Neighbor 172.16.1.1 reset (Peer closed the session) *Jul 30 18:09:01.490: %BGP-5-ADJCHANGE: neighbor 172.16.1.1 Down Peer closed the session *Jul 30 18:09:01.490: %BGP_SESSION-5-ADJCHANGE: neighbor 172.16.1.1 IPv4 Unicast topology base removed from session Peer closed the session \u0026lt;...\u0026gt; !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Success rate is 100 percent (10000/10000), round-trip min/avg/max = 1/1/32 ms Gateway#sh ip route | b Gateway Gateway of last resort is not set 172.16.0.0/16 is variably subnetted, 3 subnets, 2 masks C 172.16.1.0/24 is directly connected, Ethernet0/0 L 172.16.1.15/32 is directly connected, Ethernet0/0 B 172.16.2.0/24 [20/1000] via 172.16.1.2, 00:02:42 Gateway#sh ip bgp all sum | b Nei Neighbor V AS MsgRcvd MsgSent TblVer InQ OutQ Up/Down State/PfxRcd 172.16.1.1 4 64001 0 0 1 0 0 00:00:19 Active 172.16.1.2 4 64001 193 197 4 0 0 02:51:15 1 We can see that the BGP session to BR1-1 was closed and the ping continued without issues through BR1-2.Podemos ver que la sesión BGP con BR1-1 se cerró y el ping continuó sin problemas a través de BR1-2.\nA nivel de paquetes, BR1-1 cerró la sesión BGP antes de reiniciar, evitando interrupciones.\nEste es el comportamiento esperado y cómo se hacen típicamente las pruebas de failover.\nComportamiento durante una actualización Ahora BR1-2 es la ruta primaria:\nBGP#sh ip route | b Gateway Gateway of last resort is not set 172.16.0.0/16 is variably subnetted, 3 subnets, 2 masks C 172.16.1.0/24 is directly connected, Ethernet0/0 L 172.16.1.15/32 is directly connected, Ethernet0/0 B 172.16.2.0/24 [20/1000] via 172.16.1.2, 00:28:48 Esta vez usaré el Manager para actualizar BR1-2.\nEl ping desde el router Gateway falla cuando BR1-2 se reinicia:\nGateway# ping 172.16.2.2 rep 1000000 Type escape sequence to abort. Sending 1000000, 100-byte ICMP Echos to 172.16.2.2, timeout is 2 seconds: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!............................................ Curiosamente, el vecino BGP sigue activo, y la ruta sigue apuntando a BR1-2 aunque ya no está disponible:\nGateway# sh ip route | b Gate Gateway of last resort is not set 172.16.0.0/16 is variably subnetted, 3 subnets, 2 masks C 172.16.1.0/24 is directly connected, Ethernet0/0 L 172.16.1.15/32 is directly connected, Ethernet0/0 B 172.16.2.0/24 [20/1000] via 172.16.1.2, 00:35:09 El tráfico queda en un blackhole durante el tiempo de espera de BGP:\nGateway# ping 172.16.2.2 rep 5 Type escape sequence to abort. Sending 10, 100-byte ICMP Echos to 172.16.2.2, timeout is 2 seconds: ..... *Jul 30 15:17:10.575: %BGP-3-NOTIFICATION: sent to neighbor 172.16.1.2 4/0 (hold time expired) 0 bytes!!!!! Success rate is 50 percent (5/10), round-trip min/avg/max = 1/1/2 ms *Jul 30 15:17:10.575: %BGP-5-NBR_RESET: Neighbor 172.16.1.2 reset (BGP Notification sent) *Jul 30 15:17:10.575: %BGP-5-ADJCHANGE: neighbor 172.16.1.2 Down BGP Notification sent *Jul 30 15:17:10.575: %BGP_SESSION-5-ADJCHANGE: neighbor 172.16.1.2 IPv4 Unicast topology base removed from session BGP Notification sent Gateway#ping 172.16.2.2 rep 5 Type escape sequence to abort. Sending 5, 100-byte ICMP Echos to 172.16.2.2, timeout is 2 seconds: !!!!! Success rate is 100 percent (5/5), round-trip min/avg/max = 1/2/3 ms Conceptos erróneos comunes Un error común en operaciones de red es asumir que todos los tipos de reinicio se comportan igual. Es fácil pensar que si el reinicio se da por CLI, por algun power cycle o una actualización de software, el resultado será consistente: BGP se cae, se quitan rutas y se hace el failover. Este estudio demuestra lo contrario.\nEn Cisco SD-WAN, un reinicio por actualización desde el Manager no cierra las sesiones de control como BGP. A diferencia del comando reload, no se envía un FIN de TCP que cierra la sesión de manera correcta. El reinicio por actualización de software se salta este paso, manteniendo la sesión \u0026ldquo;viva\u0026rdquo; aunque el router vecino este abajo.\nEste comportamiento sutil rara vez está documentado, y se prueba aún con menos frecuencia. Muchos ingenieros confían únicamente en pruebas de reinicio o flapeo de interfaces para validar el comportamiento ante fallos. Como resultado, pueden creer que su configuración es resiliente, cuando en realidad es vulnerable a ciertos workflows de actualización.\nSer consciente de esta diferencia es clave para diseñar una red más robusta y predecible.\nAnálisis Al inspeccionar los logs del Manager vemos que se envía el siguiente comand de netconf hacia BR1-2.\n30-Jul-2025 19:34:51,103 UTC INFO [6a486f9b-e3d8-42f7-982b-89701bfeab58] [Manager01] [ChangePartitionActionProcessor] (device-action-change_partition-1) || Change partition request XML \u0026lt;activate xmlns=\u0026#34;http://cisco.com/ns/yang/Cisco-IOS-XE-install-rpc\u0026#34;\u0026gt; \u0026lt;uuid xmlns=\u0026#34;http://cisco.com/ns/yang/Cisco-IOS-XE-install-rpc\u0026#34;\u0026gt;change_partition-fc8b8de6-5f34-470d-b8a0-40e0f6513686%C8K-D4CE7174-5261-7E6F-91EA-4926BCF4C2DD%1800000\u0026lt;/uuid\u0026gt; \u0026lt;version xmlns=\u0026#34;http://cisco.com/ns/yang/Cisco-IOS-XE-install-rpc\u0026#34;\u0026gt;17.15.03a.0.176\u0026lt;/version\u0026gt; \u0026lt;/activate\u0026gt; El comando equivalente en SD-WAN es:\nrequest platform software sdwan activate \u0026lt;version\u0026gt; Por lo tanto, no es una comparación directa, pero naturalmente se esperaría un cierre limpio de la sesión BGP como cuando se usa el comando reload.\nSolución Para evitar este comportamiento, debemos usar BFD enlazado con BGP:\nPara configurarlo en los equipo de SD-WAN se hace por CLI Add-on\nLa configuración en el Gateway:\nbfd-template single-hop t1 interval min-tx 250 min-rx 250 multiplier 3 interface eth0/0 bfd template t1 router bgp 64002 bgp log-neighbor-changes neighbor 172.16.1.1 remote-as 64001 neighbor 172.16.1.1 fall-over bfd neighbor 172.16.1.2 remote-as 64001 neighbor 172.16.1.2 fall-over bfd Con esto, BGP detectará el fallo en menos de un segundo, previniendo ese blackhole del tráfico.\nAl probarlo, solo se pierde un ping:\nGateway#ping 172.16.2.2 rep 10000000 Type escape sequence to abort. Sending 10000000, 100-byte ICMP Echos to 172.16.2.2, timeout is 2 seconds: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! *Aug 1 09:50:08.876: %BFDFSM-6-BFD_SESS_DOWN: BFD-SYSLOG: BFD session ld:1 handle:1,is going Down Reason: DETECT TIMER EXPIRED *Aug 1 09:50:08.876: %BGP-5-NBR_RESET: Neighbor 172.16.1.2 reset (BFD adjacency down) *Aug 1 09:50:08.876: %BGP-5-ADJCHANGE: neighbor 172.16.1.2 Down BFD adjacency down *Aug 1 09:50:08.876: %BGP_SESSION-5-ADJCHANGE: neighbor 172.16.1.2 IPv4 Unicast topology base removed from session BFD adjacency down.!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! *Aug 1 09:50:08.876: %BFD-6-BFD_SESS_DESTROYED: BFD-SYSLOG: bfd_session_destroyed, ld:1 neigh proc:BGP, idb:Ethernet0/0 handle:1 active!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! \u0026lt;...\u0026gt; Success rate is 99 percent (22877/22878), round-trip min/avg/max = 1/1/70 ms Resumen: CLI vs Manager Here’s a quick comparison of what happens when a router reloads via CLI vs when it’s upgraded through the SD-WAN Manager:\nComportamiento Reinicio por CLI(reload) Actualización via Manager Manejo sesión de BGP Sesión cerrada con TCP FIN Sesión permanece activa hasta llegar al hold time Retiro de rutas Inmediato Retrasado (hasta llegar al BGP hold timer) Impacto en el tráfico Mínimo Alto (blackhole) Cubierto en pruebas típicas Sí No siempre ¿Puede mitigarse con BFD? Opcional Altamente recomendado Convergencia sin BFD) sub-segundo Minutos Convergencia con BFD) sub-segundo Sub-segundo Esta tabla resalta por qué BFD no es solo “algo bueno de tener”, sino una parte crítica en las implementaciones de SD-WAN.\nConclusion Este caso de estudio revela un aspecto importante y frecuentemente pasado por alto del comportamiento ante fallos en Cisco SD-WAN: no todos los reinicios son tratados por igual. Mientras que un reinicio manual termina limpiamente las sesiones BGP, provocando un redireccionamiento inmediato, una actualización iniciada desde el SD-WAN Manager no siempre envía señales a los protocolos de control antes de apagarse. Esta diferencia sutil puede causar pérdida de tráfico (blackhole) durante toda la duración del hold timer de BGP.\nAquí es donde BFD se vuelve un aliado clave. Al reducir los tiempos de detección de fallos de minutos a sub-segundos, BFD asegura que los protocolos de enrutamiento puedan adaptarse rápidamente, incluso en casos donde el router no cierra adecuadamente las sesiones. Asociar BFD a las sesiones BGP es una forma simple y efectiva de reforzar tu topología frente a estos comportamientos.\nAdemás, este comportamiento no se limita solo a actualizaciones de software. También puedes encontrar problemas similares en otros escenarios de “fallo silencioso”, por ejemplo:\nUn corte de fibra entre pares que no genera una caída directa de la interfaz. Fallos indirectos dentro del transporte o la infraestructura de switching. Un cambio de route processor (RP). Entonces, ¿cuál es la lección principal? No asumas que el comportamiento por CLI refleja todos los escenarios. Siempre prueba el failover usando los métodos reales que se usan en producción—ya sea una actualización de software o una tarea iniciada desde el Manager. Y como recomendación final: despliega siempre BFD. Es una inversión pequeña con un gran retorno.\n¡Nos vemos en el próximo!\n","permalink":"http://localhost:1313/case-study-es/","summary":"En este caso de estudio exploramos un comportamiento interesante observado al actualizar dispositivos mediante el SD-WAN Manager, el cual podría causar problemas de tráfico. También veremos cómo mitigar este riesgo usando BFD.","title":"Reload vs Upgrade: Un caso de estudio"},{"content":"Introducción SD-WAN proporciona una arquitectura de overlay altamente flexible que permite construir túneles sobre múltiples tipos de transporte. Un aspecto clave de esta flexibilidad es cómo se reenvía el tráfico entre dispositivos edge a través de túneles basados en colores de transporte como privados (mpls, private1, etc) y públicos (public-internet, biz-internet, etc).\nExisten un par de formas de controlar qué túneles se crean, siendo las más destacadas las Políticas de Control y los Tunnel Groups.\nLos Tunnel Groups permiten a los administradores de red agrupar lógicamente túneles (TLOCs) bajo una etiqueta común, simplificando cómo se establecen los túneles entre dispositivos. Este enfoque hace que la gestión de túneles sea más escalable y fácil de mantener. En este post exploraremos qué son los Tunnel Groups, cómo funcionan y cómo pueden servir como alternativa a las Control Policies en ciertos escenarios.\n¿Qué son los Tunnel Groups? Un Tunnel Group es una etiqueta numérica que representa un conjunto de TLOCs (túneles) agrupados lógicamente según una intención definida.\nFigura 1 – Tunnel Group configurado en Feature Template Una vez que se configura un Tunnel Group ID, el router:\nEstablecerá túneles con TLOCs que tengan el mismo Tunnel Group ID. Establecerá túneles con TLOCs que no tengan Tunnel Group ID (valor 0). El Tunnel Group ID se propaga por OMP, igual que otros atributos de los TLOCs. Una diferencia clave entre Tunnel Groups y Políticas de Control es dónde se aplican: los Tunnel Groups controlan el establecimiento de túneles localmente en el dispositivo, mientras que las Control Policies determinan qué TLOCs son anunciados por el Controller (vSmart) a nivel central. Ambos mecanismos pueden usarse de forma independiente o combinada, dependiendo del diseño.\nComportamiento del Tunnel Group: Ejemplo Real Tomemos esta topología como referencia para el escenario:\nFigura 2 – Topología de Referencia Vamos a validar cómo los Tunnel Group IDs influyen en qué túneles se forman realmente observando los TLOCs y sesiones BFD desde un dispositivo en el sitio 20.\nBarcelona_BR20-1#show sdwan omp tlocs table ... PUBLIC PRIVATE AFFINITY ADDRESS TENANT PSEUDO PUBLIC PRIVATE PUBLIC IPV6 PRIVATE IPV6 BFD GROUP FAMILY TLOC IP COLOR ENCAP ID FROM PEER STATUS TENANT NAME KEY PUBLIC IP PORT PRIVATE IP PORT IPV6 PORT IPV6 PORT STATUS REGION ID NUMBER --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ipv4 1.1.10.1 mpls ipsec 0 1.0.0.3 C,I,R [Default] 1 21.11.0.2 12426 21.11.0.2 12426 :: 0 :: 0 down None None 1.1.10.1 biz-internet ipsec 0 1.0.0.3 C,I,R [Default] 1 31.11.0.2 12346 31.11.0.2 12346 :: 0 :: 0 down None None 1.1.10.2 mpls ipsec 0 1.0.0.3 C,I,R [Default] 1 21.12.0.2 12346 21.12.0.2 12346 :: 0 :: 0 down None None 1.1.10.2 biz-internet ipsec 0 1.0.0.3 C,I,R [Default] 1 31.12.0.2 12346 31.12.0.2 12346 :: 0 :: 0 down None None 1.1.20.1 mpls ipsec 0 0.0.0.0 C,Red,R [Default] 1 21.21.0.2 12346 21.21.0.2 12346 :: 0 :: 0 up None None 1.1.20.1 biz-internet ipsec 0 0.0.0.0 C,Red,R [Default] 1 31.21.0.2 12346 31.21.0.2 12346 :: 0 :: 0 up None None 1.1.20.2 mpls ipsec 0 1.0.0.3 C,I,R [Default] 1 21.22.0.2 12346 21.22.0.2 12346 :: 0 :: 0 down None None 1.1.20.2 biz-internet ipsec 0 1.0.0.3 C,I,R [Default] 1 31.22.0.2 12346 31.22.0.2 12346 :: 0 :: 0 down None None 1.1.100.1 mpls ipsec 0 1.0.0.3 C,I,R [Default] 1 21.101.0.2 12406 21.101.0.2 12406 :: 0 :: 0 up None None 1.1.100.1 biz-internet ipsec 0 1.0.0.3 C,I,R [Default] 1 31.101.0.2 12346 31.101.0.2 12346 :: 0 :: 0 up None None 1.1.100.2 mpls ipsec 0 1.0.0.3 C,I,R [Default] 1 21.102.0.2 12346 21.102.0.2 12346 :: 0 :: 0 up None None 1.1.100.2 biz-internet ipsec 0 1.0.0.3 C,I,R [Default] 1 31.102.0.2 12346 31.102.0.2 12346 :: 0 :: 0 up None None 1.1.200.1 mpls ipsec 0 1.0.0.3 C,I,R [Default] 1 21.201.0.2 12346 21.201.0.2 12346 :: 0 :: 0 up None None 1.1.200.1 biz-internet ipsec 0 1.0.0.3 C,I,R [Default] 1 31.201.0.2 12346 31.201.0.2 12346 :: 0 :: 0 up None None 1.1.200.2 mpls ipsec 0 1.0.0.3 C,I,R [Default] 1 21.202.0.2 12346 21.202.0.2 12346 :: 0 :: 0 up None None 1.1.200.2 biz-internet ipsec 0 1.0.0.3 C,I,R [Default] 1 31.202.0.2 12386 31.202.0.2 12386 :: 0 :: 0 down None None Se reciben 14 TLOCs desde vSmart, pero solo algunos túneles están activos:\nBarcelona_BR20-1#sh sdwan bfd sessions SOURCE TLOC REMOTE TLOC DST PUBLIC DST PUBLIC DETECT TX SYSTEM IP SITE ID STATE COLOR COLOR SOURCE IP IP PORT ENCAP MULTIPLIER INTERVAL(msec UPTIME TRANSITIONS ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 1.1.100.1 100 up mpls mpls 21.21.0.2 21.101.0.2 12406 ipsec 7 1000 0:02:23:34 2 1.1.100.2 100 up mpls mpls 21.21.0.2 21.102.0.2 12346 ipsec 7 1000 0:02:23:33 1 1.1.200.1 200 up mpls mpls 21.21.0.2 21.201.0.2 12346 ipsec 7 1000 6:03:57:35 0 1.1.200.2 200 up mpls mpls 21.21.0.2 21.202.0.2 12346 ipsec 7 1000 6:03:57:36 0 1.1.100.1 100 up biz-internet biz-internet 31.21.0.2 31.101.0.2 12346 ipsec 7 1000 0:02:23:34 1 1.1.100.2 100 up biz-internet biz-internet 31.21.0.2 31.102.0.2 12346 ipsec 7 1000 0:02:23:33 1 1.1.200.1 200 up biz-internet biz-internet 31.21.0.2 31.201.0.2 12346 ipsec 7 1000 6:03:57:35 0 1.1.200.2 200 up biz-internet biz-internet 31.21.0.2 31.202.0.2 12426 ipsec 7 1000 0:00:00:08 0 Si examinamos los detalles de los TLOC, vemos que hay 4 TLOCs con un group-id no coincidente de 10. El resto o bien coinciden o están sin configurar ([0]). Recuerda que los dispositivos dentro del mismo sitio no forman túneles BFD.\nBarcelona_BR20-1#show sdwan omp tlocs | include tloc|mpls|internet|groups|site tloc entries for 1.1.10.1 \u0026lt;\u0026lt;\u0026lt; Group ID Diferente mpls site-id 10 groups [ 10 ] site-type not set tloc entries for 1.1.10.1 \u0026lt;\u0026lt;\u0026lt; Group ID Diferente biz-internet site-id 10 groups [ 10 ] site-type not set tloc entries for 1.1.10.2 \u0026lt;\u0026lt;\u0026lt; Group ID Diferente mpls site-id 10 groups [ 10 ] site-type not set tloc entries for 1.1.10.2 \u0026lt;\u0026lt;\u0026lt; Group ID Diferente biz-internet site-id 10 groups [ 10 ] site-type not set tloc entries for 1.1.20.1 \u0026lt;\u0026lt;\u0026lt;\u0026lt; TLOC propio mpls site-id 20 groups [ 20 ] site-type not set site-id 20 groups [ 20 ] ) site-type not set tloc entries for 1.1.20.1 \u0026lt;\u0026lt;\u0026lt;\u0026lt; TLOC propio biz-internet site-id 20 groups [ 20 ] site-type not set site-id 20 groups [ 20 ] ) site-type not set tloc entries for 1.1.20.2 \u0026lt;\u0026lt;\u0026lt;\u0026lt; mismo sitio mpls site-id 20 groups [ 20 ] site-type not set tloc entries for 1.1.20.2 \u0026lt;\u0026lt;\u0026lt;\u0026lt; mismo sitio biz-internet site-id 20 groups [ 20 ] site-type not set tloc entries for 1.1.100.1 #1 mpls site-id 100 groups [ 0 ] site-type not set tloc entries for 1.1.100.1 #2 biz-internet site-id 100 groups [ 0 ] site-type not set tloc entries for 1.1.100.2 #3 mpls site-id 100 groups [ 0 ] site-type not set tloc entries for 1.1.100.2 #4 biz-internet site-id 100 groups [ 0 ] site-type not set tloc entries for 1.1.200.1 #5 mpls site-id 200 groups [ 20 ] site-type not set tloc entries for 1.1.200.1 #6 biz-internet site-id 200 groups [ 20 ] site-type not set tloc entries for 1.1.200.2 #7 mpls site-id 200 groups [ 20 ] site-type not set tloc entries for 1.1.200.2 #8 biz-internet site-id 200 groups [ 20 ] site-type not set Tunnel Group + opción restrict Como se muestra arriba, solo se establecen túneles entre colores coincidentes, lo que significa que la opción restrict está habilitada en los dispositivos:\nFigura 3 – Configuración de Tunnel Group con la opción \u0026#39;restrict\u0026#39; Si se desactiva la opción restrict para el túnel MPLS, veamos qué sucede con las sesiones BFD:\nBarcelona_BR20-1#show sdwan bfd sessions SOURCE TLOC REMOTE TLOC DST PUBLIC DST PUBLIC DETECT TX SYSTEM IP SITE ID STATE COLOR COLOR SOURCE IP IP PORT ENCAP MULTIPLIER INTERVAL(msec UPTIME TRANSITIONS ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 1.1.100.1 100 up mpls mpls 21.21.0.2 21.101.0.2 12406 ipsec 7 1000 0:03:14:45 2 1.1.100.2 100 up mpls mpls 21.21.0.2 21.102.0.2 12346 ipsec 7 1000 0:03:14:44 1 1.1.200.1 200 up mpls mpls 21.21.0.2 21.201.0.2 12346 ipsec 7 1000 6:04:48:46 0 1.1.200.2 200 up mpls mpls 21.21.0.2 21.202.0.2 12346 ipsec 7 1000 6:04:48:47 0 1.1.100.1 100 up mpls biz-internet 21.21.0.2 31.101.0.2 12346 ipsec 7 1000 0:00:03:37 0 1.1.100.2 100 up mpls biz-internet 21.21.0.2 31.102.0.2 12346 ipsec 7 1000 0:00:03:37 0 1.1.200.1 200 up mpls biz-internet 21.21.0.2 31.201.0.2 12346 ipsec 7 1000 0:00:03:37 0 1.1.200.2 200 up mpls biz-internet 21.21.0.2 31.202.0.2 12426 ipsec 7 1000 0:00:03:37 0 1.1.200.1 200 up biz-internet mpls 31.21.0.2 21.201.0.2 12346 ipsec 7 1000 0:00:03:33 0 1.1.200.2 200 up biz-internet mpls 31.21.0.2 21.202.0.2 12346 ipsec 7 1000 0:00:03:35 0 1.1.100.1 100 up biz-internet biz-internet 31.21.0.2 31.101.0.2 12346 ipsec 7 1000 0:03:14:45 1 1.1.100.2 100 up biz-internet biz-internet 31.21.0.2 31.102.0.2 12346 ipsec 7 1000 0:03:14:44 1 1.1.200.1 200 up biz-internet biz-internet 31.21.0.2 31.201.0.2 12346 ipsec 7 1000 6:04:48:46 0 1.1.200.2 200 up biz-internet biz-internet 31.21.0.2 31.202.0.2 12426 ipsec 7 1000 0:00:51:19 0 Ahora hay túneles entre diferentes colores, pero respetando el Tunnel Group ID.\nEn resumen, si la opción restrict está configurada junto con Tunnel Groups, los túneles se formarán si:\nEl color del TLOC coincide. Los Tunnel Group IDs coinciden o uno de los extremos no tiene Tunnel Group configurado (Group 0). Casos de Uso Veamos algunos casos reales para esta funcionalidad.\nAgrupar colores privados y públicos Existen múltiples etiquetas para colores privados y públicos. Dependiendo del diseño de red, podrías terminar con diferentes nombres de colores por región. Ejemplo:\nContinente Colores Públicos Colores Privados Europa biz-internet mpls América gold metro-ethernet Usando Tunnel Groups, podemos separar fácilmente los túneles entre colores privados y públicos:\nFigura 4 – Agrupación de Colores basada en Tunnel Group ID Asignando Tunnel Group 10 a los colores privados, nos aseguramos que solo se establezcan túneles entre mpls y metro-ethernet. De igual forma, el Tunnel Group 20 permitirá túneles entre colores públicos, gold y biz-internet.\nEscalamiento Horizontal Cuando los routers del data center deben construir túneles con muchas sucursales remotas, cada una usando múltiples transportes, pueden alcanzar el límite de escala de túneles de la plataforma. Tunnel Groups ayudan a distribuir la creación de túneles entre diferentes routers y sucursales, haciendo el diseño más escalable.\nFigura 5 – Estrategia de Escalamiento Horizontal con Tunnel Groups Así, cada sucursal estará conectada a ambos data centers, pero manteniendo bajo control la cantidad de sesiones en los routers del data center.\nCrear Mesh Parcial Si necesitas crear una malla parcial, los Tunnel Groups pueden ser de gran ayuda.\nFigura 5 – Topología de Mesh Parcial En este caso, los dispositivos con Tunnel Group 10 y sin Tunnel Group (0) establecerán túneles entre ellos. De igual forma, los dispositivos con Tunnel Group 20 y sin Tunnel Group (0) formarán túneles.\nConclusión Los Tunnel Groups en Cisco SD-WAN ofrecen una forma escalable de controlar el establecimiento de túneles en despliegues pequeños o grandes. Al etiquetar TLOCs con IDs de grupo numéricos, puedes:\nCrear grupos lógicos de túneles sin depender únicamente del color. Reducir la complejidad de las políticas de control centralizadas. Diseñar topologías más predecibles y escalables como malla parcial, hub-and-spoke o escalamiento horizontal. Ya sea para lidiar con nombres de colores inconsistentes entre regiones, escalar routers del data center o simplemente tener una forma más limpia de gestionar túneles, los Tunnel Groups ofrecen una herramienta potente para simplificar el diseño.\nCuando se combinan con la opción restrict, los Tunnel Groups te dan control granular sobre qué túneles se permiten,por color, por grupo o ambos. Con la estrategia adecuada, puedes reducir significativamente la cantidad de túneles innecesarios, manteniendo alta disponibilidad y buen rendimiento.\n","permalink":"http://localhost:1313/tunnel-groups-es/","summary":"Descubre cómo los Tunnel Groups en Cisco SD-WAN simplifican la gestión de túneles a gran escala. Aprende cómo funcionan, en qué se diferencian de las políticas de control y cuándo usarlos con ejemplos del mundo real.","title":"Simplificando la gestión de túneles con Tunnel Groups en Cisco SD-WAN"},{"content":"Aprende las diferencias clave entre las control y data policies en Cisco SD-WAN, cuándo usar cada una y cómo impactan en el enrutamiento y el reenvío del tráfico.\nIntroducción Cisco SD-WAN proporciona herramientas poderosas para definir tanto el comportamiento de enrutamiento como el flujo del tráfico a través del overlay. En el núcleo de esta flexibilidad existen dos tipos clave de políticas: políticas de control y Data Policies. Entender la diferencia entre ambas es crucial para diseñar implementaciones SD-WAN escalables y optimizadas.\nEn esta publicación, exploraremos qué hace cada tipo de política, en qué se diferencian y cuándo usar una sobre la otra.\nPolíticas Centralizadas y Locales Las políticas se categorizan según el lugar donde se configuran y aplican: pueden ser Centralizadas o Locales. El Manager utiliza netconf/yang para enviar la configuración de políticas.\nPolíticas Centralizadas\nSe configuran en el Controller (vSmart) y se envían a un grupo seleccionado de routers SD-WAN a través del protocolo Overlay Management Protocol (OMP). Incluyen:\npolíticas de control Data policies Políticas de App-Aware Routing Políticas Locales\nSe configuran directamente en los routers SD-WAN y solo afectan a ese dispositivo específico. Incluyen:\nACLs locales Políticas de enrutamiento (Route policies) Configuración de QoS ¿Qué son las Políticas de Control? Las políticas de control en Cisco SD-WAN se aplican en el plano de control – específicamente, definen cómo se intercambia la información de ruteo entre los Controllers y los routers SD-WAN.\nCaracterísticas clave:\nSe aplican en los Controllers Influyen en la publicación de rutas y propagación de TLOCs Definen qué rutas se aceptan, modifican o rechazan Casos de uso típicos:\nCrear topologías (hub/spoke, partial-mesh, etc.) Controlar route-leaking entre VPNs Filtrado o etiquetado de rutas OMP Las políticas de control definen la topología SD-WAN, decidiendo qué rutas existen y hacia dónde pueden ir.\n¿Qué son las Políticas de Datos? Las políticas de datos, por otro lado, operan en el plano de datos. Definen cómo se maneja el tráfico real.\nCaracterísticas clave:\nTambién se configuran en los Controllers pero se aplican en los routers SD-WAN Operan a nivel de plano de datos, no afectan la publicación de rutas Pueden hacer match a varios campos: IP de origen/destino, puertos, aplicaciones, etc. Casos de uso típicos:\nRedirección de tráfico según aplicación Aplicación de clases de QoS Bloqueo de ciertos tipos de tráfico (por ejemplo, mediante reglas tipo ACL) Usando una analogía: las políticas de control son los urbanistas que deciden dónde se construyen las calles; las políticas de datos son las reglas de tránsito que dictan cómo se mueve el tráfico por ellas.\nDiferencias clave a simple vista Característica Control Policy políticas de datos Plano Plano de control Plano de datos Se aplica en Controller WAN Edge Afecta Publicación de rutas Reenvío del tráfico real Casos comunes Filtrado de rutas, TLOCs Redirección de tráfico, QoS, ACLs Direccionalidad Entre controllers Del controller a los routers Orden de ejecución de políticas Los siguientes pasos ocurren cuando un paquete pasa por un router de SD-WAN:\nPrimero se aplican las políticas locales de entrada, como las ACLs a nivel de interfaz y configuraciones de QoS. Estas pueden filtrar paquetes y aplicar marcados o remarcar para QoS.\nDespués se evalúa la política de Application-Aware Routing centralizada. Este toma decisiones de reenvío solo entre rutas de costo igual que ya estén en la tabla de enrutamiento.\nLuego se evalúa la política de datos centralizada, que tiene la capacidad de sobrescribir cualquier decisión de reenvío tomada por AAR.\nUna vez aplicadas las políticas, el sistema realiza una búsqueda de enrutamiento y envío para identificar la interfaz de salida apropiada.\nSe aplican los mecanismos de queueing y scheduling para moldear el tráfico según la configuración de QoS.\nFinalmente, se aplica la política local de salida antes de colocar el paquete en el medio.\nEntender este orden es clave para evitar errores de configuración y asegurar que tus políticas funcionen como esperas. Un error común es sobrescribir sin querer una decisión de AAR aplicando una políticas de datos centralizada que coincide con el mismo tráfico y lo redirige a otro lugar.\n¿Cuándo usar cuál? Elegir entre control y data policies depende de qué problema estás tratando de resolver:\n¿Quieres limitar qué rutas se comparten entre sitios? → Usa una políticas de control. ¿Necesitas redirigir ciertas aplicaciones por MPLS o DIA? → Eso es trabajo de una políticas de datos. ¿Intentas evitar loops de publicidad de rutas o controlar fugas entre VPNs? → políticas de control. ¿Quieres priorizar tráfico VoIP o bloquear tráfico P2P? → políticas de datos. En muchos diseños, ambas se usan en conjunto. Por ejemplo, una control policy puede garantizar que solo ciertos prefijos sean alcanzables entre sitios, mientras que una políticas de datos se encarga de cómo se prioriza y reenvía ese tráfico coincidente.\nConclusión Las políticas de datos y control tienen propósitos distintos pero complementarios en Cisco SD-WAN. Una gobierna la topología y decisiones de enrutamiento, la otra define cómo se mueve el tráfico dentro de esa topología.\nEntender estas diferencias te permite construir entornos SD-WAN más inteligentes y eficientes. ¿Quieres profundizar más? Consulta la documentación oficial de Cisco sobre políticas de control y Data Policies.\nTambién te recomiendo leer mi análisis detallado sobre Application-Aware Routing, y descubrir cómo SD-WAN puede mover automáticamente el tráfico hacia los caminos de mejor rendimiento y garantizar una buena experiencia para el usuario.\n","permalink":"http://localhost:1313/policies-intro-es/","summary":"Aprende las diferencias clave entre las control y data policies en Cisco SD-WAN, cuándo usar cada una y cómo impactan en el enrutamiento y el reenvío del tráfico.","title":"Guía Rápida: Control vs Data Policies en Cisco SD-WAN"},{"content":"Introducción En esta publicación, exploraremos cómo dar los primeros pasos con la automatización en SD-WAN. Ya sea que estés comenzando con los scripts o apenas empieces a descubrir lo que es posible hacer con la API de SD-WAN, esta guía te ayudará a empezar. Cubriremos conceptos clave, ejemplos prácticos y las herramientas que necesitas para automatizar tareas y simplificar tus operaciones de red.\n¿Por qué deberías automatizar? Hay muchos casos donde la automatización puede aportar beneficios significativos. Ya sea para aplicar cambios más rápido, minimizar riesgos, ahorrar tiempo, construir herramientas personalizadas o integrar con sistemas de terceros — la automatización abre la puerta a una gestión de red más simple y eficiente.\nAquí algunos casos de uso comunes:\nDespliegue de dispositivos – Automatiza el proceso de despliegue de VMs y su configuración inicial usando plantillas predefinidas. Gestión de configuraciones – Aplica configuraciones mediante la API en segundos, en lugar de iniciar sesión manualmente en cada dispositivo. Monitoreo y alertas – Recibe alertas cuando ocurran eventos específicos en la red y crea scripts para monitorear exactamente lo que necesitas. Integración con otros sistemas – Enriquece plataformas de Cisco o externas con información compartida directamente desde el SD-WAN Manager. Verificaciones de salud – Verifica de forma continua que tu red esté funcionando correctamente y bajo el estado deseado. Ampliación de capacidades – Experimenta con nuevas tecnologías y explora cómo integrarlas a tus tareas diarias. APIs REST de SD-WAN Manager En el centro de la automatización están las APIs REST (Interfaz de Programación de Aplicaciones basada en Transferencia de Estado Representacional), que permiten que los sistemas se comuniquen entre sí a través de HTTP — el mismo protocolo que usa tu navegador para cargar páginas web.\nLa API REST del SD-WAN Manager te permite interactuar programáticamente con tu controlador SD-WAN. En lugar de hacer clic en la interfaz gráfica, puedes enviar solicitudes HTTP para:\nGET obtener información (por ejemplo, listar dispositivos, obtener estadísticas de salud) POST crear nuevas configuraciones PUT actualizar objetos existentes DELETE eliminar configuraciones que ya no necesitas Cada solicitud se dirige a una URL específica e incluye encabezados, autenticación y datos.\nPuedes encontrar la documentación de los endpoints de Cisco aquí.\nTambién puedes acceder a la documentación de la API dentro del producto en:\nhttps://vmanage-ip:port/apidocs\nCódigos de estado HTTP Los códigos de estado HTTP te indican el resultado de tu solicitud a la API. Aquí están los más comunes:\n200 OK – La solicitud fue exitosa. 301 Moved Permanently – El recurso tiene una nueva URL. 400 Bad Request – La solicitud está mal formada. 401 Unauthorized – Necesitas iniciar sesión. 403 Forbidden – No tienes permiso para acceder a este recurso. 404 Not Found – El recurso solicitado no existe. 500 Internal Server Error – Algo falló en el servidor. 503 Service Unavailable – El servidor está sobrecargado o fuera de servicio temporalmente. Esperamos recibir un 200 OK al realizar llamadas a la API.\nAutenticación Generar una ID de sesión (cookie) Antes de interactuar con la API del SD-WAN Manager, necesitas autenticarte — tal como lo harías al iniciar sesión en la interfaz gráfica. Para ello, se debe usar el siguiente endpoint:\nPOST https://{vmanage-ip-address}/j_security_check Content-Type: application/x-www-form-urlencoded HTTP Body: \u0026#34;j_username={admin}\u0026amp;j_password={credential}\u0026#34; Se trata de una operación POST, que requiere el encabezado Content-Type: application/x-www-form-urlencoded y espera un cuerpo con el siguiente formato:\nj_username={admin}\u0026amp;j_password={credential}.\nVamos a probarlo con curl. Ten en cuenta que cuando usamos la opción \u0026ndash;data, curl entiende que debe usar el método POST.\nalex ~ % curl -v -k --location \u0026#39;https://10.1.1.1:443/j_security_check\u0026#39; \\ --header \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; \\ --data-urlencode \u0026#39;j_username=netwithalex\u0026#39; \\ --data-urlencode \u0026#39;j_password=netwithalex\u0026#39; * Trying 10.1.1.1:443... * Connected to 10.1.1.1 (10.1.1.1) port 443 ... * using HTTP/1.x \u0026gt; POST /j_security_check HTTP/1.1 \u0026gt; Host: 10.1.1.1 \u0026gt; User-Agent: curl/8.7.1 \u0026gt; Accept: */* \u0026gt; Content-Type: application/x-www-form-urlencoded ... * upload completely sent off: 45 bytes \u0026lt; HTTP/1.1 200 OK \u0026lt; set-cookie: JSESSIONID=dEzBwsDlx-eMKye1xbXBgT7NZVfXRe1tJQZvkMLH.b387d75e92857dc1e41025f809f43b054a0d0aa8ebf50be8d2fc1aa2f87c90da; path=/; secure; HttpOnly ... \u0026lt; * Connection #0 to host 10.1.1.1 left intact Debemos guardar el valor de set-cookie\nJSESSIONID=dEzBwsDlx-eMKye1xbXBgT7NZVfXRe1tJQZvkMLH\ny utilizarlo a continuación para generar un token.\nObtener un token Un token XSRF (también llamado CSRF o Cross-Site Request Forgery token) es una medida de seguridad que ayuda a proteger una aplicación web contra acciones no autorizadas realizadas por atacantes.\nSe utiliza el siguiente endpoint para obtener un token:\nGET https://{vmanage-ip-address}/dataservice/client/token Content-Type: application/json HTTP Header: \u0026#34;Cookie: JESSIONID={session hash id}\u0026#34; Este token es requerido principalmente para operaciones POST, si estás realizando operaciones GET probablemente no lo necesitarás. Ten esto en cuenta al construir scripts que requieran acciones POST.\nalex ~ % curl -v -k --location \u0026#39;https://10.1.1.1:443/dataservice/client/token\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --header \u0026#39;Cookie: JSESSIONID=dEzBwsDlx-eMKye1xbXBgT7NZVfXRe1tJQZvkMLH.b387d75e92857dc1e41025f809f43b054a0d0aa8ebf50be8d2fc1aa2f87c90da\u0026#39; * Trying 10.1.1.1:443... * Connected to 10.1.1.1 (10.1.1.1) port 443 ... * using HTTP/1.x \u0026gt; GET /dataservice/client/token HTTP/1.1 \u0026gt; Host: 10.1.1.1 \u0026gt; Accept: */* \u0026gt; Content-Type: application/json \u0026gt; Cookie: JSESSIONID=dEzBwsDlx-eMKye1xbXBgT7NZVfXRe1tJQZvkMLH.b387d75e92857dc1e41025f809f43b054a0d0aa8ebf50be8d2fc1aa2f87c90da \u0026lt; HTTP/1.1 200 OK ... \u0026lt; vary: Accept-Encoding \u0026lt; content-type: application/json; charset=UTF-8 \u0026gt; * Connection #0 to host 10.1.1.1 left intact F1FE79CE079240E12A393B73F0EB5445F31BC456322F634EDEF8A9A7D5856A6FC7763D2C80D2253118917910502F20A9A1CA% El token se muestra al final:\nF1FE79CE079240E12A393B73F0EB5445F31BC456322F634EDEF8A9A7D5856A6FC7763D2C80D2253118917910502F20A9A1CA\nCon esto, estás listo para interactuar con el SD-WAN Manager\nEjemplos GET - Obtener la configuración de un dispositivo Vamos a obtener la configuración de un dispositivo con la siguiente llamada\nGET https://{{vmanage-ip}}:{{port}}/dataservice/template/config/running/{deviceId} Content-Type: application/json En este caso,e el deviceId es el chassis number, se puede encontrar en la UI:\nalex ~ % curl -k -v --location \u0026#39;https://10.1.1.1:8443/dataservice/template/config/running/C8K-C0302D69-35A9-4E85-8909-2031A2165FE8\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --header \u0026#39;Cookie: JSESSIONID=dEzBwsDlx-eMKye1xbXBgT7NZVfXRe1tJQZvkMLH.b387d75e92857dc1e41025f809f43b054a0d0aa8ebf50be8d2fc1aa2f87c90da\u0026#39; * Trying 10.1.1.1:8443... * Connected to 10.1.1.1 (10.1.1.1) port 8443 ... * using HTTP/1.x \u0026gt; GET /dataservice/template/config/running/C8K-C0302D69-35A9-4E85-8909-2031A2165FE8 HTTP/1.1 \u0026gt; Host: 10.1.1.1:8443 \u0026gt; User-Agent: curl/8.7.1 \u0026gt; Accept: */* \u0026gt; Content-Type: application/json \u0026gt; Cookie: JSESSIONID=dEzBwsDlx-eMKye1xbXBgT7NZVfXRe1tJQZvkMLH.b387d75e92857dc1e41025f809f43b054a0d0aa8ebf50be8d2fc1aa2f87c90da \u0026gt; ... \u0026lt; vary: Accept-Encoding \u0026lt; content-type: application/json; charset=UTF-8 \u0026lt; server: svcproxy \u0026lt; transfer-encoding: chunked \u0026lt; {\u0026#34;config\u0026#34;:\u0026#34; system\\n system-ip 1.1.200.1\\n overlay-id 1\\n site-id 200\\n no transport-gateway enable\\n port-offset 0\\n control-session-pps 300\\n admin-tech-on-failure\\n sp-organization-name MYSDWAN-LAB123\\n organization-name MYSDWAN-LAB123\\n port-hop\\n track-transport\\n track-default-gateway\\n upgrade-confirm...} La configuración se regresa dentro de las {}\nPOST - Crear un nuevo usuario Vamos a hacer una operación POST sencilla para ver cómo debemos pasar el token.\nUsaremos el siguiente endpoint\nPOST https://{{vmanage-ip}}:{{port}}/dataservice/admin/user Headers: \u0026#34;Content-Type: application/json\u0026#34;, \u0026#34;accept: */*\u0026#34; Payload = { \u0026#34;group\u0026#34;:[ \u0026#34;operator\u0026#34; ], \u0026#34;description\u0026#34;:\u0026#34;Demo User\u0026#34;, \u0026#34;userName\u0026#34;:\u0026#34;apiUser\u0026#34;, \u0026#34;password\u0026#34;:\u0026#34;apiuser\u0026#34;, } Necesitamos especificar el grupo, la descripción, el nombre de usuario y la contraseña.\nHagámoslo con curl\nalex ~ % curl -v -k --location \u0026#39;https://10.1.1.1:8443/dataservice/admin/user\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --header \u0026#39;X-XSRF-TOKEN: F1FE79CE079240E12A393B73F0EB5445F31BC456322F634EDEF8A9A7D5856A6FC7763D2C80D2253118917910502F20A9A1CA\u0026#39; \\ --header \u0026#39;Cookie: JSESSIONID=dEzBwsDlx-eMKye1xbXBgT7NZVfXRe1tJQZvkMLH.b387d75e92857dc1e41025f809f43b054a0d0aa8ebf50be8d2fc1aa2f87c90da\u0026#39; \\ --data \u0026#39;{ \u0026#34;group\u0026#34;:[ \u0026#34;operator\u0026#34; ], \u0026#34;description\u0026#34;:\u0026#34;API User\u0026#34;, \u0026#34;userName\u0026#34;:\u0026#34;apiuser\u0026#34;, \u0026#34;password\u0026#34;:\u0026#34;apiuser\u0026#34; }\u0026#39; * Trying 10.1.1.1:8443... * Connected to 10.1.1.1 (10.1.1.1) port 8443 ... \u0026gt; POST /dataservice/admin/user HTTP/1.1 \u0026gt; Host: 10.1.1.1:8443 \u0026gt; User-Agent: curl/8.7.1 \u0026gt; Accept: */* \u0026gt; Content-Type: application/json \u0026gt; X-XSRF-TOKEN: F1FE79CE079240E12A393B73F0EB5445F31BC456322F634EDEF8A9A7D5856A6FC7763D2C80D2253118917910502F20A9A1CA \u0026gt; Cookie: JSESSIONID=dEzBwsDlx-eMKye1xbXBgT7NZVfXRe1tJQZvkMLH.b387d75e92857dc1e41025f809f43b054a0d0aa8ebf50be8d2fc1aa2f87c90da \u0026gt; Content-Length: 117 \u0026gt; ... * upload completely sent off: 117 bytes \u0026lt; HTTP/1.1 200 OK ... \u0026lt; vary: Accept-Encoding \u0026lt; vmanagerequestid: 45dc1c76-8a00-48e4-80f0-fe9b2f2a894b \u0026lt; x-content-type-options: nosniff \u0026lt; strict-transport-security: max-age=31536000; includeSubDomains \u0026lt; permissions-policy: geolocation=(self), microphone=(), camera=(), fullscreen=(self) \u0026lt; content-type: application/octet-stream; charset=UTF-8 \u0026lt; server: svcproxy \u0026lt; transfer-encoding: chunked \u0026lt; * Connection #0 to host 10.1.1.1 left intact {}% Recibimos un HTTP 200 y una respuesta vacía {}, lo que indica que el usuario fue creado correctamente. Vamos a verificar en la interfaz gráfica (UI).\nEl usuario apiuser se creó correctamente!\nConclusión En este post, cubrimos los conceptos básicos que necesitas para comenzar a trabajar con las REST APIs del SD-WAN Manager — desde entender los códigos de estado HTTP hasta recuperar configuraciones y crear usuarios. Los ejemplos usaron curl intencionalmente para que puedas ver la estructura de las solicitudes, entender los encabezados y aprender cómo trabajar con cookies y el token XSRF.\nEn la siguiente parte, traduciremos estos conceptos a Python y comenzaremos a automatizar tareas del mundo real paso a paso.\n","permalink":"http://localhost:1313/automation-intro-es/","summary":"Aprende los fundamentos de la automatización en SD-WAN y cómo comenzar a usar scripts y APIs para optimizar tus operaciones de red.","title":"Primeros pasos con la automatización en SD-WAN"},{"content":"Introducción En mi post anterior hablé sobre FEC, una técnica para combatir la pérdida de paquetes enviando un paquete de paridad que permite reconstruir los datos perdidos. En esta publicación, exploraremos otra potente funcionalidad de SD-WAN diseñada para enfrentar transportes con pérdida: Packet Duplication. Aunque ambas funciones buscan mejorar la confiabilidad, lo hacen de formas muy diferentes.\nVamos a verlo:\n¿Qué es Packet Duplication? Como su nombre indica, Packet Duplication consiste en enviar paquetes idénticos a través de múltiples rutas de transporte para aumentar la probabilidad de entrega exitosa. Si una ruta experimenta pérdida transitoria o es inherentemente inestable, el paquete duplicado enviado por un segundo transporte más confiable puede compensarlo, manteniendo la experiencia del usuario sin interrupciones.\nVisualmente:\nEl emisor utiliza ambos transportes, bronze y gold, para enviar la información duplicada. La ruta bronze sufre pérdida de paquetes, mientras que la ruta gold entrega todos los paquetes con éxito. El receptor descarta los duplicados y reenvía solo la copia que llega primero al destino, eliminando efectivamente la pérdida desde la perspectiva del usuario, sin importar qué ruta tomó el paquete.\nAntes de duplicar un paquete, el WAN Edge compara su tamaño con el Path Maximum Transmission Unit (PMUT), si la longitud del paquete es menor que el PMUT, este se duplica.\nNota: A partir de la versión 17.15.1a, los paquetes pueden duplicarse incluso si su tamaño es mayor al PMUT, utilizando VRF and Underlay Fragmentation.\nDesde la versión 16.12.1b esta funcionalidad aplica para:\nTráfico IPv4 sobre túneles IPv4. Y a partir de la 17.15.1a se amplía el soporte a:\nTráfico IPv4 sobre túneles IPv6 Tráfico IPv6 sobre túneles IPv4 Tráfico IPv6 sobre túneles IPv6 Consideraciones Aquí algunos puntos clave a tener en cuenta al habilitar Packet Duplication:\nPara que funcione, debe haber al menos dos transportes disponibles; no es una solución viable para sitios con un solo transporte. La cantidad de tráfico se duplica, tenlo en cuenta según la capacidad de tus transportes. El receptor necesita almacenar en búfer y descartar paquetes, lo que añade carga de procesamiento. Debe habilitarse solo para tráfico crítico, considerando los puntos anteriores. Configuración Utilizando Policy Groups, podemos configurar Packet Duplication mediante una data policy que haga match con el tráfico deseado y aplique la acción Loss Correction seleccionando Packet Duplication.\nEsta configuración debe aplicarse en ambas direcciones, por lo que la política completa se ve así:\ndata-policy data_service_Packet-Duplication vpn-list vpn_Corporate_Users sequence 1 match source-ip 172.16.100.0/24 destination-ip 172.16.10.0/24 ! action accept loss-protect pkt-dup loss-protection packet-duplication ! ! sequence 11 match source-ip 172.16.10.0/24 destination-ip 172.16.100.0/24 ! action accept loss-protect pkt-dup loss-protection packet-duplication ! ! default-action accept ! ! ! apply-policy site-list site_10_100 data-policy data_service_Packet-Duplication from-service ! ! Nota: Packet Duplication no es compatible con las siguientes acciones dentro de una data policy:\nlocal tloc remote_tloc Puedes consultar la guía de configuración para más información sobre restricciones y casos de uso.\nVerificación Para asegurar que Packet Duplication está funcionando, hay algunas validaciones que podemos hacer.\nDesde el dispositivo se puede ejecutar:\nLisbon_10-1#show sdwan tunnel statistics pkt-dup Generating output, this might take time, please wait ... tunnel stats gre 21.11.0.2 21.101.0.2 0 0 pktdup-rx 4844 pktdup-rx-other 1 pktdup-rx-this 4844 pktdup-tx 8710 pktdup-tx-other 4693 pktdup-capable true tunnel stats gre 31.11.0.2 31.101.0.2 0 0 pktdup-rx 1 pktdup-rx-other 4844 pktdup-rx-this 1 pktdup-tx 4693 pktdup-tx-other 8710 pktdup-capable true pktdup-rx: paquetes originales recibidos por el túnel primario pktdup-rx-other: paquetes duplicados recibidos por el segundo túnel pktdup-tx: paquetes duplicados enviados por el túnel primario pktdup-tx-other: paquetes duplicados enviados por el túnel secundario pktdup-capable: indica si se realizó intercambio de capacidades con el otro dispositivo Esta misma información está disponible en la sección de Real Time del Manager:\nAdemás, se puede añadir un contador a la política para confirmar que la secuencia está siendo aplicada.\nProbando Packet Duplication En mi laboratorio tengo dos túneles activos entre los dispositivos SD-WAN: uno sobre MPLS y otro sobre Biz-Internet.\nPara probar Packet Duplication, introduciré pérdida de paquetes en el transporte MPLS y ejecutaré una prueba básica de iperf entre dos clientes para observar cómo se comporta.\nEl comando de prueba utilizado fue:\niperf3 -c 172.16.100.11 -u -b 1M -t 20 \u0026ndash;dscp ef\nEste comando inicia una prueba UDP de 20 segundos, con un ancho de banda de 1 Mbps y marcado DSCP EF.\nNota: No me enfoco en el porcentaje exacto de pérdida en MPLS. La idea no es medir cuánto puede recuperar Packet Duplication, sino observar cómo actúa la funcionalidad. En teoría, incluso con una pérdida del 100% en un transporte, el tráfico debería llegar por el otro, siempre y cuando Packet Duplication esté correctamente configurado.\nEl emisor utiliza biz-internet como transporte primario:\nLisbon_10-1#show sdwan policy service-path vpn 10 interface gigabitEthernet 2 source-ip 172.16.10.11 dest-ip 172.16.100.11 protocol 17 dscp 46 all Number of possible next hops: 1 Next Hop: GRE Source: 31.11.0.2 Destination: 31.101.0.2 Local Color: biz-internet Remote Color: biz-internet Remote System IP: 1.1.100.1 MPLS tiene un 80% de pérdida y los resultados de iperf fueron los siguientes:\n[ ID] Interval Transfer Bitrate Jitter Lost/Total Datagrams [ 5] 0.00-20.00 sec 2.38 MBytes 1.00 Mbits/sec 0.000 ms 0/4188 (0%) emisor [ 5] 0.00-20.04 sec 2.38 MBytes 998 Kbits/sec 0.255 ms 0/4188 (0.0%) receiver Vamos a revisar las estadísticas de Packet Duplication tanto en el emisor como en el receptor:\nEmisor\nLisbon_10-1#show sdwan tunnel statistics pkt-dup Generating output, this might take time, please wait ... tunnel stats gre 21.11.0.2 21.101.0.2 0 0 pktdup-rx 14 pktdup-rx-other 0 pktdup-rx-this 14 pktdup-tx 0 pktdup-tx-other 4206 pktdup-capable true tunnel stats gre 31.11.0.2 31.101.0.2 0 0 pktdup-rx 0 pktdup-rx-other 14 pktdup-rx-this 0 pktdup-tx 4206 pktdup-tx-other 0 pktdup-capable true Observa lo siguiente:\nRol Paquetes enviados primario Paquetes duplicados secundario Emisor 4206 4206 Se transmitió exactamente la misma cantidad de paquetes por los transportes MPLS y Biz-Internet.\nReceptor\nMunich_DC100-1#show sdwan tunnel statistics pkt-dup Generating output, this might take time, please wait ... tunnel stats gre 21.101.0.2 21.11.0.2 0 0 pktdup-rx 0 pktdup-rx-other 758 pktdup-rx-this 0 pktdup-tx 14 pktdup-tx-other 0 pktdup-capable true tunnel stats gre 31.101.0.2 31.11.0.2 0 0 pktdup-rx 4206 pktdup-rx-other 0 pktdup-rx-this 758 pktdup-tx 0 pktdup-tx-other 14 pktdup-capable true Rol Paquetes recibidos primario Paquetes recibidos secundario Receptor 4206 758 Como el transporte secundario experimentaba una pérdida severa, solo el 18% de los paquetes fueron recibidos por él. Sin embargo, esto no representó un problema ya que el transporte primario entregó el 100% de los paquetes.\nSi el escenario se invirtiera, es decir, si la ruta primaria sufriera pérdida y la secundaria permaneciera estable, los roles simplemente se intercambiarían. El primario entregaría el 18% y el secundario el 100%, y nuevamente, el usuario final no experimentaría ninguna pérdida de paquetes.\nConclusión Packet Duplication es una funcionalidad simple pero poderosa en Cisco SD-WAN que mejora significativamente la confiabilidad del tráfico. Al enviar paquetes idénticos por múltiples rutas de transporte, garantiza que, incluso si una ruta falla, el rendimiento de la aplicación no se vea afectado.\nAunque conlleva un mayor uso de ancho de banda y procesamiento adicional, puede marcar una gran diferencia para tráfico crítico como voz, video o sesiones remotas, especialmente en entornos con circuitos poco confiables.\nComo con cualquier funcionalidad de SD-WAN, la clave es usarla de manera estratégica: activarla para el tráfico correcto, monitorear los resultados y ajustar las políticas según el comportamiento de tu red. ¿Has utilizado Packet Duplication en producción? Cuéntame tu experiencia en los comentarios o conéctate conmigo en LinkedIn para conversar sobre temas avanzados de SD-WAN.\n","permalink":"http://localhost:1313/appqoe-pkt-dup-es/","summary":"Descubre cómo packet duplication utiliza múltiples transportes para minimizar el riesgo de pérdida de paquetes sobre transportes inestables, manteniendo la calidad de las aplicaciones más importantes para cumplir con los objetivos del negocio.","title":"Serie AppQoe: Packet Duplication"},{"content":"Introducción Ofrecer un rendimiento de aplicación consistente sobre enlaces congestionados o poco confiables es un desafío constante para la mayoría de las redes. Incluso con funciones avanzadas como Enhanced Application-Aware Routing u Optimización TCP, hay condiciones en los enlaces que van más allá de lo que el failover, el balanceo de carga o la optimización pueden resolver.\nAl agregar un mecanismo de recuperación a nivel de paquete, FEC permite que Cisco SD-WAN enmascare la pérdida de paquetes y mantenga el rendimiento de las aplicaciones sin depender de retransmisiones.\nEn este post, exploraremos qué tan efectivo puede ser FEC en un entorno SD-WAN, simulando condiciones con pérdida de paquetes y midiendo las tasas de recuperación.\nSi estás evaluando FEC para tu despliegue o simplemente tienes curiosidad sobre cómo funciona, este artículo te llevará por la teoría y la práctica.\nVamos allá!\nQué es Forward Error Correction (FEC)? Forward Error Correction (FEC) es una técnica que mejora la confiabilidad de la transmisión de datos añadiendo información redundante a los paquetes antes de enviarlos por la red. En lugar de esperar retransmisiones cuando se pierden paquetes, el receptor utiliza esa redundancia para reconstruir los datos faltantes en tiempo real.\nEn la implementación de Cisco SD-WAN, FEC agrupa 4 paquetes de datos y agrega 1 paquete de paridad. Si uno de esos 4 paquetes se pierde en el camino, el receptor puede reconstruirlo utilizando el paquete de paridad mediante una operación XOR.\nVeámoslo en un diagrama:\nEl remitente transmite la información al receptor, pero el paquete 3 se pierde en tránsito. El receptor puede usar el paquete de paridad para reconstruir el paquete 3 y así evitar retransmisiones y retrasos que afectarían la experiencia de las aplicaciones.\nEs importante notar que si se pierden más de 1 paquete, incluyendo el de paridad, no es posible reconstruir la información. El tamaño del bloque es siempre de 4 paquetes de datos + 1 de paridad y no puede modificarse. Un bloque puede contener paquetes de diferentes flujos.\nNota El hecho de que FEC agregue 1 paquete de paridad por cada bloque de 4 incrementa el consumo de ancho de banda.\nHay dos modos de operación:\nAlways: Se aplica FEC a todo el tráfico que haga match a la política, sin importar la cantidad de pérdida de paquetes en el transporte. Adaptive: Permite definir un threshold de pérdida de paquetes antes de empezar a aplicar FEC. Por ejemplo, si hay 2% o más pérdida de paquetes, se debe aplicar FEC al tráfico. El porcentaje de pérdida de paquetes se saca con los paquetes BFD. FEC es especialmente útil en aplicaciones en tiempo real como voz, video o sesiones interactivas, donde esperar retransmisiones provocaría retrasos severos.\nUn punto importante es que FEC opera entre los dispositivos edge de SD-WAN, lo que lo hace completamente transparente para las aplicaciones: no es necesario modificar el comportamiento de clientes o servidores. Sin embargo, solo funciona cuando se utiliza encapsulación IPSec; no está soportado sobre túneles GRE.\nUn detalle crítico de implementación es el tamaño de los paquetes: si los paquetes son demasiado grandes y terminan siendo fragmentados, la capacidad de FEC para reconstruirlos se reduce considerablemente. Para aprovechar al máximo FEC, asegúrate de que el payload se mantenga por debajo del MTU del path MTU para evitar la fragmentación.\nConfiguración Utilizando Policy Groups, podemos configurar FEC a través de política de datos que hagan match al tráfico y apliquen la acción Loss Correction\nEn mi caso, hice match a a todo el tráfico entre 172.16.10.0/24 y 172.16.100.0/24. Nota que se tienen los dos modos de operación: Always y Adaptive\nSi se selecciona FEC Adaptive, el threshold tiene que estar entre 1% y 5% pérdida de paquetes.\nEstá es la configuración completa de mi política:\nvsmart_1# show running-config policy policy data-policy data_all_FEC vpn-list vpn_Corporate_Users sequence 1 match source-ip 172.16.100.0/24 destination-ip 172.16.10.0/24 ! action accept loss-protect fec-always loss-protection forward-error-correction always ! ! sequence 11 match source-ip 172.16.10.0/24 destination-ip 172.16.100.0/24 ! action accept loss-protect fec-always loss-protection forward-error-correction always ! ! default-action accept ! ! lists vpn-list vpn_Corporate_Users vpn 10 ! site-list site_10_100 site-id 10 site-id 100 ! ! apply-policy site-list site_10_100 data-policy data_all_FEC from-service ! ! ! Verificación de FEC No hay muchos comandos relacionados a FEC, pero podemos confirmar que FEC está operando con el siguiente comando:\nMunich_DC100-1#show sdwan tunnel statistics fec tunnel stats ipsec 21.101.0.2 21.11.0.2 12346 12346 fec-rx-data-pkts 16243 fec-rx-parity-pkts 4075 fec-tx-data-pkts 7 fec-tx-parity-pkts 1 fec-reconstruct-pkts 935 fec-capable true fec-dynamic false El fec-reconstruct-pkts indica que se recuperaron 935 paquetes\nNota también que podemos fácilmente ver la cantidad de paquetes de paridad que se enviaron y recibieron siendo aproximadamente 1/4 del total de paquetes de datos enviados/recibidos.\nLa misma información está también disponible a través de la interfaz gráfica del Manager, en la opción de real time\nProbando FEC Vamos a realizar algunas pruebas para ver FEC en acción y analizar la cantidad de pérdida de paquetes que puede recuperar. Mostraré distintos resultados para entender en qué condiciones FEC ofrece mejores beneficios.\nNota existe cierta pérdida de paquetes fuera de los routers SD-WAN que no puedo controlar. Por eso, para obtener resultados más precisos, primero tuve que encontrar una tasa de transmisión con la que obtuviera 0% de pérdida la mayor parte del tiempo en mis resultados con iperf3, y a partir de ahí comencé a introducir pérdida de manera controlada.\niperf -c 172.16.100.11 -u -b 450k -t 30 -l 361 \u0026ndash;dscp ef\nUn ancho de banda de 450 kbps equivale aproximadamente a 5 llamadas VoIP, utilizando un payload de 361 bytes.\nEn este caso, estoy realizando pruebas unidireccionales, pero ten en cuenta que FEC funciona en ambos sentidos.\n% Pérdida Total Paquetes enviados Total Paquetes recibidos Paquetes recuperados % efectivo de pérdida 1 4693 4639 54 0 2 4694 4588 96 0,24 3 4693 4558 111 0,58 4 4694 4524 147 0,51 5 4693 4448 195 0,68 6 4693 4401 231 1,3 7 4693 4374 238 1,8 8 4693 4331 283 1,8 9 4693 4292 297 2,2 10 4693 4215 304 3,8 12 4693 4122 348 3,8 15 4695 3941 382 8 18 4696 3815 356 11 20 4696 3731 368 13 Veamos unas gráficas interesantes:\nA medida que aumenta la pérdida de paquetes, también crece el número de paquetes recuperados, hasta cierto punto. Esto es esperable: FEC agrega redundancia, y cuanto más se pierde, más se necesita recuperar. Sin embargo, esta capacidad tiene un límite natural: si se pierden dos o más paquetes dentro del mismo bloque FEC —incluyendo el paquete de paridad— la recuperación ya no es posible y la pérdida efectiva comienza a aumentar.\nTambién es importante destacar que FEC es una función utiliza muchos recursos, por lo que se recomienda activarla solo para tráfico crítico y, preferentemente, en combinación con un threshold de pérdida de paquetes, en lugar de mantenerla activa permanentemente.\nAunque este laboratorio no replica a la perfección un entorno de producción, los resultados son bastante reveladores. FEC logró recuperar prácticamente todos los paquetes perdidos con hasta un 5% de pérdida introducida, y continuó recuperando cerca del 70% de los paquetes a aproximadamente 9% de pérdida. A partir de ahí, la eficiencia de recuperación empieza a disminuir. Dicho esto, no es común ver pérdidas constantes superiores al 10% en enlaces WAN de producción, y menos aún en ambas direcciones.\nPor último, aunque las pruebas fueron unidireccionales, vale la pena mencionar que FEC puede aplicarse de forma independiente en cada dirección. Esto significa que, con una implementación bien ajustada, se podría tolerar cerca de un 5% de pérdida de paquetes por dirección sin afectar significativamente el rendimiento.\nConclusion Forward Error Correction (FEC) es una técnica proactiva que agrega redundancia antes de la transmisión de paquetes, permitiendo que el receptor recupere ciertas pérdidas sin necesidad de retransmisiones. Esto la hace especialmente valiosa para aplicaciones en tiempo real como voz o video, donde esperar retransmisiones generaría retrasos perjudiciales.\nRecuerda que habilitar FEC viene con un costo: introduce carga adicional. El edge de SD-WAN que recibe los paquetes necesita usar capacidad de procesamiento adicional para reconstruir los que se perdieron. Por eso, es recomendable activarlo solo para tráfico crítico y, en lo posible, hacerlo condicionado a un threshold de pérdida de paquetes.\nFEC no reemplaza la necesidad de corregir enlaces de red defectuosos. Más bien, actúa como una capa de mitigación inteligente que ayuda a suavizar pérdidas moderadas o transitorias, manteniendo una experiencia de usuario consistente incluso cuando la red no es perfecta.\nEn resumen, cuando se implementa correctamente, FEC puede ser una herramienta muy poderosa en tu arquitectura SD-WAN, ayudando a garantizar un rendimiento de aplicaciones constante sobre redes imperfectas.\n💭 ¿Qué opinas sobre el uso de Forward Error Correction en SD-WAN? ¿Lo has utilizado antes? ¿Tienes dudas sobre cómo funciona o cuándo activarlo?\nDéjame tus comentarios, preguntas o experiencias. Me encantaría saber cómo están abordando esta función en sus despliegues reales. ¡Aprendamos entre todos!\n","permalink":"http://localhost:1313/appqoe-fec-es/","summary":"Aprende cómo funciona Forward Error Correction (FEC) en Cisco SD-WAN para mejorar el rendimiento de las aplicaciones en enlaces con pérdida de paquetes. Explora casos de uso, configuración y resultados de pruebas.","title":"Serie AppQoe: Forward Error Correction (FEC)"},{"content":"Introducción Cuando implementas un nuevo sitio remoto, quieres que el proceso sea lo más sencillo posible. No quieres enviar el dispositivo a una ubicación intermedia solo para precargarle una configuración, y luego volver a enviarlo a su destino final. Tampoco quieres tener que viajar al sitio, conectar un cable de consola y configurar manualmente cada dispositivo. Ahora imagina multiplicar ese esfuerzo por docenas o cientos de sitios 🤯.\nPara resolver este desafío, Cisco creó un proceso de incorporación automatizado llamado Plug and Play (PnP) o Zero Touch Provisioning (ZTP). La idea es simple: un router se enciende, obtiene una dirección IP, localiza su overlay de SD-WAN, se conecta a los controladores y descarga su configuración—todo esto sin intervención humana más allá de conectarlo a la corriente y la red.\nUn paso clave en este proceso es ayudar al router a descubrir el overlay de SD-WAN. Esto se puede lograr a través de la nube de Cisco o, en entornos aislados (air-gapped), alojando tu propio servidor ZTP On-Prem. Hoy vamos a explorar esta segunda opción.\nFuncionalidad PnP/ZTP El proceso en la imagen describe lo que hace un router SD-WAN al iniciar sin configuración:\nNota este proceso está disponible únicamente en plataformas físicas.\nEl dominio ZTP está definido en el servidor DHCP, por ejemplo, si el nombre de dominio es cisco.com, el router intentará resolver ztp.cisco.com. Para más información puedes consultar la siguiente documentación de Cisco\nConfiguración Necesitamos completar las siguientes tareas para utilizar ZTP on prem\nAgregar y configurar el servidor ZTP Cargar la lista de equipo al servidor ZTP Preparar la configuración del equipo en el Manager Configurar un servidor DHCP y DNS Lanzar el proceso de PnP Agregar y configurar el servidor ZTP El servidor ZTP utiliza la misma imagen que un Validator regular. Sigue el proceso habitual para levantar una nueva máquina virtual con conectividad hacia el Manager.\nLa siguiente es la configuración mínima necesaria:\nvbond# show run system system host-name ztp-server system-ip 10.10.10.194 site-id 5 sp-organization-name SDWAN-LAB123 organization-name SDWAN-LAB123 vbond 192.168.200.2 local ztp-server vpn 0 interface eth0 ip dhcp-client ipv6 dhcp-client no shutdown ! interface ge0/0 ip address 192.168.200.3/24 no shutdown ! ip route 0.0.0.0/0 192.168.200.253 ! Nota el sufijo ztp-server, esto indicará al dispositivo que actuará como servidor ZTP.\nDesde el Manager, agrega el servidor ZTP a la lista de Controladores:\nDependiendo del método de autenticación del Controlador, genera y firma el CSR.\nSi estás utilizando certificados Enterprise, necesitarás instalar el certificado raíz y el certificado firmado.\nPor ejemplo:\nztp-server# request root-cert-chain install home/admin/root-ca.crt ztp-server# request certificate install home/admin/ztp.crt Nota: El servidor ZTP no tiene ninguna conexión de control con el Manager ni con ningún otro controlador.\nCargar la lista de equipo al servidor ZTP Ahora que el servidor ZTP está instalado, es necesario cargar la lista de equipo que se conectarán a él.\nLa manera más sencilla es obtener el archivo serialFile.viptela desde el portal PnP y copiarlo localmente en el equipo.\nztp-server:~$ ls -l | grep serial -rw-r--r-- 1 admin admin 2364 Apr 24 21:41 serialFile.viptela Luego es necesario ejecutar el siguiente comando\nztp-server# request device-upload chassis-file home/admin/serialFile.viptela Uploading chassis numbers via VPN 0 Copying ... /home/admin/serialFile.viptela via VPN 0 file: /tmp/tmp.CbUWf8GnSN/viptela_serial_file PnP Verifying public key received from PnP against production root cert is_public_key_ok against production root ca: OK Signature verified for viptela_serial_file final file: /tmp/tmp.CbUWf8GnSN/viptela_serial_file Signature verification Suceeded. Success: Serial file is /tmp/tmp.CbUWf8GnSN/viptela_serial_file INFO: Input File specified was \u0026#39;/usr/share/viptela/chassis_numbers.tmp\u0026#39; INFO: # of complete chassis entries written: 12 Json to CSV conversion succeeded! Successfully loaded the chassis numbers file to the database. Para verificar que la lista se cargó correctamente\nztp-server# show ztp entries ROOT VBOND ORGANIZATION CERT INDEX CHASSIS NUMBER SERIAL NUMBER VALIDITY VBOND IP PORT NAME PATH ----------------------------------------------------------------------------------------------------------------------------------------------------------- ... 23 ASR1001-HX-XXXXXXXXXXX XXXXXXXX valid 192.168.200.1 12346 SDWAN-LAB123 default Preparar la configuración del equipo en el Manager Para logar esto, utilizaré un Configuration Group, pero se puede logar con Templates igualmente\nCreo la configuración y la envío al equipo. Como está offline, la tarea queda como \u0026ldquo;Scheduled\u0026rdquo;\nConfigurar un servidor DHCP y DNS Para hacerlo sencillo, configuro un switch intermedio como servidor DHCP y DNS con la siguiente configuración:\nip dhcp pool ASR vrf MPLS network 192.168.11.4 255.255.255.252 default-router 192.168.11.6 dns-server 192.168.11.6 domain-name cisco.com ip host vrf MPLS ztp.cisco.com 192.168.200.3 ip host vrf MPLS devicehelper.cisco.com 192.168.200.3 Ok, estamos listos para lanzar el proceso PnP\nLanzar el proceso de PnP Para activar el proceso de PnP, el dispositivo debe tener una configuración en blanco. Voy a usar el siguiente comando para restablecer la configuración y activar el proceso.\nRouter#request platform software sdwan config reset %WARNING: Bootstrap file doesn\u0026#39;t exist and absence of it can cause loss of connectivity to the controller. For saving bootstrap config, use: request platform software sdwan bootstrap-config save Proceed to reset anyway? [confirm] Backup of running config is saved under /bootflash/sdwan/backup.cfg Config reset requested from a console session. Waiting for up to 60 seconds for IOS to initiate reload or report failure. IOS return status: \u0026#34;cfgreset_proceed\u0026#34; Config reset is raised successfully, device will reload shortly. Para ver los siguientes logs es necesario acceso por consola:\nEl equipo arranca y comienza el proceso de PnP\n*May 4 04:18:42.659: %PNP-6-PNP_DISCOVERY_STARTED: PnP Discovery started El equipo obtiene una dirección ip, router por defecto y un nombre de dominio\nAutoinstall trying DHCPv4 on GigabitEthernet0/0/0,GigabitEthernet0/0/1,GigabitEthernet0/0/2,GigabitEthernet0 ... *May 4 04:19:44.999: %PKI-2-NON_AUTHORITATIVE_CLOCK: PKI functions can not be initialized until an authoritative time source, like NTP, can be obtained. Acquired IPv4 address 192.168.11.5 on Interface GigabitEthernet0/0/1 Received following DHCPv4 options: domain-name : cisco.com dns-server-ip : 192.168.11.6 El equipo intenta resolver los dominos y es redirigido a ztp.cisco.com\n*May 4 04:20:08.694: %PNP-3-PNP_CCO_SERVER_IP_UNRESOLVED: CCO server (devicehelper.cisco.com.) can\u0026#39;t be resolved (1/5) by (pid=619, pname=PnP Agent Discovery, time=04:20:08 UTC Sun May 4 2025) ... *May 4 04:20:20.696: %IOSXE_SDWAN_CONFIG-5-PNP_REDIRECT: PnP Redirect Msg: Org name \u0026#34;\u0026#34; Host \u0026#34;ztp.cisco.com.\u0026#34; port 0 intf GigabitEthernet0/0/1 *May 4 04:20:42.010: %PNP-6-PNP_REDIRECTION_DONE: PnP Redirection done (1) by (pid=619, pname=PnP Agent Discovery) *May 4 04:20:42.010: %PNP-6-PNP_SDWAN_STARTED: PnP SDWAN started (1) via (pnp-sdwan-vbond-ztp-discovery) by (pid=619, pname=PnP Agent Discovery) *May 4 04:20:42.811: %PNP-6-PNP_DISCOVERY_DONE: PnP Discovery done successfully (PnP-VBOND-ONPREM-ZTP-IPV4) profile (pnp-zero-touch) Podemos confirmar que la resolución DNA para ztp.cisco.com ocurrió de manera correctamente\nASR1K-2#show pnp trace | i ztp [05/04/25 04:20:10.695 UTC B7 619] 1: VBOND_ONPRIME_ZTP hostname ztp.cisco.com. resolved to 192.168.11.6 on interface GigabitEthernet0/0/1 [05/04/25 04:20:10.695 UTC B8 619] host_name is ztp.cisco.com. vbond_ipv4_address is 192.168.11.6, interface is GigabitEthernet0/0/1 Enseguida, el eouter se conecta al servidor ZTP y es redirigido al Validator\n*May 4 04:21:17.991: %Cisco-SDWAN-Router-vdaemon-6-INFO-1400002: Notification: 5/4/2025 4:21:17 control-connection-state-change severity-level:major host-name:\u0026#34;Router\u0026#34; system-ip::: personality:vedge peer-type:vbond peer-system-ip::: peer-vmanage-system-ip:0.0.0.0 public-ip:192.168.200.3 public-port:12346 src-color:default remote-color:default uptime:\u0026#34;0:00:00:00\u0026#34; new-state:up ... *May 4 04:21:19.242: %Cisco-SDWAN-Router-vdaemon-6-INFO-1400002: Notification: 5/4/2025 4:21:19 org-name-change severity-level:minor host-name:\u0026#34;Router\u0026#34; system-ip::: old-organization-name:\u0026#34;\u0026#34; new-organization-name:\u0026#34;SDWAN-LAB123\u0026#34; *May 4 04:21:21.597: %Cisco-SDWAN-Router-vdaemon-6-INFO-1400002: Notification: 5/4/2025 4:21:21 control-connection-state-change severity-level:major host-name:\u0026#34;Router\u0026#34; system-ip::: personality:vedge peer-type:vbond peer-system-ip::: peer-vmanage-system-ip:0.0.0.0 public-ip:192.168.200.1 public-port:12346 src-color:default remote-color:default uptime:\u0026#34;0:00:00:00\u0026#34; new-state:up Eventualmente, el equipo se conecta al MAnager y al Controller y obtiene su configuración\n*May 4 04:21:23.924: %Cisco-SDWAN-Router-vdaemon-6-INFO-1400002: Notification: 5/4/2025 4:21:23 control-connection-state-change severity-level:major host-name:\u0026#34;Router\u0026#34; system-ip::: personality:vedge peer-type:vmanage peer-system-ip:10.10.10.2 peer-vmanage-system-ip:0.0.0.0 public-ip:192.168.100.1 public-port:12746 src-color:default remote-color:biz-internet uptime:\u0026#34;0:00:00:00\u0026#34; new-state:up *May 4 04:21:24.299: %Cisco-SDWAN-CSS-SDWAN-POD1-ASR1K-2-OMPD-5-NTCE-400003: Operational state changed to UP *May 4 04:21:43.981: %DMI-5-AUTH_PASSED: R0/0: dmiauthd: User \u0026#39;vmanage-admin\u0026#39; authenticated successfully from 10.10.10.2:42962 for netconf over ssh. ASR1K-2#show sdwan control connections | i up vsmart dtls 10.10.10.3 5 1 192.168.100.2 12346 192.168.100.2 12346 SDWAN-LAB123 mpls No up 0:02:02:51 0 vbond dtls 0.0.0.0 0 0 192.168.200.1 12346 192.168.200.1 12346 SDWAN-LAB123 mpls - up 0:02:02:54 0 vmanage dtls 10.10.10.2 5 0 192.168.100.1 12946 192.168.100.1 12946 SDWAN-LAB123 mpls No up 0:02:02:49 0 Conclusion El servidor ZTP On-Prem amplía la capacidad de incorporar dispositivos físicos en aquellas redes donde el acceso a internet está restringido.\nAutomatizar la incorporación de routers con ZTP On-Prem es una excelente alternativa para las organizaciones que necesitan tener control total sobre su proceso de aprovisionamiento o que operan en entornos aislados (air-gapped). Al replicar localmente el proceso de Plug and Play, eliminas la necesidad de configuraciones manuales en sitios remotos mientras mantienes aislados los entornos sensibles.\nCon la configuración adecuada, incorporar nuevos sitios se convierte en un proceso sencillo y repetible que ahorra tiempo valioso, reduce errores humanos y escala las implementaciones de SD-WAN.\n👉 ¿Te interesa configurar ZTP On-Prem para tu red? Déjame un comentario o contáctame; ¡me encantaría ayudarte o responder tus preguntas!\n","permalink":"http://localhost:1313/ztp-on-prem-es/","summary":"Plug and Play (PnP) te permite agregar dispositivos SD-WAN automáticamente a través de la nube de Cisco. Esta publicación explica cómo lograr Zero-Touch Provisioning (ZTP) en un entorno aislado y local (on-premises).","title":"Cisco SD-WAN ZTP On-Prem: Automatizando el onboarding de los routers"},{"content":"Introduction ¿Alguna vez has usado una aplicación que se siente demasiado lenta? Tal vez las videollamadas se congelan o un portal web tarda una eternidad en cargar. Estos (y otros) son signos de que tu red WAN podría estar teniendo problemas.\n¿La buena noticia? Cisco SD-WAN incluye un conjunto de tecnologías diseñadas para mejorar el rendimiento en enlaces poco confiables o con alta latencia. En esta serie, desglosaremos tres funciones clave que pueden mejorar significativamente la experiencia de las aplicaciones en tu red: _Optimización TCP, Forward Error Correction (FEC) y Duplicación de Paquetes_.\nEn este primer post, exploraremos la Optimización TCP: cómo funciona, cuándo utilizarla y por qué puede marcar una gran diferencia para tus usuarios, especialmente en conexiones con alta latencia.\nQué es la optimización TCP? El objetivo de la Optimización TCP es ajustar finamente las conexiones TCP para mejorar su rendimiento. Esto es especialmente útil cuando hay enlaces con alta latencia involucrados.\nLos routers SD-WAN actuarán como proxies, lo que significa que interceptarán las conexiones TCP y las ajustarán para obtener un mejor desempeño. Veamos un ejemplo visual.\nSin la optimización TCP, el cliente y el servidor establecerán una sesión TCP directamente entre ellos.\nCuando se utiliza la Optimización TCP, el Router 1 interceptará y terminará la conexión TCP proveniente del cliente y establecerá una sesión TCP optimizada con el Router 2. De igual manera, el Router 2 creará una sesión TCP con el servidor.\nNota Todo este proceso es transparente para el cliente y el servidor, y los datos serán almacenados en caché en los routers para mantener activas las sesiones.\nLos equipos IOS-XE SD-WAN usan el algoritmo BBR el cual utiliza información sobre RTT (Round Trip Time) and ancho de banda disponible para optimizar la conexión. Si te gustaría profundizar en el tema te recomiendo ver este vídeo de Neal Cardwell.\nLa implementación actual de Optimization TCP tiene definidos dos roles:\nController Node: Equipo que intercepta y distribuye el trafico al Service Node. Service Node: Motores de optimización para la aceleración del tráfico. En un escenario de la vida real, la recomendación es tener servicios de optimización en las sedes y en los Data Centers. Hay requerimientos diferentes basados en el volumen de tráfico que los equipos van a procesar. Te sugiero leer la Documentación de Cisco para informarte sobre los requerimientos de hardware y más.\nEn las sedes pequeñas, es común utilizar un Integrated Service Node, es decir, un solo equipo puede interceptar, distribuir y optimizar el tráfico. Por otro lado, en el Data Cetner, un cluster de External Service Nodes es necesario para para lograr un mayor rendimiento y distribuir volúmenes más altos de tráfico entre los miembros del cluster.\nEn general, la Optimización TCP es un proceso intensivo para los dispositivos, por lo que es crucial confirmar los requisitos de la plataforma. Por ejemplo, mi entorno de demostración cuenta con dos Catalyst 8000V con 8 CPUs y 16 GB de RAM, requisitos adecuados para una implementación pequeña.\nVeamos en la práctica qué efecto tiene la optimización TCP en el tráfico. Para demostrarlo, voy a tomar una captura de paquetes en el lado WAN con y sin optimización.\nWindow Scaling Sin Optimización Veamos como se comporta el window scalind sin optimización\nNota como el window size se mantuvo estable alrededor de 1,000,000 Bytes después de aproximadamente 5 segundos\nWindow Scaling Con Optimización Veamos la misma información pero con la optimización activa.\nNota como el window size estuvo en constante cambio a lo largo de la sesión, recuperándose rápida y agresivamente después de caer.\nPor qué es tan importante este parámetro? Le pedí a ChatGPT que lo explicará de una manera simple y concisa.\nLa ampliación de ventana (window scaling) es crucial en redes con alta latencia o gran ancho de banda, ya que permite que TCP utilice una ventana de recepción más grande, lo cual impacta directamente en la cantidad de bytes in flight (datos no confirmados) que el emisor puede enviar. Sin esta opción, el tamaño máximo de la ventana es de 65,535 bytes —demasiado pequeño para enlaces de alta velocidad— lo que lleva a una infrautilización del enlace. Con window scaling, la ventana puede crecer hasta varios gigabytes, permitiendo al emisor mantener más datos \u0026ldquo;en vuelo\u0026rdquo; y sostener un alto rendimiento incluso con demoras.\nEn resumen, la sesión TCP se divide en tres segmentos, donde los routers que optimizan anuncian una mayor ampliación de ventana (window scaling) y gestionan las conexiones con el cliente y el servidor. El tráfico ahora se rige por el algoritmo BBR para maximizar el rendimiento.\nConfiguración Para configurar esta funcionalidad, se pueden utilizar Feature Templates o Configuration Groups (con la versión 20.15 o superior). En mi caso utilizaré Configuration Groups y voy a tener Internal Service Nodes en ambos lados\nPara empezar, añado la funcionalidad \u0026ldquo;App QoE\u0026rdquo; en el Service Profile con la siguiente configuración:\nService Node para hacer aceleración Forwarder para actuar como Controller Node Esta es la configuración que se enviará al equipo:\ninterface VirtualPortGroup2 no shutdown ip address 192.168.2.1 255.255.255.0 service-insertion appqoe ! service-insertion appnav-controller-group appqoe ACG-APPQOE appnav-controller 192.168.2.1 ! service-insertion service-node-group appqoe SNG-APPQOE service-node 192.168.2.2 ! service-insertion service-context appqoe/1 appnav-controller-group ACG-APPQOE service-node-group SNG-APPQOE cluster-type integrated-service-node enable vrf global ! El estatus debe ser \u0026ldquo;Running\u0026rdquo;\nLisbon_10-1#show sdwan appqoe tcpopt status ========================================================== TCP-OPT Status ========================================================== Status ------ TCP OPT Operational State : RUNNING TCP Proxy Operational State : RUNNING A continuación, creo una política de datos muy sencilla para hacer match del tráfico entre el cliente y el servidor y selecciono la acción de AppQoE Optimization y selecciono la casilla de TCP Optimization.\nvsmart_1# show running-config policy policy data-policy _VPN_10_AppQoE vpn-list VPN_10 sequence 1 match source-data-prefix-list BR10_172_16_10_0 destination-data-prefix-list DC_100_172_16_100_0 ! action accept tcp-optimization service-node-group SNG-APPQOE ! ! sequence 11 match source-data-prefix-list DC_100_172_16_100_0 destination-data-prefix-list BR10_172_16_10_0 ! action accept tcp-optimization service-node-group SNG-APPQOE ! ! default-action accept ! ! Nota la dirección en la cual se debe aplicar la política es ALL\nvsmart_1# show running-config apply-policy apply-policy site-list BR_10 data-policy _VPN_10_AppQoE all ! site-list DC_100 data-policy _VPN_10_AppQoE all ! ! Verificando la Optimización TCP Para verificar que el tráfico está siendo optimizado, podemos habilitar On-Demand Troubleshooting y seleccionar un periodo de tiempo.\nTambién, con la información en tiempo real podemos sacar la lista de flows que están siendo optimizados\nLa columna de Services indica que la Optimización TCP se está aplicando a esos flujos\nProbando el rendimiento de la Optimization TCP Para evaluar el impacto de la Optimización TCP, ejecuté pruebas con iperf utilizando diferentes valores de latencia para observar en qué condiciones la función ofrece mayores beneficios. Aunque no se trata de un entorno de laboratorio profesional, proporciona información valiosa sobre cómo se comporta la optimización en la práctica.\nNota Mi tráfico de iperf no está encriptado. No es posible optimizar tráfico encriptado sin antes desencriptarlo a través de TLS/SSL Decryption\nAlgunos detalles adicionales:\nEl ancho de banda está topado a 250 Mbps en los routers. Utilizo 4 flujos en paralelo, cada uno simulando una descarga de 100 MB: iperf -c 172.16.100.11 -n 100MB -P 4 -i 15 -R\nPara mantener consistencia, corro cada prueba 5 veces, descarto el resultado más alto y más bajo y al final saco un promedio de los tres restantes.\nLa siguiente tabla muestra los resultados obtenidos:\nDelay TCP Opt BW (Mbps) Time (s) 0 Disabled 248 ~ 13 0 Enabled 121,6 ~ 27 50 Disabled 99,7 ~ 33 50 Enabled 124 ~ 26 100 Disabled 71 ~ 46 100 Enabled 131 ~ 25 150 Disabled 66 ~ 49 150 Enabled 125 ~ 26 200 Disabled 59 ~ 56 200 Enabled 131 ~ 25 250 Disabled 63 ~ 52 250 Enabled 126 ~ 26 Aquí hay una representación visual de la misma información\nLo que puedo concluir de los resultados:\nCon un delay de 0 ms, la optimización reduce el rendimiento (121 Mbps frente a 248 Mbps), debido al procesamiento que introduce esta funcionalidad.\nA medida que aumenta el delay, la optimización mejora el rendimiento y reduce el tiempo de transferencia, lo cual ya es evidente a partir de un delay de 50 ms.\nEl rendimiento disminuye significativamente sin optimización TCP. El ancho de banda baja de 248 Mbps a 0 ms a ~59–63 Mbps con retrasos de 200–250 ms. El tiempo también aumenta proporcionalmente.\nEl rendimiento se mantiene estable a través de diferentes valores de delay con optimización TCP. El rendimiento se mantiene alrededor de 125–131 Mbps incluso con retrasos altos. El tiempo de transferencia también es consistente, alrededor de ~26s.\nConclusión La optimización TCP es altamente efectiva para mitigar el impacto de la latencia en el rendimiento de TCP. Si bien introduce algo de sobrecarga en condiciones de baja latencia, sus beneficios se vuelven más evidentes a medida que aumenta el retraso. En escenarios con retrasos de 100 ms o más, la optimización puede ayudar a duplicar el rendimiento y reducir el tiempo de transferencia. Si estás pensando en habilitarla, ten en cuenta que, dependiendo del modelo de router, obtendrás rendimientos diferentes.\nAdemás, esta función no debe habilitarse para todo el tráfico, sino que debe activarse para una aplicación específica o un conjunto de aplicaciones que necesiten aceleración. Finalmente, esta función ofrece mayores beneficios en líneas intercontinentales, transportes satelitales o enlaces de alta latencia similares.\n¡Espero que esta publicación haya sido útil y nos vemos en la próxima!\n","permalink":"http://localhost:1313/appqoe-opt-tcp/","summary":"Descubre cómo SD-WAN mejora el rendimiento de TCP. Conoce las principales técnicas de optimización que aumentan el rendimiento de las aplicaciones y mejoran la experiencia del usuario.","title":"Serie AppQoE: Optimización TCP"},{"content":"Introducción La seguridad siempre ha sido una prioridad para las organizaciones, pero proteger cada ángulo de la red sigue siendo un desafío. Al mismo tiempo, garantizar una experiencia óptima para aplicaciones y usuarios es igualmente importante. Las organizaciones a menudo han tenido que elegir entre soluciones centradas en la seguridad o en el rendimiento, lo que aumenta la complejidad de gestión y operación.\nCisco Secure Access es una solución robusta que aborda estos desafíos. Ofrece una seguridad de primer nivel al integrar tecnologías avanzadas y controles de acceso. Esto significa que los usuarios pueden obtener una conectividad segura y directa desde los sitios SD-WAN hacia internet y aplicaciones SaaS.\nVeamos cómo funciona.\nSD-WAN se encuentra con Secure Access A partir de la versión 20.13/17.13 de SD-WAN, la integración con Secure Access está disponible de forma nativa.\nCon esta integración, se pueden establecer túneles IPSec automáticos hacia los Data Centers primarios y secundarios de Secure Access que estén mas cercanos a la ubicación de tu router, garantizando un rendimiento óptimo. Estos túneles enrutan el tráfico mientras aplican las políticas de seguridad de tu organización, proporcionando una forma sencilla y potente de mejorar tanto la seguridad como la conectividad a internet.\nEn el centro de Secure Access están los Network Tunnel Groups (NTGs), que gestionan las conexiones IPSec. Cada NTG incluye un Data Center de Secure Access primario y uno secundario. Aunque no es obligatorio configurar túneles hacia ambos, es altamente recomendable para garantizar alta disponibilidad en caso de que uno tenga algún problema\nEs posible configurar hasta 16 túneles, 8 activos y 8 backups, lo que permite hacer load balance entre los túneles activos para aumentar el ancho de banda disponible.\nPara establecer los túneles automáticamente, el Manager y el router necesitan conectividad a Internet y DNS habilitado. Esto permite que el router determine su propia dirección IP pública, se la comunique al Manager y se le asignen los Data Centers SSE primario y secundario más cercanos.\nUna vez que se establecen los túneles, el tráfico que los atraviesa está asegurado por las funcionalidades de seguridad principales de SSE FWAAS, CASB, ZTNA y SWG y más.\nPasos de configuración Crear clave API Para comenzar, en SSE crea una clave API para que el Manager se conecte de forma segura. Asegúrate de que se otorguen los siguientes privilegios:\nDeployment / Network Tunnel Group - Read/Write Deployment / Tunnels - Read/Write Deployment / Regions - Read Obtendrás el API Key y Key Secret\nIngrese credenciales en el Manager A continuación, ingresa la información en el Manager en Administration \u0026gt; Settings \u0026gt; Cloud Credentials \u0026gt; SSE\nCrear política SSE en el Manager Crea una nueva política de SSE. Aquí es donde ingresas la información sobre los túneles IPSec.\nDesde Configuration \u0026gt; Policy Groups \u0026gt; Secure Service Edge\nLo siguiente es lo mínimo que necesitas:\nTracker IP - Se utiliza para confirmar que el túnel está arriba. Tunnel - Al menos 1 túnel. Ingresa el nombre tunnel name, source interface y selecciona primary/secondary DC Interface Pair - Especifica los túneles Active y Backup. Selecciona none como backup si solo hay 1 túnel. Nota Puedes seleccionar la región SSE de tu preferencia o usar auto para seleccionarla automáticamente.\nLuego, crea un Policy Group, asocia un dispositivo y agrega la política de SSE\nRedirigir el tráfico del lado del servicio Ahora, necesitamos redirigir el tráfico de los usuarios al túnel. Hay dos opciones:\nRuta de servicio de tipo SSE En la funcionalidad service vpn, agrega una ruta service con el proveedor de SSE Cisco-Secure Access\nEsto se agregará de la siguiente manera:\nip sdwan route vrf 10 0.0.0.0/0 service sse Cisco-Secure-Access Puede seleccionar qué tráfico se reenvía a SSE modificando la ruta, sin embargo, este enfoque no es tan flexible comparado con la segunda opción.\nData Policy Las Data Policies proporcionan más flexibilidad para redirigir el tráfico. No solo podemos hacer match al destino, sino también a otros elementos útiles, como source, aplicaciones y más.\nEste ejemplo hace match a todo el tráfico que proviene de mis usuarios en la VPN 10 y establece una acción de |Secure Service Edge. Observa que podemos habilitar la opción de Fallback to Routing en caso de que los túneles no estén disponibles.\nValidaciones en el Manager Verifica el estado del túnel desde Monitor \u0026gt; Tunnels \u0026gt; SIG/SSE Tunnels\nLos logs están disponibles y son útiles para determinar si hay algún problema al establecer los túneles\nValidaciones del usuario Para verificar que los usuarios están utilizando SSE, tenemos un par de opciones\nLa primera es visitar policy.test.sse.com, si el tráfico se redirige correctamente, verás algo como esto:\nEn el lado de SSE, hay una política que niega el tráfico a las aplicaciones de redes sociales, veamos el resultado de tratar de acceder a x.com\nPor último, acceder a welcome.umbrella.com nos hará saber si el usuario está protegido\nConsideraciones adicionales ECMP está disponible cuando múltiples túneles están activos. Unequal Load Balance se puede lograr mediante la asignación de peso a los túneles IPSEC. El fallback to routing se activa cuando los túneles no están disponibles Los trackers son personalizables - Se puede definir una URL y thresholds personalizados para cumplir con los SLA deseados Mecanismo de dampening incorporado en túneles para evitar flapping entre túneles. La redirección de la política de datos proporciona una mayor flexibilidad que las rutas estáticas Usa interfaces Loopback para crear múltiples túneles hacia SSE ¡Espero que hayas aprendido algo útil! Nos vemos en el siguiente 👋\n","permalink":"http://localhost:1313/sdwan-sse-integracion/","summary":"Descubre cómo Cisco SD-WAN y Cisco Secure Access trabajan juntos para mejorar el rendimiento y la seguridad de los usuarios en internet.","title":"Asegurando el borde con Cisco SD-WAN y Secure Access"},{"content":"Introducción En mi anterior serie de publicaciones, exploré Application Aware Routing (AAR) en profundidad, una tecnología clave en SD-WAN que dirige el tráfico sobre los transportes con mejor rendimiento. Si bien AAR ha sido una capacidad fundamental durante años, la evolución de las redes trajo nuevas ideas para mejorar su efectividad. Esto condujo a la introducción de Enhanced Application Aware Routing (EAAR).\nLimitaciones de AAR Antes de sumergirnos en EAAR, entendamos por qué fue creado. 🤓\nLa implementación actual de AAR mide la calidad del transporte utilizando BFD, enviando probes a un intervalo definido (1s por defecto). La pérdida, la latencia y jitter se derivan de esos paquetes y estos valores se colocan en cubetas que van rotando para calcular una métrica promedio que representa la salud del túnel. Este proceso generalmente toma entre 10 y 60 minutos y con algunos ajustes de configuración es posible lograr tiempos de 2 a 10 minutos.\nPara aquellas redes que requieren una detección más rápida, surgen algunos desafíos:\nBajar el intervalo de hello a menos de 1 segundo afecta la escala de túneles del dispositivo Bajar el multiplicador de BFD y el poll interval podrían conducir a falsos positivos, moviendo el tráfico incluso con condiciones de red transitorias. Cambio constante del tráfico de un lado a otro, no hay un mecanismo para determinar si un transporte es estable nuevamente después de un evento de degradación de la red. Enhanced AAR Entonces, ¿qué es EAAR y cómo mejora a su predecesor? 🤔\nEn pocas palabras, estas son las ventajas:\nUtiliza inline data en lugar de BFD. En otras palabras, los paquetes de plano de datos se utilizan para medir la pérdida, la latencia y el jitter. Capacidad de mover el tráfico en segundos en lugar de minutos Amortiguación (Dampening) implementada para propósitos de estabilidad, asegurando que los transportes sean estables antes de reenviar el tráfico a través de ellos. Medición más precisa de pérdida, latencia y jitter Vamos por partes Cuando EAAR está habilitado, los paquetes de datos se utilizarán para medir la pérdida, la latencia y la jitter. Entendamos las diferencias clave:\nMedición de pérdida Los routeres SD-WAN utilizarán inline data junto con los números de secuencia IPSEC para medir la pérdida.\nHay un mecanismo incorporado que permite a los routers determinar si la pérdida es local para el router\nPérdida local - Por lo general, debido a caídas de QoS O externo al router\nPérdida de WAN - Cualquier pérdida de paquetes fuera del router Para calcular la pérdida local, el router determinará la cantidad de paquetes que generó en comparación con la cantidad de paquetes que realmente fueron enviados. Para obtener la pérdida en el WAN, los routers SD-WAN vecinos informarán la cantidad de paquetes recibidos y utilizarán BFD (TLVs de Monitoreo de Ruta) para enviar esta información de vuelta al router original.\nHasta este punto, existe una mejora importante en cómo se realiza la medición de pérdidas, sin embargo, esto podría mejorarse aún más al aprovechar mediciones per queue de QoS. Para lograr esto, necesitamos asociar una clase de SLA con una App Probe Class. Veamos un ejemplo.\nCon esta App Probe Class, el router utilizará (y generará paquetes de BFD) con DSCP 18, imitando el tráfico menos importante que estará sujeto a diferentes reglas y rutas en los routers locales y externos. Esto proporcionará una medición más precisa de la pérdida de paquetes para cada tipo de tráfico en los transportes especificados. Si no hay inline data, BFD se usa para obtener mediciones.\nNota Si usas GRE, la medición per queue no está disponible.\nAquí hay un visual para comprender mejor cómo se medirán la pérdida dependiendo de múltiples factores.\nEncapsulación App Probe Class Tipo de medición Túneles públicos Túneles privados IPsec Sí Por SLA total pérdida WAN + pérdida local por queue pérdida WAN per queue + pérdida local por queue IPsec No Todos los SLAs total pérdida WAN + total pérdida local total pérdida WAN + total pérdida local GRE - Todos los SLAs total pérdida WAN + total pérdida local total pérdida WAN + total pérdida local Latencia Para medir la latencia, el router simplemente calculará el tiempo necesario para enviar y recibir paquetes entre los dispositivos de origen y de destino. Se utiliza inline data y puede llegar a la granularidad de App Probe Class.\nJitter Vale la pena mencionar que el jitter se calcula por dirección (recibir o transmitir). El jitter se calcula en el receptor e informa al remitente usando TLV BFD. Se utiliza inline data y, en caso de no haber tráfico de datos, se usa BFD.\nSLA Dampening Uno de los beneficios de EAAR es dirigir el tráfico en segundos en lugar de minutos, pero ¿qué pasaría si hay condiciones de red transitorias que hacen que los transportes no cumplan con el SLA cada pocos minutos? El tráfico cambiaría constantemente entre los transportes, lo que no es un escenario deseable y la razón por la cual se introdujo el dampening.\nLa idea general es que cuando un enlace de transporte deja de cumplir con el SLA, el tráfico se redirige a una ruta alternativa. Una vez que el transporte vuelve a estar en cumplimiento, el dispositivo no mueve el tráfico de inmediato. En su lugar, inicia un temporizador para asegurarse de que el enlace permanezca estable durante un período determinado antes de reutilizarlo.\nAl final, el dampening ayuda a evitar cambios innecesarios en el tráfico, lo que podría afectar negativamente el rendimiento debido a la inestabilidad del transporte.\nConfiguración de EAAR Para habilitar EAAR tenemos tres opciones predefinidas:\nMode Poll Interval Poll Multiplier Dampening Multiplier Aggressive 10s 6 (10s-60s) 120 (20 mins) Moderate 60s 5 (60s-300s) 40 (40 mins) Conservative 300s 6 (300s-1800s) 12 (60 mins) Nota Para usar tiempos personalizados, la configuración debe hacerse a través de plantillas CLI.\nEAAR sigue el mismo principio fundamental que AAR, utilizando buckets que van rotando para calcular la pérdida promedio, la latencia y la jitter. Con el modo aggressive, el tráfico tomaría entre 10 y 60 segundos en cambiar, dependiendo de qué tan severo sea el deterioro.\nEl Dampening Multiplier (poll interval x Dampening Multiplier) es de 1200 segundos, lo que significa que antes de cambiar el tráfico a un transporte, debe ser estable durante 20 minutos.\nEn mi laboratorio, estoy usando Configuration Groups, sin embargo, esto está disponible a través de Templates también.\nPuedes usar una variable, en lugar de un valor global, para que sea aplicable también a los dispositivos que no correrán EAAR. En este caso, los dispositivos habilitados para EAAR harán fallback a AAR.\nLa siguiente configuración se agrega a los dispositivos:\nbfd enhanced-app-route enable bfd enhanced-app-route pfr-poll-interval 10000 bfd enhanced-app-route pfr-multiplier 6 bfd sla-dampening enable bfd sla-dampening multiplier 120 Veamos cómo funciona\nDemo En mi laboratorio, uso el Manager con versión 20.16.1 y mis dispositivos con 17.15.1a\nNota La versión mínima requerida es 20.12/17.12\nComencemos con algunas verificaciones después de aplicar la configuración.\nPara verificar los temporizadores y multiplicadores configurados\nBR10#show sdwan app-route params Enhanced Application-Aware routing Config: :Enabled Poll interval: :10000 Poll multiplier: :6 App route Poll interval: :120000 Poll multiplier: :5 SLA dampening Config: :Enabled Multiplier: :120 Para verificar qué sesiones de BFD están utilizando EAAR, busca la columna Flags\nBR10#show sdwan bfd sessions alt SOURCE TLOC REMOTE TLOC DST PUBLIC DST PUBLIC SYSTEM IP SITE ID STATE COLOR COLOR SOURCE IP IP PORT ENCAP BFD-LD FLAGS UPTIME ------------------------------------------------------------------------------------------------------------------------------------------------- 1.1.1.20 200 up biz-internet biz-internet 30.1.10.2 30.1.20.2 12406 ipsec 20006 EAAR 0:00:20:31 1.1.1.20 200 up mpls mpls 30.2.10.2 30.2.20.2 12366 ipsec 20002 EAAR 0:00:20:38 1.1.1.20 200 up private1 private1 30.3.10.2 30.3.20.2 12366 ipsec 20003 EAAR 0:00:20:37 Para obtener más detalles sobre un túnel específico.\nBR10#show sdwan app-route stats summary Generating output, this might take time, please wait ... app-route statistics 30.1.10.2 30.1.20.2 ipsec 12386 12406 remote-system-ip 1.1.1.20 local-color biz-internet remote-color biz-internet sla-class-index 0,1,2 fallback-sla-class-index None enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 0.000 mean-latency 0 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 0 0 0 0 0 0 0 0 1 64 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 5 64 0 0 0 0 0 0 0 Nota que no hay tráfico entre mis dispositivos, por lo que el recuento total de paquetes en cada bucket es bajo.\nLa misma información está disponible a través de la interfaz gráfica, utilizando la opción de Real Time \u0026gt; App Route Statistics\nEscenario 1 - Deterioro ligero Esta es la topología de mi laboratorio\nPara esta primera prueba, usaré los siguientes parámetros de SLA:\nSLA_Real-Time Loss: 3% Latency: 150ms Jitter: 100ms La política AAR indica que:\nUse MPLS como transporte principal Si ningún color cumple con el SLA y Private1 está disponible, usarlo. Si Private1 no está disponible, se hace load balance entre todos los colores restantes. Estoy haciendo match del tráfico entre 172.16.10.0/24 y 172.16.20.0/24.\nBR10#show sdwan policy from-vsmart from-vsmart app-route-policy app_route_AAR vpn-list vpn_Corporate_Users sequence 1 match source-data-prefix-list BR10 destination-data-prefix-list BR20 action backup-sla-preferred-color private1 sla-class SLA_Real-Time no sla-class strict sla-class preferred-color mpls sequence 11 match source-data-prefix-list BR20 destination-data-prefix-list BR10 action backup-sla-preferred-color private1 sla-class SLA_Real-Time no sla-class strict sla-class preferred-color mpls Estado inicial sin deterioro en la red\nBR10#show sdwan app-route stats summary | i color|damp|mean local-color biz-internet remote-color biz-internet sla-dampening-index None mean-loss 0.000 mean-latency 1 mean-jitter 0 local-color mpls remote-color mpls sla-dampening-index None mean-loss 1.212 mean-latency 1 mean-jitter 0 mean-loss 1.212 mean-latency 1 mean-jitter 0 local-color private1 remote-color private1 sla-dampening-index None mean-loss 0.000 mean-latency 0 mean-jitter 0 mean-loss 0.000 mean-latency 0 mean-jitter 0 Observa que el número de paquetes por bucket aumentó dramáticamente\nBR10#show sdwan app-route stats remote-color mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12366 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0,1 fallback-sla-class-index None enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 1.176 mean-latency 0 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 131136 1501 0 0 100084 20846 0 0 1 131072 1438 0 0 95287 19605 0 0 2 131072 1400 0 0 100985 20937 0 0 3 131072 1781 0 0 85553 18271 0 0 4 64 0 0 0 72618 15942 0 0 5 131072 1589 0 0 65198 14226 0 0 El tráfico está utilizando MPLS como transporte primario\nBR10# show sdwan policy service-path vpn 10 interface gigabitEthernet 4 source-ip 172.16.10.10 dest-ip 172.16.20.10 protocol 6 all Number of possible next hops: 1 Next Hop: IPsec Source: 30.2.10.2 12366 Destination: 30.2.20.2 12366 Local Color: mpls Remote Color: mpls Remote System IP: 1.1.1.20 Introduzco el 3% de pérdida de paquetes en el transporte MPLS y veré cuánto tiempo lleva cambiar el tráfico. Dado que ya hay alrededor del 1% de pérdida, el 3% debería ser suficiente para activar un cambio.\nEl transporte MPLS tiene más del 3% de pérdida\nBR10#show sdwan app-route stats remote-color mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12366 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0 fallback-sla-class-index 1 enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 3.125 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; mean-latency 0 mean-jitter 0 Después de 56 segundos, el tráfico cambió y cualquiera de los transportes que cumplen el SLA podría usarse\nBR10# show sdwan policy service-path vpn 10 interface gigabitEthernet 4 source-ip 172.16.10.10 dest-ip 172.16.20.10 protocol 6 all Number of possible next hops: 2 Next Hop: IPsec Source: 30.3.10.2 12366 Destination: 30.3.20.2 12366 Local Color: private1 Remote Color: private1 Remote System IP: 1.1.1.20 Next Hop: IPsec Source: 30.1.10.2 12386 Destination: 30.1.20.2 12366 Local Color: biz-internet Remote Color: biz-internet Remote System IP: 1.1.1.20 Si quito la pérdida, podemos ver que el mecanismo de dampening se activa. Entonces, si el transporte es estable durante 20 minutos, se volverá a utilizar como ruta preferida.\nBR10#show sdwan app-route stats remote-color mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12366 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0 fallback-sla-class-index 1 enhanced-app-route Enabled sla-dampening-index 1 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; app-probe-class-list None mean-loss 0.000 mean-latency 0 mean-jitter 0 Escenario 2 - Mayor deterioro En este caso, introduciré una pérdida de paquetes del 10% para el transporte de biz-internet, lo que hace que private1 sea el único transporte cumpliendo el SLA.\nDespués de alrededor de 45 segundos, la pérdida de Biz-Internet fue de 12%\nBR10#show sdwan app-route stats local-color biz-internet summary Generating output, this might take time, please wait ... app-route statistics 30.1.10.2 30.1.20.2 ipsec 12386 12366 remote-system-ip 1.1.1.20 local-color biz-internet remote-color biz-internet sla-class-index 0 fallback-sla-class-index 1 enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 12.500 mean-latency 0 mean-jitter 0 El tráfico cambió a private1 exclusivamente\nBR10#show sdwan policy service-path vpn 10 interface gigabitEthernet 4 source-ip 172.16.10.10 dest-ip 172.16.20.10 protocol 6 all Number of possible next hops: 1 Next Hop: IPsec Source: 30.3.10.2 12366 Destination: 30.3.20.2 12366 Local Color: private1 Remote Color: private1 Remote System IP: 1.1.1.20 Después de eliminar la pérdida de paquetes, Biz-Internet tiene el mecanismo de dampening activado\nBR10#show sdwan app-route stats local-color biz-internet summary Generating output, this might take time, please wait ... app-route statistics 30.1.10.2 30.1.20.2 ipsec 12386 12366 remote-system-ip 1.1.1.20 local-color biz-internet remote-color biz-internet sla-class-index 0 fallback-sla-class-index 1 enhanced-app-route Enabled sla-dampening-index 1 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; app-probe-class-list None mean-loss 1.562 mean-latency 0 mean-jitter 0 En este caso, el tiempo para cambiar el tráfico se redujo como consecuencia de un deterioro mayor.\nEscenario 3 - Múltiples App Probe Class Para este escenario final, veamos cómo obtener el mayor beneficio de EAAR.\nLa configuración es más compleja ya que involucra QoS, App Probe Class y política AAR.\nSe requiere QoS para clasificar y enviar tráfico en diferentes colas. App Probe Class para medir la pérdida, la latencia y el jitter en cada una de esas colas, de forma independiente. Mi configuración de QoS tiene 3 colas y la cola 2 manejará el tráfico menos importante.\ncola 0 para el tráfico de control cola 1 para tráfico en tiempo real (marcado DSCP 46) cola 2 para tráfico transaccional (marcado DSCP 18) Utilizo una política de datos para hacer match del tráfico en el lado del servicio, marcarlo con el DSCP correcto y ponerla en la clase de QoS correcta. También creé un shaper en mi interfaz MPLS.\nPara demostrar las cosas, tendré dos transferencias de datos:\nHTTP GET (puerto 8000) Copia SCP (puerto 22) Mis SLA tienen las siguientes configuraciones:\nSLA Class Name Loss Latency Jitter SLA_Real-Time 3 % 150 ms 100 ms SLA_Transactional 5 % 45 ms 150 ms Lo primero que hay que notar es que mis dos clases de sondeo de aplicaciones se miden de manera independiente. Observa cómo la pérdida media para Transactional-Probe_Class es 1, mientras que para Real_Time_Probe_Class es 0.\nBR10#show sdwan app-route stats local-color mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12366 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0,1,2 fallback-sla-class-index None enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 0.000 mean-latency 1 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 16384 0 0 0 35827 111807 0 0 1 49152 0 1 0 37788 118236 0 0 2 49216 0 1 0 36859 115551 0 0 3 16384 0 1 0 23894 77280 0 0 4 32768 0 1 1 33179 103759 0 0 5 32768 0 1 0 21485 71702 0 0 app-probe-class-list Real_Time_Probe_Class mean-loss 0.000 mean-latency 0 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 0 0 0 0 - - - - 1 32768 0 1 0 - - - - 2 32768 0 0 0 - - - - 3 0 0 0 0 - - - - 4 32768 0 1 2 - - - - 5 0 0 0 0 - - - - app-probe-class-list Transactional-Probe_Class mean-loss 0.000 mean-latency 1 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 16384 0 0 0 - - - - 1 49152 0 1 0 - - - - 2 49216 0 1 0 - - - - 3 16384 0 1 0 - - - - 4 32768 0 1 1 - - - - 5 32768 0 1 0 - - - - Ahora, he bajado mi shaper. EAAR fue rápido en detectar un cambio en la latencia para el SLA Transactional, ahora son 53 ms.\nBR10# show sdwan app-route stats local mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12386 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0,1,2 fallback-sla-class-index None enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 0.000 mean-latency 53 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 2048 0 54 0 4396 8513 0 0 1 1024 0 55 0 4461 8534 0 0 2 8256 0 49 0 4429 8549 0 0 3 16384 0 54 0 4411 8549 0 0 4 0 0 53 0 4440 8549 0 0 5 0 0 54 0 4443 8549 0 0 app-probe-class-list Real_Time_Probe_Class mean-loss 0.000 mean-latency 0 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 0 0 0 0 - - - - 1 0 0 0 0 - - - - 2 8192 0 0 0 - - - - 3 16384 0 0 0 - - - - 4 0 0 0 0 - - - - 5 0 0 0 0 - - - - app-probe-class-list Transactional-Probe_Class mean-loss 0.000 mean-latency 53 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 2048 0 54 0 - - - - 1 1024 0 55 0 - - - - 2 8256 0 49 0 - - - - 3 16384 0 54 0 - - - - 4 0 0 53 0 - - - - 5 0 0 54 0 - - - - Ahora que no se cumple mi SLA Transactional con una latencia máxima de 45 ms, usaré NWPI para comprender cómo se envía el tráfico. Examinemos el tráfico HTTP con el puerto 80000\nObserva que, en la dirección upstream, el color local y remote es private1, lo que indica que el tráfico se ha alejado de MPLS y su latencia de 53 ms. Justo lo que esperábamos ✅\nAhora, veamos cómo está fluyendo el tráfico en el puerto 22\nUna vez más, observa el local y Remote Color en la dirección upstream, observa cómo MPLS todavía está en uso para este tráfico, ya que no hay problemas en los transportes para este tipo de tráfico.\nEn resumen, el tráfico con DSCP 46 funciona perfectamente bien en el transporte MPLS, sin embargo, el tráfico con DSCP 18 estaba teniendo más latencia que el SLA configurado, por lo que se trasladó a Private1 ya que cumple con el SLA.\nPodemos confirmar que estamos midiendo y tomando decisiones de ruteo per queue, esta es una gran diferencia 🤯!\nLecciones aprendidas Utilizando inline data, el número de muestras aumenta dramáticamente en comparación con el tamaño de muestra de BFD. 📈 EAAR puede redirigir el tráfico en segundos, en lugar de minutos. ⏩ EAAR ofrece los mayores beneficios en los transportes con QoS, como MPLS. 🚀 Incluso en los transportes sin QoS, las mediciones de inline data aumentan el tamaño y la precisión de las muestras. ⏳ El temporizador de dampening es útil para garantizar que los transportes sean estables antes de marcarlos como válidos. ✅ La interoperabilidad entre dispositivos que ejecutan EAAR y dispositivos que ejecutan AAR es posible 🔄 ¡Espero que hayas aprendido algo útil! Nos vemos en el siguiente 👋\n","permalink":"http://localhost:1313/aar-mejorado/","summary":"Aprende los beneficios de EAAR y cómo implementarlo en tu red","title":"Enhanced App Aware Routing"},{"content":"Introducción En mi Última publicación, creé un asistente de IA de Cisco SD-WAN para ayudarme a ejecutar trazas NWPI y solucionar problemas en la red. La interacción con el asistente requería que el usuario respondiera preguntas hasta obtener información sobre un flujo particular y posibles problemas. En esta publicación, mi objetivo es usar múltiples agentes y ver si puedo llegar a la misma conclusión con menos interacción humana. Se puede encontrar el repositorio aquí\nPrimeros Pasos Para lograr esto, usaré LangGraph oficialmente definido como:\nUna biblioteca para construir aplicaciones de actores múltiples estatales con LLMS, utilizada para crear flujos de trabajo de agentes y múltiples agentes\nHay diferentes enfoques, pero decidí construir una estructura donde hay un supervisor que orquesta el flujo de trabajo y decide quién debe actuar a continuación. La idea es construir un gráfico que represente a los agentes y cómo están conectados. El gráfico ilustra el orden en el que los agentes pueden ejecutarse.\nEn mi caso tengo 3 agentes:\nSupervisor - Este agente está a cargo de recibir input del usuario y decidir quién debe actuar a continuación. Además, una vez que otros agentes terminen sus tareas, le informarán y se tomará una nueva decisión de enrutamiento. El supervisor es el único agente que puede decidir cuándo volver al usuario con una respuesta. Reviewer - Este agente revisará la información que se enviará al usuario, realiza algunas preguntas o resúmenes y resuelve preguntas o situaciones que el tracer pueda plantear. Tracer - Este es el agente que ejecutará las trazas y recuperará la información que el usuario está buscando. Se informará al supervisor cuando se haga o si se debe responder alguna pregunta. Tuve que modificar un poco el prompt del tracer, para poder obtener un comportamiento que sea mejor para este enfoque. Además, cada agente puede tener sus propias herramientas. Actualmente, el Tracer tiene más herramientas que el resto de los agentes.\nVisualizado, el gráfico se ve así:\nLa flecha punteada indica un borde condicional, lo que significa que el supervisor puede decidir cuál debe ser el próximo agente o si terminar es apropiado.\nLa flecha continua indica el siguiente paso que debe seguirse Por ejemplo, después de \u0026ldquo;START\u0026rdquo;, el siguiente agente debe ser el supervisor. Tracer y Reviewer deben ir al Supervisor.\nAunque este es un gráfico simple, este enfoque es muy poderoso.\n¿Cómo decide el supervisor? El supervisor juega un papel fundamental, ya que determina quién debe actuar a continuación. Esto se define en la siguiente función:\noptions = [\u0026#34;FINISH\u0026#34;] + members function_def = { \u0026#34;name\u0026#34;: \u0026#34;route\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Select the next role.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;routeSchema\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;next\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Next\u0026#34;, \u0026#34;anyOf\u0026#34;: [ {\u0026#34;enum\u0026#34;: options}, ], } }, \u0026#34;required\u0026#34;: [\u0026#34;next\u0026#34;], }, } Con esto, cada vez que el supervisor reciba cualquier input, obtendrá un valor de \u0026ldquo;next\u0026rdquo; de las opciones disponibles y esto representará el siguiente nodo en el gráfico.\nDemo Usaremos la siguiente topología para probar\nLe doy información al asistente sobre el problema e informo que ya hay tráfico en la red (se requiere tráfico para que NWPI genere los insights que estamos buscando).\nEsto es con lo que regresó el asistente\nLa respuesta presenta información de manera condensada, que indica el flujo y el camino que el tráfico está tomando y algunos eventos detectados para esta comunicación. Los detalles de uno de los flujos también están presentes, sin embargo, tiene menos información que antes. Esto se debe a que he pedido al agente reviewer que mantenga lo que considera más relevante y lo envíe al usuario. Al final, podemos ver que se menciona el Drop Report y hay una sugerencia para revisar las ACL 🎉\nPodemos jugar con el reviewer para mostrar más información sobre los detalles del flujo.\nDetrás de cámaras Ok, el asistente regresó con una buena respuesta, pero veamos con más detalle lo que sucedió. Usando LangSmith podemos obtener detalles e insights sobre el workflow. Aquí está el proceso completo.\nPrimero, el supervisor recibe la consulta del usuario y la pasa al Tracer.\nA continuación, el Tracer utiliza las herramientas disponibles para iniciar la traza, espera capturar algunos flujos y recupera información. Informa al Supervisor. Ten en cuenta que el orden en que se ejecutan las herramientas depende del agente.\nLuego, el supervisor recibe la información y decide que el reviewer debería actuar a continuación.\nA continuación, el reviewer recibe la información y reescribe lo que se recibió del tracer. Informa al supervisor.\nFinalmenete, el supervisor decide que la información está lista para enviarse al usuario. Esto es cuando recibimos el mensaje en Webex.\nLecciones aprendidas Dado que los agentes pueden tomar decisiones, no siempre es fácil entender lo que están haciendo o por qué devuelven lo que devuelven, usando LangSmith definitivamente ayudó con esto. No solo podemos ver el request y las herramientas utilizadas, sino que también hay algunos metadatos que proporcionan información valiosa adicional. Llegué a algunas situaciones en las que el supervisor llamaba al tracer varias veces debido a algún error al recuperar la información. Al final, esto fue causado por un error en el código y, afortunadamente, mi asistente no es costoso. Sin embargo, si tu caso de uso consume muchos tokens, debes considerar agregar algún tipo de protección para evitar un loop que aumente el consumo de APIs. Hablando de costos, los modelos de lenguaje pequeño (SLM) son una buena alternativa. Después de quedarme sin cuota, recordé que el modelo GPT-4o-mini está disponible y decidí intentarlo. Después de algunas pruebas, vi que funcionó muy bien y era mucho más barato, así que continué con ese. Conclusión Usando la estrategia de múltiples agentes, podemos lograr tareas más complejas y tener más flexibilidad. Si es necesario, la interacción del usuario se puede agregar en ciertas decisiones que son importantes. Además, existe cierta complejidad adicional, ya que prompts deben refinarse para lograr los resultados que esperamos. En mi caso, tuve que hacer múltiples iteraciones y refinamientos a los prompts de todos los agentes antes de obtener un resultado que consideraba lo suficientemente bueno.\nMe interesa probar otros enfoques para las implementaciones de múltiples agentes y agregar información adicional para que los agentes proporcionen información más precisa a través de RAG.\n","permalink":"http://localhost:1313/mejorando-mi-asistente-sd-wan-multiples-agentes/","summary":"Aprende cómo utilizar un enfoque \u0026ldquo;agentic\u0026rdquo; para hacer troubleshooting de tu red SD-WAN con LLMs","title":"Mejora de mi asistente de SD-WAN - Múltiples agentes"},{"content":"Introducción Hace tiempo que quería subirme al tren de los LLM y aprender a usar uno de los frameworks más populares. Hace unos meses, vi una excelente presentación en Cisco Live de mi buen amigo Jesús, y eso me dio la determinación que necesitaba para finalmente profundizar en el tema.\nDesde entonces, he estado investigando y pensando en un buen caso de uso que pudiera servir como objetivo para mi proceso de aprendizaje. Después de considerar diferentes opciones, decidí construir un asistente de IA para SD-WAN que pudiera ayudarme a solucionar problemas relacionados con esta tecnología. Aprovechando las herramientas disponibles, decidí que mi asistente sería un experto en la funcionalidad de Network Wide Rath Insights.\nEn esta publicación, quiero compartir un poco de mi experiencia para construirlo y, por supuesto, mostrar algunos de los resultados. Para entenderlo mejor, sugiero tener el repositorio de Github abierto y consultarlo a medida que avanzas por la publicación.\nSobre la configuración Mi laboratorio SD-WAN está corriendo la versión 20.12.3 y WAN edges están utilizando 17.9.4a. Tengo una topología muy simple:\nEl lenguaje de programación utilizado es Python y el framework que elegí para interactuar con el LLM es Langchain. Utilicé OpenAI Model GPT-4o y un bot de webex para la interacción. El repositorio se puede encontrar aquí.\nMi objetivo Para dar contexto, la solución de problemas dentro de una infraestructura SD-WAN no es sencilla debido a que el tráfico está cifrado, las políticas dictan cómo fluirá el tráfico, pueden existir múltiples caminos hacia un destino, los siguientes saltos pueden cambiar según las políticas, hay múltiples saltos involucrados, entre otros factores. Determinar toda esta información lleva tiempo y no es un proceso directo.\nNWPI Trace es una herramienta que mejora significativamente el proceso de troubleshooting, ya que proporciona información y visibilidad salto a salto. Se puede iniciar fácilmente desde la interfaz del Manager, detecta flujos según filtros especificados y permite explorar la red para obtener toda la visibilidad necesaria. Es una herramienta muy completa y avanzada.\nComo mencioné antes, quería utilizar este proyecto como un campo de prueba para aprender, y dado que no tenía experiencia previa con LLMs o LangChain, establecí un objetivo sencillo:\nConstruir un asistente que pueda iniciar una traza NWPI y darme detalles de los flujos\nPlanificación y construcción Ok, tengo mi objetivo, pero ¿cómo comienzo?\nTomé un enfoque práctico que significaba que no aprendí Langchain desde cero y en su lugar tomé el repositorio de la sesión de Cisco Live como base y construí sobre eso. Las razones para elegir este repositorio fueron simples:\nSe explicó en las sesiones, así que tuve una idea general de las tecnologías y su propósito. Pensé que sería fácil ajustar a mi caso de uso (por ejemplo, también uso webex, interactuaré con dispositivos de red, vi cómo las herramientas podrían reemplazarse con la mías) Tuve que limpiar un poco antes de comenzar, esto me requirió que entendiera lo que era esencial para hostear el LLM e interactuar con él. Afortunadamente, el repositorio tiene una estructura organizada que facilita la comprensión.\nDe la sesión, aprendí sobre [Langchain Tools] (https://python.langchain.com/v0.1/docs/modules/tools/), así que sabía que podría crear funciones que mi agente podría usar para realizar diferentes acciones. En este caso, las acciones serían algo así como comenzar trazas y leer la información obtenida.\nDesafío 1 Necesitaba familiarizarme con la APIs de NWPI. En este punto, sabía que en algún lugar de la documentación de la API había visto que algunas operaciones estaban disponibles, pero nunca me había tomado el tiempo de analizarlas en detalle. Para mi sorpresa, las acciones específicas de iniciar un trace y obtener sus detalles no estaban incluidas… En su lugar, encontré información sobre cómo iniciar una \u0026ldquo;tarea\u0026rdquo; o \u0026ldquo;Auto-on Task\u0026rdquo;, que no es lo mismo que el \u0026ldquo;Trace\u0026rdquo; que tenía en mente.\nEn este punto, tenía que decidir si seguir el camino \u0026ldquo;oficial\u0026rdquo; (quizás más fácil) o explorar una alternativa para lograr exactamente lo que quería.\nSabiendo que casi todo en SD-WAN es impulsado por APIs, usé la pestaña de inspección de mi navegador y comencé a explorar las APIs que se activaban cuando iniciaba un trace desde la UI. Después de una primera revisión rápida, determiné que era factible y comencé a recopilar la información que necesitaba.\nDesafío 2 Ya sabía que tendría que hacer algo de análisis para convertir mi idea en realidad, pero subestimé cuánto tendría que hacer. De hecho, la dificultad de esta tarea me alejó del proyecto por un tiempo, ya que se volvió cada vez más compleja.\nEn mi mente solo había 3 tareas \u0026ldquo;simples\u0026rdquo;:\nEncontrar la API para iniciar el trace Encontrar la API para confirmar que el trace está en ejecución Encontrar la API que me dé detalles de los flujos API para iniciar la traza Iniciar la traza desde la interfaz de usuario es muy sencillo, solo necesitas un Site ID y un VPN ID. Sin embargo, hay verificaciones subyacentes que damos por sentadas.\nEl Site ID realmente es necesario para identificar los dispositivos en los que iniciar la traza Hay una serie de opciones (informes de QoS, visibilidad ART, visibilidad de aplicaciones, DIA, etc.) que dependen de la versión La VPN debe existir Para realizar esto, creé la función get_device_details_from_site para poder encontrar la información relacionada con los dispositivos en los que iniciar el trace. Necesitaba:\nversiones números de serie nombres estado de conectividad Luego, creé la función start_trace que recibiría la información obtenida previamente y otros filtros. Mantuve los filtros lo más simples posible, dejando solo la opción de especificar una subred de origen y destino. Hay muchas opciones para la traza para las cuales no realicé ninguna verificación de versión antes de ejecutarla, solo lo hice para los informes de QoS, que requieren la versión 17.9 o posterior. Esta función devuelve información necesaria más adelante para verificar el estado.\nAPI para confirmar que la traza se está ejecutando Esta fue probablemente la tarea más fácil. Creé la función verify_trace_state y con la ayuda del LLM se puede ejecutar unos segundos después de comenzar la traza. Devuelve el estado, que también es necesario para obtener información más adelante.\nAPI para darme detalles de los flujos Esta fue la tarea más compleja y tardada. En mi mente, verificar el resultado de una traza es muy simple, sin embargo, cuando recibimos la información en pedazos, a través de diferentes llamadas comienza a ser complicado.\nIntenté replicar el proceso que sigo en la interfaz de usuario:\nVer las estadísticas del trace y comprobar los flujos que fueron capturados (si es que hay alguno). Para la lista de flujos, buscar el que tiene el botón \u0026ldquo;readout\u0026rdquo; en rojo (problema detectado) y hacer clic para obtener más detalles. Expandir la vista del flujo para acceder a las funcionalidades avanzadas y así determinar las características por las que el paquete pasa en cada uno de los saltos. Para obtener los flujos capturados en el trace, creé la función get_flow_summary. Esta función devolverá la lista de los flujos capturados. Verás detalles como origen/destino, aplicación y protocolo. Esto es útil para identificar el flujo cuyo id te interesa para obtener más detalles.\nCreé la función trace_readout para obtener un resumen de los eventos que el trace capturó junto con el camino afectado. Por ejemplo, podrías ver que un flujo SSH no está funcionando entre el Dispositivo X y el Dispositivo Y.\nUna vez que hayas identificado el flujo y los eventos que te interesan, puedes obtener información detallada del flujo con la función get_flow_detai. Esto te proporcionará información como:\nHops Eventos Colores locales/remotos Interfaces de entrada/salida Funcionalidades de entrada/salida aplicadas a los paquetes Funcionalidad que determina decisión de ruteo Con esta información es posible ver todo tipo de cosas, como ACLs, tipo de políticas aplicadas, por qué un paquete fue enviado a través de un color específico, caídas, confirmar que tu política está funcionando como se espera, etc.\nOk, creo que eso es todo\nDemo Comencé creando un ACL para bloquear la comunicación y la apliqué en el lado de DC.\nMunich_DC100-1 - ACL configuration sdwan interface GigabitEthernet2 access-list ACL_Drop_172_16_10_0 out policy access-list ACL_Drop_172_16_10_0 sequence 1 match source-ip 172.16.10.0/24 destination-ip 172.16.100.0/24 ! action drop count dropCounter ! ! default-action accept ! ¿Mi asistente detectará esto? 🤔\nA continuación, comienzo la aplicación y solicito que el LLM inicie una traza. Puedo confirmar en la UI que se crea.\nLanzo un par de conexiones SSH de Branch a DC\nDespués, le pregunto al asistente si se han capturado flujos, responde con esto\nPodemos ver que los flujos fueron capturados y también me dio más información sobre los eventos detectados y el camino que tomaron los paquetes incluyendo los nombres de los dispositivos. El primer evento parece estar relacionado con nuestro problema. Hasta ahora, la información parece precisa, voy a pedir más detalles.\nCon esto, podemos ver que el cliente envió múltiples intentos de SSH, podemos profundizar en uno de los flujos. Veamos qué más da.\nFinalmente, el asistente proporciona información detallada sobre las funcionalidades que se aplican a cada uno de los flujos. En el segundo salto, en Munich DC, podemos ver que las funcionalidades de salida muestran el SD-WAN ACL y un \u0026lsquo;Drop Report\u0026rsquo;. El asistente proporciona su propia conclusión y también sospecha que el router de Munich está tirando el tráfico.\nCon un poco más de trabajo, el agente podría decir el nombre del ACL y el número de secuencia responsable de tirar el tráfico. ¡Hemos identificado con éxito la raíz del problema! 😀 🎉\nLecciones aprendidas Cuando comencé, quería ser súper cauteloso con los créditos ($$), así que estaba usando GPT-3.5-Turbo-16k que es más barato pero también menos inteligente. En algún momento, enfrenté problemas con el LLM entrando en un loop, decidí probar GPT-4O y sentí una diferencia en la forma en que el agente estaba razonando. Inicialmente, estaba usando una temperatura LLM = 0, esto estaba bien, pero las respuestas carecían de variedad y detalles, necesitaba hacerlo más hablador. Ajustar la temperatura = 0.9 me dio un buen equilibrio entre la charla y la corrección (aunque a veces el agente todavía proporciona información que es cuestionable en función de las salidas) Hacer troubleshooting puede ser difícil a veces, principalmente me basé en imprimir los resultados de las funciones mientras estas se ejecutaban y el agente imprimía en la terminal. Esto me permitió entender qué herramientas estaba utilizando el agente y el orden en que las utilizaba. Además, pude ver qué estaban devolviendo esas herramientas. Aquí tienes un ejemplo: El texto en verde indica las herramientas a las que está accediendo al agente. El texto amarillo es la información devuelta por una función. En este caso, podemos ver que el agente llamó la función \u0026quot;get_entry_time_and_state\u0026quot; para que obtener información necesaria para llamar a la siguiente función \u0026quot;get_flow_detail\u0026quot;\nHay mejores herramientas disponibles para ayudar con la resolución de problemas como LangSmith Tracing, lo voy a explorar en el futuro.\nEl prompts de mi agente tuvo que ser refinado varias veces, a menudo me di cuenta de que necesitaba proporcionar más detalles para manejar ciertas situaciones correctamente, especialmente cuando la salida de una función era necesaria para llamar a otra o para manejar situaciones inesperadas. Creo que aún puede mejorarse, de hecho, quiero escribir un prompt completamente diferente para intentar hacer que el agente ejecute todas las herramientas por sí mismo y solo devuelva una conclusión después de analizar todas las salidas. Conclusión En general, fue un buen y largo ejercicio de aprendizaje esto de construir mi primer asistente. Me siento contento con el resultado, ya que logré alcanzar mi objetivo. Al mismo tiempo, reconozco que hay muchas cosas que se pueden mejorar para hacer que los resultados sean más confiables y significativos. Además, hay mucha más información que NWPI puede mostrar, por lo que las herramientas definitivamente se pueden ampliar.\nComo siguiente paso, planeo aprender LangChain adecuadamente y entender cómo puedo implementar múltiples agentes para mejorar la funcionalidad y confiabilidad de mi asistente.\n¡Espero que este post te ayude de la misma manera que la presentación de Cisco Live me ayudó a mí!\n","permalink":"http://localhost:1313/creando-mi-primer-asistente-ai-con-langchain/","summary":"Descubre cómo los LLMs se pueden integrar con Cisco SD-WAN para hacer troubleshooting de manera sencilla y sin estrés","title":"Creando mi primer asistente de AI SD-WAN con Langchain"},{"content":"Introducción A medida que las redes evolucionan para ofrecer una mejor experiencia de usuario y se introducen nuevas tecnologías para gestionar la red, mantener todo funcionando sin problemas se ha vuelto cada vez más difícil. Una de las responsabilidades más críticas del equipo de operaciones es hacer un seguimiento de los problemas que ocurren en toda la red. Identificarlos es solo el comienzo, luego deben ser registrados y gestionados hasta su resolución. ¡Multiplica la cantidad de acciones por incidente y tendrás suficiente para mantener ocupado a tu equipo de TI todo el día!\nEn este post, te mostraré lo que necesitas saber para integrar el SD-WAN Manager con ServiceNow para la gestión de incidentes. Veremos algunos de los problemas más comunes en SD-WAN.\nConfiguración de laboratorio Estoy utilizando la versión 20.12.1 de SD-WAN Manager y tengo una instancia de desarrollador de ServiceNow. Mi servidor de Webhook funciona en Ubuntu 20.04 LTS y construí el receptor de Webhook en lenguaje Go.\nPara simplificar las cosas, tengo comunicación directa entre todos los elementos de mi laboratorio.\nWebhooks Los Webhooks son una manera en que las aplicaciones web se comunican entre sí en tiempo real. Permiten que una aplicación envíe notificaciones automáticas a otra aplicación cuando ocurre un evento específico, lo que se conoce como el modelo push. Esto facilita la integración entre diferentes sistemas y puede usarse para activar actividades automatizadas posteriores. Los Webhooks típicamente utilizan callbacks HTTP para compartir notificaciones/información.\nEn nuestro escenario, el SD-WAN Manager monitoreará eventos en BR10 y enviará solicitudes HTTP POST a nuestro servidor de Webhook cuando ocurran eventos específicos. Esto nos permitirá gestionar los incidentes en ServiceNow.\nAnatomía de una notificación webhook Comprendamos la estructura y la información que el SD-WAN Manager compartirá con nuestro servidor Webhook.\nEste es un ejemplo de la información enviada cuando alguna interfaz va abajo\n{ \u0026#34;suppressed\u0026#34;: false, \u0026#34;devices\u0026#34;: [ { \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34; } ], \u0026#34;eventname\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;rulename\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;component\u0026#34;: \u0026#34;VPN\u0026#34;, \u0026#34;entry_time\u0026#34;: 1709277345253, \u0026#34;statcycletime\u0026#34;: 1709277345253, \u0026#34;message\u0026#34;: \u0026#34;The interface oper-state changed to down\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;severity_number\u0026#34;: 1, \u0026#34;uuid\u0026#34;: \u0026#34;9e2f7630-d504-4cdf-b808-fc8e29a6dd47\u0026#34;, \u0026#34;values\u0026#34;: [ { \u0026#34;host-name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;if-name\u0026#34;: \u0026#34;GigabitEthernet2\u0026#34;, \u0026#34;new-state\u0026#34;: \u0026#34;down\u0026#34;, \u0026#34;vpn-id\u0026#34;: \u0026#34;0\u0026#34; } ], \u0026#34;rule_name_display\u0026#34;: \u0026#34;Interface_State_Change\u0026#34;, \u0026#34;receive_time\u0026#34;: 1708843127894, \u0026#34;values_short_display\u0026#34;: [ { \u0026#34;host-name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;if-name\u0026#34;: \u0026#34;GigabitEthernet2\u0026#34;, \u0026#34;new-state\u0026#34;: \u0026#34;down\u0026#34; } ], \u0026#34;system_ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;host_name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;acknowledged\u0026#34;: false, \u0026#34;active\u0026#34;: true } Veamos la información más importante para nosotros:\n\u0026quot;active\u0026quot;: true - ¿Tenemos un problema? Sí, indicado por el estado activo \u0026quot;message\u0026quot;: \u0026quot;The interface oper...\u0026quot; - ¿Qué está pasando? \u0026quot;severity_number\u0026quot;: 1 - ¿Qué tan malo es? (escogí el numero y no el string a propósito) \u0026quot;uuid\u0026quot;: \u0026quot;9e2f7630-d504...d47\u0026quot; - Identificador del evento usado por el SD-WAN Manager \u0026quot;system_ip\u0026quot;: \u0026quot;1.1.10.1\u0026quot; - ¿Qué equipo originó la alerta? \u0026quot;host_name\u0026quot;: \u0026quot;BR10\u0026quot; - Identificador de equipo más amigable para los humanos Veamos la notificación cuando la interfaz se va arriba\n{ \u0026#34;suppressed\u0026#34;: false, \u0026#34;devices\u0026#34;: [ { \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34; } ], \u0026#34;eventname\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;rulename\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;component\u0026#34;: \u0026#34;VPN\u0026#34;, \u0026#34;entry_time\u0026#34;: 1709277482508, \u0026#34;statcycletime\u0026#34;: 1709277482508, \u0026#34;message\u0026#34;: \u0026#34;The interface oper-state changed to up\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;severity_number\u0026#34;: 3, \u0026#34;uuid\u0026#34;: \u0026#34;5486325c-d189-4467-9b5a-16acb1f28ec9\u0026#34;, \u0026#34;values\u0026#34;: [ { \u0026#34;host-name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;if-name\u0026#34;: \u0026#34;GigabitEthernet2\u0026#34;, \u0026#34;new-state\u0026#34;: \u0026#34;up\u0026#34;, \u0026#34;vpn-id\u0026#34;: \u0026#34;0\u0026#34; } ], \u0026#34;rule_name_display\u0026#34;: \u0026#34;Interface_State_Change\u0026#34;, \u0026#34;receive_time\u0026#34;: 1708843265147, \u0026#34;values_short_display\u0026#34;: [ { \u0026#34;host-name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;if-name\u0026#34;: \u0026#34;GigabitEthernet2\u0026#34;, \u0026#34;new-state\u0026#34;: \u0026#34;up\u0026#34; } ], \u0026#34;system_ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;host_name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;acknowledged\u0026#34;: false, \u0026#34;cleared_events\u0026#34;: [ \u0026#34;9e2f7630-d504-4cdf-b808-fc8e29a6dd47\u0026#34; ], \u0026#34;active\u0026#34;: false } Las dos cosas más importantes son:\n\u0026quot;active\u0026quot;: false - ya no está activo o presente \u0026quot;cleared_events\u0026quot;: [\u0026quot;9e2f7630-d504...d47]\u0026quot; - ID del evento que se resuelve Una cosa que debe saber es que no todos los eventos se comportarán de la misma manera. Algunos de ellos no tendrán una entrada de cleared_events, por lo que tendríamos que manejarlos de manera diferente si queremos cerrarlos automáticamente. Otros pueden carecer de cierta información dependiendo de lo que estemos monitoreando.\nAntes de codificar cualquier tipo de aplicación, es importante saber lo que deseas monitorear y lo que obtendrás del SD-WAN Manager para que puedas manejarlo correctamente.\nConfiguración de Webhooks en SD-WAN Manager El 20.12, es muy simple configurarlos, primero habilita la configuración de notificación desde Administration \u0026gt; Settings \u0026gt; Alarm Notifications\nDefinamos las reglas para activar nuestros webhooks. Desde Monitor \u0026gt; Logs \u0026gt; Alarm notification \u0026gt; Add Alarm Notification\nCosas que tienes que saber:\nPuedes elegir monitorear sitios o dispositivos. La severidad es crucial. Para abrir incidentes, generalmente querrás monitorear incidentes de severidad crítica o alta, y para cerrarlos necesitarás monitorear severidades más bajas. Las alarmas para las que deseas generar webhooks, en nuestro caso: BFD nodo fuera de servicio/activo Omp nodo fuera de servicio/activo Nodo de control fuera de servicio/activo Interfaz fuera de servicio/activa Ten en cuenta que solo estoy usando HTTP en mi URL de webhook, se recomienda usar HTTPS para mayor seguridad. El 8080:/webhook proviene de la aplicación que construimos. El threshold limitará la cantidad de notificaciones enviadas por minuto a esta URL. 15 es suficiente para mí, pero probablemente no lo sea para un entorno de producción. Por último, el usuario y la contraseña en caso de que tu aplicación de webhook lo requiera. Estos valores se codificarían y se enviarían en los encabezados. Usa valores ficticios si no son necesarios. Construyendo el servidor webhook El código que uso esta publicado en el siguiente Repo de Github, aquí lo explicaré de una manera más simple.\nPaso 1: Las solicitudes se esperan en el puerto 8080 al endpoint /webhook.\n// Listen upcoming requests http.HandleFunc(\u0026#34;/webhook\u0026#34;, handleWebhook) fmt.Println(\u0026#34;Server listening on port 8080...\u0026#34;) if err := http.ListenAndServe(\u0026#34;0.0.0.0:8080\u0026#34;, nil); err != nil { fmt.Printf(\u0026#34;Failed to start server: %v\u0026#34;, err) } Paso 2. Comprobar si la solicitudes tiene un estado activo. En caso afirmativo, creo un incidente en ServiceNow.\n//Verify if issue is active and create incident if data[\u0026#34;active\u0026#34;] == true { fmt.Println(\u0026#34;Opening Service Now incident...\u0026#34;) err := createIncident(data) Paso 2.1 Para abrir un incidente en ServiceNow, necesitamos reformatear la información que se enviará allí.\nfunc createIncident(data map[string]interface{}) error { // Retrieve information to open incident issueId := data[\u0026#34;uuid\u0026#34;].(string) ruleName := data[\u0026#34;rule_name_display\u0026#34;].(string) title := data[\u0026#34;message\u0026#34;].(string) severity := data[\u0026#34;severity_number\u0026#34;].(float64) severityStr := strconv.FormatFloat(severity, \u0026#39;f\u0026#39;, -1, 64) device := \u0026#34;. Device \u0026#34; + data[\u0026#34;host_name\u0026#34;].(string) + \u0026#34;, System-ip \u0026#34; + data[\u0026#34;system_ip\u0026#34;].(string) // Construct JSON payload for creating incident in SNOW incidentData := map[string]interface{}{ \u0026#34;category\u0026#34;: \u0026#34;network\u0026#34;, \u0026#34;caller_id\u0026#34;: \u0026#34;vManage\u0026#34;, \u0026#34;short_description\u0026#34;: issueId, \u0026#34;description\u0026#34;: ruleName + \u0026#34; - \u0026#34; + title + device, \u0026#34;urgency\u0026#34;: severityStr, \u0026#34;impact\u0026#34;: severityStr, } ... Observa que almaceno el uuid proveniente de vManage y lo usamos como short_description para ServiceNow.\nPaso 3.a Si el estado no es activo, verificamos si hay algún cleared_events incluido, esto nos dará una alta precisión al cerrar incidentes.\nif _, ok := data[\u0026#34;cleared_events\u0026#34;]; ok { ... clearedEvents, ok := data[\u0026#34;cleared_events\u0026#34;].([]interface{}) eventId := clearedEvents[0].(string) incidentExists, incident_id, err := getIncidentWithId(eventId) ... if incidentExists { err := closeIncident(incident_id) Para cerrar un caso, necesitamos tener el identificador de ServiceNow llamado sys_id. Para obtenerlo, usamos la función getIncidentWithId.\nfunc getIncidentWithId(issueId string) (bool, string, error) { ... // Store Service Now \u0026#34;short_description\u0026#34; shortDescription, ok := incidentMap[\u0026#34;short_description\u0026#34;].(string) // Compare the short_description with the issueId if strings.Contains(shortDescription, issueId) { // If the short_description matches the issueId, return the incident id sys_id, ok := incidentMap[\u0026#34;sys_id\u0026#34;].(string) if !ok { continue } return true, sys_id, nil Paso 3.b Si el estado no es activo y no hay _cleared events_ incluidos, vamos a intentar encontrar el incidente que se abrió. Hay tres cosas que verificamos:\nRule Name - Los nombres de reglas para los eventos que estamos monitoreando tendrán la siguiente estructura _node_. Por ejemplo, BFD_Node_Down. Si estamos viendo BFD_Node_Up, cambiaremos \u0026ldquo;Up\u0026rdquo; por \u0026ldquo;Down\u0026rdquo; y buscaremos BFD_Node_Down en los incidentes devueltos desde ServiceNow. System Ip - Almacene el System-IP contenido en la notificación y coincida con la descripción de cada incidente devuelto. Time - Almaceno el opened_at y verificamos si tiene menos de 12 horas. Esta es una medida totalmente subjetiva, pero mi idea es que los problemas que tardan más de 12 horas en resolverse, tendrían que ser verificados por algún humano. func getIncidentWoutId(ruleName, sysIp string, openTime float64) (bool, string, error) { ... // IncidentMap holds the incidents from Service Now description := incidentMap[\u0026#34;description\u0026#34;].(string) snowTime := incidentMap[\u0026#34;opened_at\u0026#34;].(string) newRuleName := strings.Replace(ruleName, \u0026#34;Up\u0026#34;, \u0026#34;Down\u0026#34;, -1) // Compare Rule Name, system ip and time if strings.Contains(description, newRuleName) \u0026amp;\u0026amp; strings.Contains(description, sysIp) \u0026amp;\u0026amp; diffHours \u0026lt; 12 { sys_id, ok := incidentMap[\u0026#34;sys_id\u0026#34;].(string) sys_id, ok := incidentMap[\u0026#34;sys_id\u0026#34;].(string) if !ok { continue } return true, sys_id, nil Paso 4. Cierra el caso con el sys_id obtenido a través de la función getIncidentWoutId.\nif incidentExists { err := closeIncident(incident_id) if err != nil { fmt.Printf(\u0026#34;Error closing incident: %v\\n\u0026#34;, err) // Handle the error accordingly (e.g., log it, return, etc.) return } } else { fmt.Printf(\u0026#34;Incident doesn\u0026#39;t exist or is older than 12 hours\u0026#34;) } Demo Comenzaremos ejecutando la aplicación en Go. Nota que no estoy usando VS Code para ejecutarla (Ctrl + F5), sino la terminal para permitir las conexiones entrantes.\nNotificación de interfaz Apagamos una de las interfaces de servicio en el router:\nBR10-1#config-transaction BR10-1(config)# interface GigabitEthernet 2 BR10-1(config-if)# shutdown BR10-1(config-if)# commit Commit complete. El servidor recibe la notificación y abre el incidente. El número de incidente es el identificador ServiceNow (sys_id)\nTraigo la interfaz arriba y el incidente se cierra\nObserve que esta notificación tiene la información de cleared_events, por lo que es muy fácil encontrar ese incidente en ServiceNow. Además, la severidad es \u0026lsquo;Medium\u0026rsquo;, por eso es importante establecer el valor correcto en la configuración de Alarm Notifications.\nObserva que State es Resolved y Resolution Notes indica que el incidente se cerró automáticamente a través de Webhooks.\nNotificaciones de BFD y Control Connections Bajemos las sesiones de control y BFD cerrando la apagando la interfaz de transporte\nBR10-1(config)# interface GigabitEthernet 1 BR10-1(config-if)# sh BR10-1(config-if)# commit Commit complete. Se reciben notificaciones y se crean incidentes\nCuando volvemos a habilitar la interfaz, recibimos las notificaciones y también registramos el estado de la interfaz para la interfaz Gig 1 y Tunnel1. Todo esto se refleja en ServiceNow. Estas notificaciones de interfaz no fueron entregadas antes porque se perdió la conectividad con el SD-WAN Manager.\nLecciones aprendidas Es muy importante monitorear el nivel de severidad correcto, de lo contrario podríamos perder notificaciones necesarias para cerrar los incidentes adecuadamente. El SD-WAN Manager puede generar muchas alertas, por lo que el umbral del webhook se vuelve muy importante. Deberías probar para encontrar el número que funcione para tu entorno. ServiceNow asignará una prioridad en función de la urgencia e impacto utilizados para crear el ticket. ServiceNow puede tener políticas que te impidan cerrar incidentes si cierta información no está presente en la interfaz. Familiarízate un poco con las políticas en la interfaz gráfica y Data Policies. Aunque puedes establecer manualmente el \u0026ldquo;sys_id\u0026rdquo; en ServiceNow mediante APIs, sugiero dejarlo como está, ya que poner valores manuales podría causar problemas en el futuro, y este campo debe ser único en tu instancia. Te recomiendo usar el valor generado automáticamente. Puedes usar sitios públicos como este para ver fácilmente el contenido de las notificaciones mientras planificas tus casos de uso. Conclusión Los webhooks son una excelente manera de monitorear nuestro entorno. Al ser notificado exactamente cuándo ocurre un problema en lugar de confiar en encuestas continuas, aumente nuestra capacidad de iniciar sesión y reaccionar rápidamente a lo que esté sucediendo. Puede combinar webhooks con otro tipo de alertas, como correos electrónicos o incluso chat (webex, holgura, etc.) en caso de que necesite alertar a diferentes equipos. Espero que esta publicación te haya dado algunas ideas o active tu curiosidad.\n¡Gracias por leerme!\n","permalink":"http://localhost:1313/rastreando-incidentes-de-sdwan-con-servicenow/","summary":"Aprenda a integrar Cisco SD-WAN con ServiceNow y automatiza la gestión de incidentes","title":"Seguimiento de incidentes SD-WAN con ServiceNow"},{"content":"Introducción Las Redes Definidas por Software (SDN) llegaron con la promesa de simplificar la administración de la red, permitiendo a los equipos de redes automatizar y adoptar un enfoque programático. Cisco creó soluciones como Catalyst Center, ACI, Meraki y Viptela SD-WAN. Esta última introdujo nuevos controladores que cambiaron las reglas que rigen el funcionamiento de la red WAN.\nLas organizaciones que no estaban listas para dar el salto completo a SD-WAN, pero que aún deseaban los beneficios de los principios de SDN, tenían opciones limitadas, como integrarse con sistemas de terceros o depender de Catalyst Center. Aunque estas soluciones resolvían algunos desafíos, quedó una brecha significativa sin cubrir hasta que llegó\u0026hellip; ¡SD-Routing!\n¿Qué es SD-Routing? En términos simples, SD-Routing es el punto medio entre SDN y SD-WAN. Con SD-Routing, las organizaciones pueden adoptar de manera gradual el enfoque de redes definidas por software en su infraestructura existente.\nLa idea detrás de esto es administrar la red no-SD-WAN (también conocida como \u0026ldquo;tradicional\u0026rdquo;) desde un Single Pane of Glass llamado SD-WAN Manager (anteriormente vManage). ¡Por supuesto, también es posible gestionar dispositivos SD-WAN al mismo tiempo!\nA diferencia de SD-WAN, no es necesario conectarse al SD-WAN Controller (anteriormente vSmart), por lo que los protocolos de ruteo existentes se mantienen. Además, se obtiene una capa de seguridad adicional con el SD-WAN Validator (anteriormente vBond), que se encarga de permitir la conexión solo a los dispositivos autorizados.\nBeneficios Algunos de los beneficios de SD-Routing incluyen:\nOnboarding – Los nuevos dispositivos pueden integrarse de forma fácil y rápida utilizando SD-WAN Manager. Configuración – Administra la configuración de tus dispositivos desde un único lugar mediante un método reutilizable llamado Configuration Groups, que permite escalar más rápido. Además, cuenta con workflows optimizados para políticas de seguridad y conectividad a la nube. Monitoreo – Supervisa tus dispositivos, sitios y aplicaciones. Recibe alertas y eventos, y aprovecha las capacidades de notificación de SD-WAN Manager. Gestión de software – Distribuye, instala y activa imágenes de software de manera sencilla y rápida en uno o varios dispositivos. Troubleshooting – Ejecuta diversas operaciones desde vManage, como sesiones SSH, pruebas de velocidad, traceroutes y más. Transición a SD-WAN – Si planeas implementar SD-WAN, SD-Routing es un excelente punto de partida para familiarizarte con SD-WAN Manager y simplificar la migración. 🚀 Descripción general del SD-WAN Manager Déjame darte un recorrido rápido por el SD-WAN Manager y un vistazo a algunas de las características. Si ya lo conoces, probablemente aún te sorprenderá el nuevo aspecto del 20.13. ¡Te lo enseño!\nDescripción general de la red Cuando iniciamos sesión por primera vez, se presenta un overview de la red para que podamos determinar rápidamente cuántos dispositivos y controladores están conectados, información de las aplicaciones, salúd de los equipos y más.\nOye, ¿a dónde se fue el Controller (vSmart)?\nSD-WAN Manager 20.13\nLa apariencia magnética te recordará a otros productos de seguridad de Cisco o Meraki, esto es genial para mantener la experiencia consistente. Observe que arriba a la derecha hay un botón que te permite activar el modo SD-Routing, esto es muy útil para mostrar la información referente a SD-Routing y la razón por la que no vemos el Controller.\nMonitoreo de red Si queremos ver información más detallada del dispositivo, podemos visitar la pestaña devices. SD-WAN Manager está constantemente actualizando esta información, por lo que tenemos una vista precisa. Nota como los dispositivos se muestran como SD-Ruting.\nBR20 no tiene una buena salud debido a la alta utilización de la memoria, ¿podríamos saber cuándo comenzó esto? Hagamos doble clic en él.\nComenzó a ir más allá del 75% alrededor de las 12:30, esto se debió a que activé Performance Monitor para obtener información del rendimiento de las aplicaciones.\nCentrémonos en el menú izquierdo, mira las opciones de monitoreo disponibles que incluyen aplicaciones, funciones de seguridad e información en tiempo real. La sección Troubleshooting es el lugar para usar las herramientas que mencioné anteriormente.\nConfiguración En las versiones 20.13/17.13 se agregó soporte para SD-Routing Configuration Groups. Con ellos, puedes crear Feature Profiles basados en parcels, que son elementos individuales que, en conjunto, conforman toda la configuración del router.\nEn la versión 20.13, los siguientes parcels están disponibles:\nTenemos el CLI Configuration Profile para aplicar cualquier configuración que no esté disponible a través de parcels. Podemos definir variables para hacer nuestro Profile reutilizable en múltiples dispositivos. También es posible usar un CLI Profile completo en lugar de parcels.\nPor cierto, si tienes una combinación de dispositivos SD-WAN y SD-Routing, verás ambos Configuration Groups en la lista. Actualmente, SD-WAN tiene un conjunto más amplio de parcels, pero con el tiempo, SD-Routing también recibirá más configuraciones sin depender de CLI.\nWorkflows La workflows library nos ayudará a realizar fácilmente ciertas acciones como onboarding, configuración de seguridad, actualizaciones de software, entre otras.\nEn lugar de hacer clic en múltiples páginas, podemos seguir un flujo paso a paso con toda la información necesaria en un solo lugar. Personalmente, me gusta cómo los workflows simplifican las cosas.\nConectividad con la nube Es muy probable que tu organización utilice algún tipo de conectividad a la nube, ya sea para acceder a aplicaciones o ejecutar cargas de trabajo. SD-Routing cubre esta necesidad.\nPuedes automatizar la conexión con el proveedor de nube, extendiendo tu red para acceder a esos recursos sin complicaciones.\nHay múltiples opciones. También se proporciona algo de esto para SD-WAN, por lo que recomiendo verificar la Guía de configuración de SD-Routing.\nConclusión El propósito de esta publicación es mostrar lo que es posible con SD-Routing y el vacío que busca llenar. Adoptar esta tecnología puede impactar positivamente los flujos de trabajo operativos, mejorar la agilidad de la red y optimizar la utilización de recursos.\nSi tu organización aún no ha adoptado ninguna forma de SDN, te invito a reflexionar sobre tus procesos diarios, identificar los principales desafíos y pensar en cómo SD-Routing podría ayudarte a resolverlos.\n¡Déjame saber qué opinas y nos vemos en el próximo post! 🚀\n","permalink":"http://localhost:1313/sd-routing-revoluciona-la-gestion-de-red/","summary":"Explora cómo SD-Ruting puede ayudarte de manera simple y efectiva a administrar y monitorear equipos autónomos (IOX-XE regular, sin SD-WAN).","title":"Un nuevo capítulo: SD-Routing revoluciona la gestión de red"},{"content":"Introducción Para la publicación final de esta serie, exploremos la opción restante para manejar el tráfico cuando no se cumple SLA: Fallback a Best Path. Se introdujo en 20.5/17.5 y proporciona más flexibilidad y selección de ruta mejorada en comparación con las otras opciones. Entendamos por qué fue creado.\nMotivación Con los [métodos anteriores] (/desmitificación-AAR-Enderstanding-Diferent-SceneRios/), el tráfico lo haría:\nse eliminará, rara vez se usan casos de uso específicos que se aplican a una pequeña cantidad de entornos. Esté equilibrado en las rutas disponibles, ampliamente utilizada, sin embargo, el tráfico podría estar utilizando la ruta de peor desempeño. Tome el siguiente ejemplo\nTunnel 2 claramente tiene el peor rendimiento, sin embargo, con el método load balance, el tráfico aún podría usarlo en función del algoritmo de hash. ¿Cómo superamos esta situación? Probablemente lo hayas adivinado: _ ** Falta a la mejor ruta ** _\nFuerte a la mejor ruta Veamos cómo lo describe la documentación:\nCuando el tráfico de datos no cumple con ninguno de los requisitos de la clase SLA, esta característica le permite seleccionar la mejor secuencia de criterios de ruta del túnel utilizando el túnel mejor alternativo.\nEl gerente de Cisco SD-WAN usa Best of Weor (Bow) para encontrar el mejor túnel cuando ningún túnel cumple con ninguno de los requisitos de la clase SLA.\nhttps://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-ware-routing.html\nlo mejor de lo peor Veamos cómo funciona Bow con el siguiente ejemplo:\nEl requisito de latencia de SLA se establece en 8. Ninguno de los túneles lo satisface, pero el túnel 1 es el más cercano, lo que lo convierte en lo mejor de peor con una latencia de 10.\nLos criterios para elegir el arco son extremadamente flexibles, en este ejemplo utilizamos latencia, otras opciones podrían ser:\nLatencia - Solo latencia Jitter - Solo jitter Pérdida - Solo pérdida Latencia/Jitter - Primera latencia, si son iguales, entonces Jitter Latencia/pérdida - Primera latencia, si son iguales, entonces pérdida Jitter/Latencia - Primer jitter, si son iguales, entonces latencia -. . . pérdida/jitter/latencia - Primera pérdida, luego fase, luego latencia Varianza Vamos un paso más allá, el túnel 3 también está muy cerca de la latencia 8 ms, no sería una mala idea enviar tráfico también en ese túnel. ¿Cómo logramos esto? Bueno, podemos implementar un variance para acomodar pequeñas variaciones al elegir las mejores rutas.\nContinuando con este ejemplo, echemos un vistazo a la selección de arco con una `varianza de 5 ms \u0026lsquo;.\nBow Range = (mejor latencia, mejor latencia + varianza) Rango de arco = (10, 15) La mejor latencia en los túneles es 10 (Túnel 1), observe que esto ** no es ** la latencia configurada en el SLA. Con esta varianza, si algún otro túnel tiene una latencia entre 10 y 15, también se eligirá para enviar tráfico. En nuestro ejemplo, el túnel 3 satisface la condición, por lo que ahora el túnel 1 y el túnel 3 se utilizarán como túneles fallback.\nComo puede ver, el túnel 2 ya no se considera. ¡Excelente!\nConfiguración Clase SLA Para usar este método, lo primero que debemos hacer es modificar nuestra clase SLA para indicar que debe buscar la ruta de mejor rendimiento cuando no se cumple SLA. Nuestra configuración se ve así:\nSLA-CLASS Custom-SLA Pérdida 1 Latencia 250 Jitter 100 alero-mejor túnel pérdida de criterios Varianza de pérdidas 2 Observe que seleccionamos el criteria para ser pérdida 'y un _variance_ de 2`. La varianza es un parámetro ** opcional **.\nPolítica AAR A continuación, en la política de AAR especificamos la acción cuando no se cumple SLA: Fallback a Best Path\nsecuencia 1 fósforo Fuente-IP 172.16.10.0/24 Destino-IP 172.16.20.0/24 acción SLA-CLASS Custom-SLA No hay clase SLA estricta MPLS de color de clase SLA SLA-Class Fallback-to-Best-Path Mantengamos la misma dinámica y construamos un diagrama:\nEscenarios Usando la misma topología exploremos algunas situaciones\nMPLS compatible, biz-internet/private1 no conforme Iniciaré el tráfico de Branch10 -\u0026gt; Branch 20 y lo capturaré con NWPI. MPLS tiene métricas KPI perfectas (0, 0, 0)\nObserve cómo fallback to Best Path se establece en `no \u0026lsquo;y el tráfico coincide con el SLA y el color preferido. Veamos también el siguiente comando de verificación de BR10. `` BR10#show sdwan tunnel sla \u0026lt;. . .\u0026gt; Túnel SLA-Class 1 SLA-NAME Custom-SLA SLA-Loss 1 SLA-Latencia 250 sla-jitter 100 RETROCEDER Remoto t sla sla Sistema DST SRC Local t remota media media media clase de clase PROTO SRC IP DST Puerto IP Puerto IP Color Pérdida de color Pérdida de latencia Jitter Índice SLA Nombre de clase Índice Gre 21.1.10.2 21.1.20.2 0 0 1.1.0.20 MPLS MPLS 0 0 0 0,1 all_tunnels, Custom-SLA Ninguno Gre 21.1.10.2 31.1.20.2 0 0 1.1.0.20 MPLS Biz-Internet 0 0 0 0,1 all_tunnels, Custom-SLA Ninguno GRE 21.1.10.2 41.1.20.2 0 0 1.1.0.20 MPLS Private1 0 0 0 0,1 all_tunnels, Custom-SLA Ninguno ``\nAlgunos comentarios sobre este resultado:\nEl hecho de que veamos túneles enumerados en Custom-SLA, nos dice que hay túneles que cumplen con la pérdida, la latencia y la fluctuación. Esto se espera ya que nuestro MPLS está teniendo métricas perfectas. Vea que esta clase SLA tiene un identificador numérico de 1-Túnel SLA-Class 1. Verá referencia a este número en breve. Fallback SLA Class Index está configurado en Ninguno, esto significa que estos túneles no se están utilizando como túneles de respaldo, esto quedará claro en un segundo. mpls/biz-inernet/private1 no conforma pero varianza de reunión Ahora que no tenemos transportes que cumplan con el SLA, verifiquemos cómo lo mostrará NWPI:\nObserve que ahora NWPI está indicando que fallback a la mejor ruta está en uso.\nPrivate1 fue elegido para enviar este flujo en particular, pero ¿hay otros túneles que pudieran usarse? Vamos a ver BR10 nuevamente.\n`` BR10# show sdwan tunnel sla Túnel SLA-Class 0 sla-name all_tunnels SLA-Loss 0 SLA-Latencia 0 sla-jitter 0 RETROCEDER SLA SLA remoto Sistema DST SRC T Local T Remote media media media clase PROTO SRC IP DST Puerto IP Puerto IP Color Pérdida de color Pérdida de latencia Jitter Índice SLA Nombre de clase Índice Gre 21.1.10.2 21.1.20.2 0 0 1.1.0.20 MPLS MPLS 18 0 0 0 0 all_tunnels Ninguno GRE 21.1.10.2 31.1.20.2 0 0 1.1.0.20 MPLS Biz-Internet 9 0 0 0 all_tunnels Ninguno Gre 21.1.10.2 41.1.20.2 0 0 1.1.0.20 MPLS Private1 11 0 0 0 all_tunnels Ninguno Gre 31.1.10.2 21.1.20.2 0 0 1.1.0.20 Biz-Internet Mpls 4 0 0 0 all_tunnels 1 Gre 31.1.10.2 31.1.20.2 0 0 1.1.0.20 Biz-Internet Biz-Internet 2 0 0 0 0 all_tunnels 1 Gre 31.1.10.2 41.1.20.2 0 0 1.1.0.20 Biz-Internet Private1 4 0 0 0 all_tunnels 1 GRE 41.1.10.2 21.1.20.2 0 0 1.1.0.20 Private1 MPLS 3 0 0 0 0 all_tunnels 1 GRE 41.1.10.2 31.1.20.2 0 0 1.1.0.20 Private1 Biz-Internet 6 0 0 0 all_tunnels Ninguno GRE 41.1.10.2 41.1.20.2 0 0 1.1.0.20 Private1 Private1 3 0 0 0 0 all_tunnels 1\nTúnel SLA-Class 1 SLA-NAME Custom-SLA SLA-Loss 1 SLA-Latencia 250 sla-jitter 100\nBR10# ``\nComentarios sobre este resultado:\nHay ** no ** túneles que cumplen con nuestro custom-sla Incluso si MPLS es el color preferido, ** no es ** considerado porque no cumple con el rango de varianza de pérdida. Hay 5 túneles que satisfacen la varianza. Observe cómo algunos túneles tienen una clase SLA de Fallback SLA Index establecido en 1, lo que significa que están sirviendo como alternativos para SLA-Class 1 (Custom-SLA). En este caso, el ** arco ** es biz-instantet-biz-insternet tunnel con una pérdida media de 2. El variance se establece en 2, por lo que el rango de arco es 2-4. Los túneles que satisfacen la gama de arco también se utilizarán para reenviar el tráfico. Dependiendo del hash de equilibrio de carga, se eligirán diferentes túneles `` BR10#show Sdwan Policy Service-Path VPN 10 Interfaz GigabitEthernet 3 Fuente-IP 172.16.10.2 Dest-IP 172.16.20.2 Protocolo 6 Dest-Port 22 Siguiente salto: Gre Fuente: 31.1.10.2 Destino: 21.1.20.2 Color local: Biz-Internet Color remoto: Sistema remoto MPLS IP: 1.1.0.20\nBR10#show SDWAN Policy Service-Path VPN 10 Interfaz GigabitEthernet 3 Fuente-IP 172.16.10.56 Dest-IP 172.16.20.2 Protocolo 6 Dest-Port 24 Siguiente salto: Gre Fuente: 31.1.10.2 Destino: 41.1.20.2 Color local: Biz-Internet Color remoto: Private1 Sistema remoto IP: 1.1.0.20 ``\nPodemos ver dos túneles diferentes biz -internet - mpls y biz -internet - privado\nLatencia fuera de cumplimiento Hasta ahora hemos estado jugando solo con pérdida, porque los criterios de alojamiento estaban establecidos en la pérdida. Veamos qué sucede cuando un criterio diferente no se cumple. Estableceré la latencia del SLA a 15 ms. .\n`` BR10#show sdwan política de vsmart From-vsmart SLA-Class Custom-SLA Pérdida 1 latencia 15 Jitter 100 alero-mejor túnel pérdida de criterios Varianza de pérdidas 2\n``\nDespués de presentar algo de latencia, vemos algo interesante:\n`` BR10#show sdwan tunnel sla Túnel SLA-Class 0 sla-name all_tunnels SLA-Loss 0 SLA-Latencia 0 sla-jitter 0 RETROCEDER SLA SLA remoto Sistema DST SRC T Local T Remote media media media clase PROTO SRC IP DST Puerto IP Puerto IP Color Pérdida de color Pérdida de latencia Jitter Índice SLA Nombre de clase Índice Gre 21.1.10.2 21.1.20.2 0 0 1.1.0.20 MPLS MPLS 0 20 1 0 all_tunnels 1 GRE 21.1.10.2 31.1.20.2 0 0 1.1.0.20 MPLS Biz-Internet 0 20 1 0 all_tunnels 1 Gre 21.1.10.2 41.1.20.2 0 0 1.1.0.20 MPLS Private1 0 20 0 0 all_tunnels 1 Gre 31.1.10.2 21.1.20.2 0 0 1.1.0.20 Biz-Internet Mpls 0 21 2 0 all_tunnels 1 Gre 31.1.10.2 31.1.20.2 0 0 1.1.0.20 Biz-Internet Biz-Internet 0 21 2 0 all_tunnels 1 Gre 31.1.10.2 41.1.20.2 0 0 1.1.0.20 Biz-Internet Private1 0 21 2 0 all_tunnels 1 Gre 41.1.10.2 21.1.20.2 0 0 1.1.0.20 Private1 MPLS 0 16 1 0 all_tunnels 1 GRE 41.1.10.2 31.1.20.2 0 0 1.1.0.20 Privado1 Biz-Internet 0 16 0 0 all_tunnels 1 GRE 41.1.10.2 41.1.20.2 0 0 1.1.0.20 Private1 Private1 0 16 0 0 all_tunnels 1\nTúnel SLA-Class 1 SLA-NAME Custom-SLA SLA-Loss 1 SLA-Latencia 15 sla-jitter 100\nBR10# ``\n¡Todos los túneles se usan como túneles respaldados porque todos tienen un 0% de pérdida! ¿Es esta la situación ideal? Esto es discutible, tal vez para algunos tipos de tráfico está bien, pero para otros probablemente desee tener un segundo o tercer criterio para elegir los mejores túneles de respaldo.\nCriterios de arco múltiple Para la última prueba, veamos qué sucede cuando seleccionamos múltiples criterios para seleccionar el arco. Agregaré latencia a los criterios de SLA.\nBR10#show sdwan política de vsmart From-vsmart SLA-Class Custom-SLA Pérdida 1 latencia 15 Jitter 100 alero-mejor túnel latencia de pérdida de criterios Varianza de pérdidas 2 Lo que esperamos es que si alguno de los KPI no cumple, el arco se decidirá en base a:\nPérdida media más baja. Si hay un empate, entonces Latencia más baja Verifiquemos `` BR10#show sdwan tunnel sla Túnel SLA-Class 0 sla-name all_tunnels SLA-Loss 0 SLA-Latencia 0 sla-jitter 0 RETROCEDER SLA SLA remoto Sistema DST SRC T Local T Remote media media media clase PROTO SRC IP DST Puerto IP Puerto IP Color Pérdida de color Pérdida de latencia Jitter Índice SLA Nombre de clase Índice Gre 21.1.10.2 21.1.20.2 0 0 1.1.0.20 MPLS MPLS 0 20 1 0 all_tunnels Ninguno Gre 21.1.10.2 31.1.20.2 0 0 1.1.0.20 MPLS Biz-Internet 0 20 1 0 all_tunnels Ninguno Gre 21.1.10.2 41.1.20.2 0 0 1.1.0.20 MPLS Private1 0 20 1 0 all_tunnels Ninguno Gre 31.1.10.2 21.1.20.2 0 0 1.1.0.20 Biz-Internet Mpls 0 20 1 0 all_tunnels Ninguno Gre 31.1.10.2 31.1.20.2 0 0 1.1.0.20 Biz-Internet Biz-Internet 0 20 1 0 all_tunnels Ninguno Gre 31.1.10.2 41.1.20.2 0 0 1.1.0.20 Biz-Internet Private1 0 21 1 0 all_tunnels Ninguno GRE 41.1.10.2 21.1.20.2 0 0 1.1.0.20 Private1 Mpls 0 16 0 0 all_tunnels 1 GRE 41.1.10.2 31.1.20.2 0 0 1.1.0.20 Privado1 Biz-Internet 0 16 0 0 all_tunnels 1 GRE 41.1.10.2 41.1.20.2 0 0 1.1.0.20 Private1 Private1 0 16 0 0 all_tunnels 1\nTúnel SLA-Class 1 SLA-NAME Custom-SLA SLA-Loss 1 SLA-Latencia 15 sla-jitter 100\nBR10# ``\nEstá claro que la pérdida no se usó para elaborar el arco, de lo contrario, veríamos todos los túneles actuando como respaldo para el índice de clase SLA 1. En cambio, se seleccionaron túneles con latencia más baja. Tenga en cuenta que podría haber agregado una varianza de latencia para incluir otros túneles con números similares.\nConclusión A través de las últimas tres publicaciones, hemos sido testigos de AAR como una funcionalidad crítica de SD-WAN para proteger el SLA de nuestras aplicaciones. Espero que después de explicar y verificar diferentes escenarios, ahora tenga una mejor comprensión y se sienta más seguro de probar AAR dentro de su infraestructura SD-WAN. Guía] (https://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-ware-routing.html#config-variance-best-tunnel-path) es muy completo, lo que está familiarizado con it y use lo necesita.\nDéjame saber tus pensamientos en los comentarios.\n¡Nos vemos pronto!\n","permalink":"http://localhost:1313/simplificando-aar-3-3-fallback-to-best-path/","summary":"Aprende cómo AAR puede ayudarte a mejorar la experiencia del usuario y aplicación con Cisco SD-WAN","title":"Simplificando AAR: 3/3 Fallback to Best Path"},{"content":"Introducción Bienvenido de nuevo a la segunda entrega de mi serie en Application Aware Routing (AAR). En mi publicación anterior, discutimos los conceptos básicos de BFD y SLAs, estableciendo las bases para comprender cómo AAR optimiza el rendimiento de la red en función de los requisitos de las aplicaciones. También tocamos brevemente la configuración de AAR con un ejemplo simple.\nAhora, vamos a ver en profundidad diferentes configuraciones de AAR cuando no hay túneles que cumplan con los SLAs, más específicamente nos concentraremos en el comportamiento de strict/drop y Preferred Backup SLA.\nTopología y configuración inicial Comencemos con una topología simple\nNo estoy limitando los túneles entre los colores, por lo que tenemos un total de 4 túneles en cada borde WAN.\nmpls - mpls mpls - biz-inet biz-inet- mpls biz-inet - biz-inet Este es el Hello interval de BFD y la configuración de app-route para todos los dispositivos; esto es lo más relevante para AAR. Si no estás familiarizado con ello, te recomiendo que revises mi última publicación antes de continuar.\nhello-interval 1000 bfd app-route multiplier 3 bfd app-route poll-interval 120000 Escenario 1: SLA not met - Strict/Drop Nuestra política de AAR está usando el SLA Business-Critical. Vou a introducir pérdida de paquetes para demostrar cómo cambia el tráfico.\nBR10#show sdwan policy from-vsmart from-vsmart sla-class Business-Critical loss 1 latency 250 jitter 100 from-vsmart app-route-policy _VPN10_AAR vpn-list VPN10 sequence 1 match source-ip 172.16.10.0/24 destination-ip 172.16.20.0/24 action sla-class Business-Critical sla-class strict sla-class preferred-color mpls sequence 11 match source-ip 172.16.20.0/24 destination-ip 172.16.10.0/24 action sla-class Business-Critical sla-class strict sla-class preferred-color mpls from-vsmart lists vpn-list VPN10 vpn 10 Leamos lo que dice la documentación sobre nuestra configuración:\nsla-class preferred-color mpls\nsla-class sla-class-name preferred-color color - Para configurar un túnel específico para el tráfico de datos que cumpla con una clase de SLA, incluye la opción preferred-color, especificando el color del túnel preferido. Si más de un túnel cumple con el SLA, el tráfico se enviará a través del túnel preferido. Si no hay un túnel del color preferido disponible, el tráfico se enviará a través de cualquier túnel que cumpla con la clase de SLA. Si ningún túnel cumple con el SLA, el tráfico de datos se enviará a través de cualquier túnel disponible.\nhttps://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-aware-routing.html\nAquí hay un diagrama para visualizarlo mejor:\nTen en cuenta que incluso si tanto Biz-Internet como MPLS cumplen con el SLA, solo se utilizará MPLS.\nSí, Biz-Internet se utilizará incluso si no está especificado como un color preferido si el color preferido no cumple con el SLA. Desde mi experiencia, esta es una fuente frecuente de confusión, ya que la expectativa suele ser que, si MPLS no cumple con el SLA, se ejecutará la acción de SLA not met sin considerar el resto de los colores.\nsla-class strict\nHaz clic en Strict/Drop para hacer un match estricto de la clase SLA. Si no hay un túnel de plano de datos disponible que satisfaga los criterios de SLA, se tira el tráfico.\nhttps://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-ware-routing.html\nAhora el diagrama se ve así:\nPrueba 1 - MPLS/Biz-internet cumplen SLA Inicio el tráfico de Branch 10 -\u0026gt; Branch 20 y lo capturo con NWPI. Tanto MPLS como Biz-Internet están teniendo métricas de KPI perfectas (0 pérdida, 0 latencia, 0 jitter)\nBR10-PC1#ssh -l admin 172.16.20.2 Password: Podemos ver que el color Actual Color mpls y Tunnel Match Reason is Matched sla and pref encap color. Todo funcionando de acuerdo con nuestra definición de política.\nPrueba 2- Biz-internet cumple, MPLS no cumple con SLA Introduzco el 3% de pérdida de paquetes en el enlace MPLS. Veamos qué pasa.\nAhora, nuestro túnel MPLS está por encima del 1% de pérdida, por lo que ya no es elegible. Confirmamos que el túnel biz-internet se usa porque cumple con el sla - Tunnel match reason es matched sla and color any\nPrueba 3-MPLS/Biz-internet no cumplen SLA Nuestra última prueba para este escenario será estropear los SLA para ambos transportes. Nuevamente, introduzco el 3% de pérdida de paquetes en ambos MPLS y Biz-internet.\nComo se esperaba, ahora el tráfico se está tirando en BR10, ya que no hay transportes que coincidan con el SLA. Nota como DROP_REPORT indica SdwanDataPolicyDrop\nEscenario 2: Backup SLA Preferred Color Exploremos un nuevo escenario, agregaremos un transporte adicional.\nNuestra configuración de políticas tendrá ligeros cambios. Es importante destacar que, al usar la opción Backup SLA preferred color, la única acción disponible cuando el SLA no se cumple será Load Balance.\nBR10#show sdwan policy from-vsmart from-vsmart sla-class Business-Critical loss 1 latency 250 jitter 100 from-vsmart app-route-policy _VPN10_AAR vpn-list VPN10 sequence 1 match source-ip 172.16.10.0/24 destination-ip 172.16.20.0/24 action backup-sla-preferred-color private1 sla-class Business-Critical no sla-class strict sla-class preferred-color mpls sequence 11 match source-ip 172.16.20.0/24 destination-ip 172.16.10.0/24 action backup-sla-preferred-color private1 sla-class Business-Critical no sla-class strict sla-class preferred-color mpls from-vsmart lists vpn-list VPN10 vpn 10 Nuevamente, veamos qué dice la documentación:\nbackup-sla-preferred-color private1\nCuando ningún túnel cumple con el SLA, se puede elegir cómo manejar el tráfico:\nbackup-sla-preferred-color colors: Dirige el tráfico de datos a un túnel específico. El tráfico de datos se envía a través del túnel configurado si la interfaz de dicho túnel está disponible; si no lo está, el tráfico se enviará por otro túnel disponible. Se pueden especificar uno o más colores.\nhttps://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-aware-routing.html\nPara ponerlo visualmente\nPrueba 1- MPLS/Private1 complen con el SLA, Biz-Internet no cumple Comenzaremos con la suposición de que Biz-Internet no cumple con el SLA, por lo que tenemos dos transportes disponibles: MPLS y Private1. Inicio el tráfico.\nBR10-PC1#ssh -l admin 172.16.20.2 Password: Nota como SLA Strict tiene un varlo de No y el MPLS cumple con el SLA y se usa.\nPrueba 2 - Private1 cumple con el SLA, MPLS/Biz-internet no cumplen Para la segunda prueba, estamos introduciendo pérdida en el transporte MPLS. Con esto, el único transporte que cumple con el SLA es Private1, que también es el color preferido de respaldo para el SLA. Veamos cómo se ve.\nEn el Tunnel Match Reason podemos ver claramente que el SLA se cumple a través de un color que no es el preferido (Private1). ¿Qué crees que sucederá si Private1 no cumple con el SLA?\nPrueba 3 - MPLS/Private1/Biz-Internet No confunde Private1 es el único transporte que cumple con el SLA, me encargaré de eso al introducir la pérdida de paquetes.\nDe nuevo (!) Private1 se usa, pero ahora el tráfico coincide con el SLA por defecto, en otras palabras, no hay túneles que coincidan con el SLA, por lo que se utilizará el túnel marcado backup preferred.\nBono Private1 no disponible\nEl resultado después de apagar la interfaz Private1, aún sin ningún túnel que cumpla con el SLA. Podemos ver que se realiza una coincidencia flexible en los túneles (se puede elegir cualquier túnel disponible).\nBiz-internet cumple, MPLS/Private1 no cumplen\nEl resultado después de que biz-internet vuelve a tener valores de pérdida cero, mientras que private1 no cumple con el SLA. Aunque no sea el color preferido, aún cumple con el SLA, por lo que es seleccionado.\nComo nota final, ten en cuenta que AAR siempre intentará usar los túneles que cumplan con el SLA especificado, no te confundas solo porque los nombres de los colores no están explícitamente mencionados en la configuración.\nEn la Siguiente publicación, exploraremos la opción restante Fallback to Best Path. ¡Nos vemos allí!\n","permalink":"http://localhost:1313/simplificando-aar-analizando-diferentes-escenarios/","summary":"Aprende cómo AAR puede ayudarte a mejorar la experiencia del usuario y aplicación con Cisco SD-WAN","title":"Simplificando AAR: 2/3 Analizando diferentes escenarios"},{"content":"Introducción Piensa en las tecnologías de enrutamiento que existen; la mayoría de ellas han mejorado mucho en reaccionar ante fallos de enlaces y cortes de energía mediante protocolos como OSPF LFA/FRR, EIGRP Feasible Successor, BGP PIC, etc.\nSin embargo, estos protocolos no son tan eficaces cuando se trata de abordar problemas como la degradación del rendimiento de la red durante brownouts, que pueden ser causados por fluctuaciones de energía o congestión en los enlaces. Estos escenarios presentan nuevos desafíos para los cuales los protocolos de enrutamiento tradicionales no tienen herramientas adecuadas.\nAquí es donde Application Aware Routing llega al rescate.\nA pesar de generar cierta confusión entre los clientes y quienes están aprendiendo sobre SD-WAN, Application Aware Routing (AAR) representa una ventaja fundamental de esta tecnología.\nEn esta serie, exploraremos los conceptos básicos para comprender los principios y comportamientos clave que nos permitirán analizar diferentes escenarios.\nUsaremos NWPI para entender mejor cómo funciona todo. Si no estás familiarizado con NWPI, te recomiendo leer este post que escribí sobre el tema.\nAAR explicado en 5 líneas Using IPSec tunnels formed between WAN Edges, BFD packets will be sent across them to measure the **loss, latency Utilizando túneles IPSec formados entre los WAN Edges, se enviarán paquetes BFD a través de ellos para medir la pérdida, latencia y jitter (KPIs).\nLos usuarios pueden definir SLAs para distintos tipos de tráfico (voz, web, video, etc.) y configurar políticas de AAR para garantizar que el tráfico se envíe a través de rutas que cumplan con el SLA.\nSi en algún momento la ruta deja de cumplir con el SLA, el tráfico será redirigido automáticamente a una ruta que sí lo haga.\nSencillo, ¿verdad? 😃\nSLAs El Service Level Agreement (SLA) se refiere a la cantidad de pérdida, latencia y jitter que una aplicación puede tolerar mientras sigue funcionando correctamente. Su definición debe ser precisa y realista según el tipo de tráfico y el entorno de la red.\nPor ejemplo, si estamos definiendo un SLA para voz, debemos conocer los valores aceptables de pérdida, latencia y jitter.\nSi nuestro SLA de voz tuviera estos valores:\nPérdida: 5% Latencia: 350 ms Jitter: 200 ms Es muy probable que las llamadas tengan una mala calidad.\nEn cambio, estos valores serían mucho mejores:\nPérdida: 1% Latencia: 150 ms Jitter: 50 ms También es importante considerar la naturaleza del entorno al definir estos valores. Hay lugares donde los proveedores pueden ser menos confiables, el tráfico puede recorrer grandes distancias y los tipos de transporte pueden variar (satélite vs. fibra, por ejemplo).\nPuedes utilizar los datos históricos de KPIs en SD-WAN Manager para construir una línea base y definir un SLA adecuado.\nLa definición de SLA se verá así:\nsla-class Custom-SLA loss 1 latency 250 jitter 100 BFD El protocolo Bidirectional Forwarding Detection (BFD) se usa para detectar rápidamente fallas entre dos dispositivos de red. En SD-WAN, también se usa para medir la pérdida, la latencia y el jitter. Los parámetros que usamos para configurar BFD dictarán qué tan rápido SD-WAN detectará y reaccionará a los problemas de red.\nHello Interval Este intervalo representa la frecuencia con la que se enviará un paquete de BFD. Está configurado por color en milisegundos; El valor predeterminado por defecto es 1000 ms. Este paquete viajará hasta el WAN Edge del otro extremo y regresará. De esta manera, se medirán los KPIs para cada paquete.\nsdwan interface GigabitEthernetX tunnel-interface color mpls hello-interval 1000 \u0026lt;\u0026lt;\u0026lt; Cada modelo de router tiene una capacidad definida de túneles (cantidad de túneles que puede formar). Reducir el hello interval por debajo de 1 segundo disminuye la capacidad de túneles.\nTen esto en cuenta para evitar posibles problemas por exceder la capacidad del hardware.\nApp route poll interval Digamos que tenemos un intervalo de votación de 4000 ms. Cada 4 segundos se construye un nuevo cubo, este cubo tendrá su propio índice. ** El intervalo de encuesta predeterminado ** es de 600,000 ms (10 minutos).\nA medida que el WAN Edge sigue enviando paquetes, el poll interval es el temporizador que ayuda a organizarlos en buckets. Estos buckets se utilizan para calcular las estadísticas del túnel.\nEl poll interval se configura a nivel de dispositivo (per box basis), lo que significa que se aplica de la misma manera para todos los colores.\nPor ejemplo, si el poll interval es de 4000 ms, cada 4 segundos se crea un nuevo bucket, y cada uno tendrá su propio índice.\nEl valor por defecto del poll interval es 600,000 ms (10 minutos).\nPara configurar el poll interval\nbfd app-route poll-interval 60000 La pérdida promedio, la latencia y el jitter, se calcularán para cada poll interval. Podemos verificar esto directamente en SD-WAN Manager -\u0026gt; Monitor -\u0026gt; Real Time -\u0026gt; App Route Statistics\nMultiplicador de ruta de la aplicación Para configurar el multiplicador\nbfd app-route multiplier 3 El multiplicador indica la cantidad de buckets que se utilizarán para calcular las estadísticas del túnel, lo que influirá en la decisión de redirigir el tráfico cuando las condiciones de la red empeoren.\nPara esta ilustración, se usa un multiplicador de 3.\nPor defecto, el multiplicador está configurado en 6.\nObserva que cada bucket contiene 4 paquetes.\nhello interval (s) x Poll interval (s)\nEn el mundo real, 4 paquetes serían ** demasiado bajo **. Si tomamos todos los valores predeterminados, terminaríamos con un cubo de 600 paquetes. Consulte la [Guía de implementación de AAR] (https://www.cisco.com/c/en/us/td/docs/solutions/cvd/sdwan/cisco-sdwan-application-ware-routing-deploy-guide.html) para obtener más detalles y opciones.\nDespués de llenar todos los buckets, se calcularán las estadísticas del túnel.\nPodemos visualizar los buckets y los cálculos de la media. Fíjate que los valores son los mismos para todos los buckets. No te confundas con las columnas de avg loss, latency y jitter que se mostraron antes.\nEste mecanismo actúa como una ventana deslizante que descartará el bucket más antiguo para hacer espacio al nuevo, recalculando las estadísticas del túnel cada poll interval.\nConfiguración de la política AAR Ahora que tenemos una mejor comprensión sobre SLA y BFD, podemos crear las reglas que gobernarán el comportamiento de nuestra política AAR. Así es como se verá en SD-WAN Manager.\nEsta es probablemente la forma más simple que podemos configurar. El tráfico de Google Apps será matcheado y se utilizarán los transportes que coincidan con nuestro Custom-SLA de manera indiferente.\nEn otras palabras, si tenemos 3 transportes diferentes y todos cumplen con el SLA, el tráfico se balanceará entre ellos.\n¿Qué pasa si queremos que el tráfico prefiera uno de los transportes? Bueno, podemos especificar un Prefered Color como se muestra a continuación:\nEn esta secuencia, las aplicaciones de voz se emparejan, y el SLA de los transportes debe coincidir con el de Bussiness-Critical. Se dará preferencia a MPLS si cumple con el SLA. La acción cuando no se cumple el SLA se configura en Load Balance entre los colores disponibles.\nA primera vista, esto parece muy simple, pero hay algunos detalles que debemos conocer si queremos entender completamente cómo se comportará el tráfico bajo diferentes circunstancias.\nTe invito a leer mi próximo post donde exploraremos algunos escenarios para tener un mejor entendimiento de esta tecnología. ¡Nos vemos allá!\n","permalink":"http://localhost:1313/simplificando-aar-1-3-las-bases/","summary":"Aprende cómo AAR puede ayudarte a mejorar la experiencia del usuario y aplicación con Cisco SD-WAN","title":"Simplificando AAR: 1/3 Las bases"},{"content":"Motivación: El escenario clásico de crisis Imagina comenzar el día en el equipo de redes, solo para ser bombardeado con quejas sobre la principal aplicación interna. Empiezas a investigar. ¿Dónde se encuentra el problema? ¿Está aislado o afectando múltiples lugares? ¿Cuándo comenzó el problema? ¿Cuál es el impacto?\nA continuación, intentas conectar con alguien que te ayude a verificar los conceptos básicos. DHCP y DNS funcionan. Gateway es accesible. ¡La conectividad a otros objetivos en el mismo DC es intermitente! Está empezando a ser raro \u0026hellip;\nEn este punto, cada minuto cuenta y un proceso de solución de problemas adecuado debe implementarse para verificar todos los dispositivos involucrados y aislar la raíz del problema. Comienza a tomar capturas de paquetes y trazas en diferentes puntos de la red, verificas los contadores, las sesiones BFD e IPSEC, buscas inconsistencias en la tabla OMP y enrutamiento, verificas largas configuraciones de políticas y parámetros de puerto, una cosa a la vez. Dos horas más tarde (¡con suerte!) tú y tu equipo finalmente llegan a la causa raíz\u0026hellip;\n¿Qué hizo Cisco al respecto? Teniendo en cuenta el nivel de complejidad y los esfuerzos necesarios para resolver los problemas de la red, Cisco creó - Network Wide Path Insights (NWPI) - para facilitar la solución de problemas de nuestra WAN. NWPI se introdujo por primera vez la versión 20.4 y con cada lanzamiento siguió mejorando. En la versión 20.9 hay varias mejoras importantes que lo ayudarán a determinar rápidamente lo que está sucediendo. ¿Quieres verlo en acción? ¡Vamos!\n** Topología ** Usaremos este escenario para ejecutar nuestro traza NWPI. No existe una política centralizada, como resultado, tenemos un full mesh y el tráfico podría fluir en cualquiera de los túneles disponibles.\n** Comprensión de NWPI ** En VManage, navegue a la sección Tools para encontrar esta característica. Para comenzar a usarlo, la información mínima que necesita es:\nDonde se genera el tráfico (Site`` ID) segmento de la red (VPN) Device se determina automáticamente. Puedes refinar aún más los filtros para capturar exactamente lo que está buscando.\n20.12.2 NWPI\nUna vez que los filtros estén en su lugar, comienza la traza y observa la magia.\nInsight - Vista básica Veamos los resultados de una pequeña transferencia SCP entre sitios 10 y 20. Esta es la primera información que veremos.\nDe lo anterior, podemos determinar:\n** Dirección de flujo ** - Tráfico que fluye del sitio 10 a 20 ** Equipos edges tocando el tráfico ** - BR10-1 y BR20-2 ** Información de flujo ** - src/dst ips, puertos, protocolo, aplicación, etc. ** Colores involucrados ** - MPLS -\u0026gt; Biz- Internet ** KPIs SD-WAN específicos del flujo ** - Pérdida de paquetes, latencia y jitter ** Porcentaje de pérdida de paquetes ** - en los dispositivos WAN y en los dispositivos Hagamos clic en readout para obtener más información\nLeer Una nueva información está disponible para nosotros:\n** Entrada coincidente en la tabla de enrutamiento ** - 172.10.20.0/24 Provenía de OMP y sus respectivas métricas. ** Candidato y ruta elegida ** - Rutas disponibles que se muestran y elegidas una resaltada en verde. ** Interfaces físicas involucradas ** - tanto para el servicio como para el transporte ** Razón para elegir esta ruta ** - Enrutamiento, sin embargo, tenga en cuenta que las políticas pueden anular la tabla de enrutamiento. Si nos detenemos aquí, ya tenemos mucha información muy útil para comprender el flujo del tráfico, pero ¿qué pasa si necesitamos profundizar? Bueno, ahora exploremos las vistas Advanced\nVistas avanzadas Si conoce [DataPath Packet Trace] (https://www.cisco.com/c/en/us/support/docs/content-networking/adaptive-session-redundancy-asr/117858-technote-asr-00.html#toc-hid-180344474), esta información será familiar. Esencialmente, nos dirá todas las funcionalidades que ejecuta el dispositivo a medida que se procesa el paquete. Algunos ejemplos podrían ser ACL, políticas, reglas FW, DPI, Netflow y mucho más. Hay casos en los que necesitamos determinar si o por qué el dispositivo está dejando caer paquetes, ¡este es el lugar para verificar!\nEn resumen aquí está la información adicional que podemos obtener:\nFuncionalidades - Algunas de ellas dependerán de la configuración, otras siempre estarán allí en un entorno SD-WAN. Drops - Si una característica está dejando caer el tráfico, tiene la información para saber exactamente por qué. Detalles de bajo nivel sobre las funcionalidades - La mayoría de las veces no tendrá que lidiar con esto, pero puede ser útil cuando se comunica con el soporte técnico. Hay mucho más que hacer con esta herramienta, pero creo que esto es suficiente como introducción. Sin embargo, antes de llegar a la conclusión, me gustaría mencionar algunos de los casos de uso en los que esta herramiento es extremadamente útil.\nMal rendimiento de la aplicación Validación de políticas Aislamiento del problema Validación/solución de problemas DIA y SaaS (sí, también puede brindar información sobre el tráfico destinado a Internet) ¿En qué otros escenarios podrías pensar?\nConclusión NWPI es un gran ejemplo del esfuerzo de Cisco para crear una herramienta que puede ayudar a solucionar problemas más rápido y de manera simple y eficiente. Consulte esta guía para saber más sobre las características introducidas y más.\nEn mi experiencia, NWPI no se usa lo suficiente principalmente porque todavía es desconocido para muchos. Te animo a que lo pruebes y eventualmente lo incorpores a su conjunto de herramientas de solución de problemas, estoy seguro de que encontrará algún beneficio.\n","permalink":"http://localhost:1313/introduccion-network-wide-path-insights/","summary":"Aprende a usar la herramienta de troubleshooting más avanzada para tu red Cisco SD-WAN.","title":"Cisco SD-WAN Network Wide Path Insights (NWPI)"},{"content":" ¡Hola! Soy Alex y me encanta compartir mi conocimiento sobre redes y tecnología. He estado en el campo de networking durante los últimos años. Actualmente, aporto mi experiencia en Cisco, donde comencé en el equipo de soporte TAC de R\u0026S. Después de un par de años, hice la transición al equipo de soporte TAC de SD-WAN. Ahora soy Customer Success Specialist para tecnologías como DNA Center y SD-WAN. Obtuve mi CCIE Enterprise en 2022. También me interesa la automatización, la inteligencia artificial y la tecnología en general. Gracias por estar aquí. Espero que encuentres mi blog útil y entretenido. ¡Conectemos! 👇 ","permalink":"http://localhost:1313/es/sobre-mi/","summary":"\u003cdiv style=\"display: flex; align-items: center;\"\u003e\n    \u003cdiv style=\"flex: 1; padding-right: 20px;font-size: 17px;\"\u003e\n        \u003cdiv style=\"line-height: 1; margin-bottom: 1em; \"\u003e\u003c/div\u003e\n      \n\n¡Hola! Soy Alex y me encanta compartir mi conocimiento sobre redes y tecnología. He estado en el campo de networking durante los últimos años.\n\u003cbr\u003e\u003cbr\u003e\nActualmente, aporto mi experiencia en Cisco, donde comencé en el equipo de soporte TAC de R\u0026S. Después de un par de años, hice la transición al equipo de soporte TAC de SD-WAN.\n\u003cbr\u003e\u003cbr\u003e\nAhora soy Customer Success Specialist para tecnologías como DNA Center y SD-WAN. Obtuve mi CCIE Enterprise en 2022. También me interesa la automatización, la inteligencia artificial y la tecnología en general.\n\u003cbr\u003e\u003cbr\u003e\nGracias por estar aquí. Espero que encuentres mi blog útil y entretenido. ¡Conectemos! 👇\n\u003cbr\u003e\u003cbr\u003e\n\u003cdiv style=\"display: flex; gap: 30px; align-items: center;\"\u003e\n\n  \u003ca href=\"https://www.linkedin.com/in/alexruizs/\" target=\"_blank\" style=\"margin-right: 1px;\"\u003e\n\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" style=\"width:30px; height:30px; fill: var(--primary);\"\u003e\u003cpath d=\"M22.23 0H1.77C.8 0 0 .77 0 1.72v20.56C0 23.23.8 24 1.77 24h20.46c.98 0 1.77-.77 1.77-1.72V1.72C24 .77 23.2 0 22.23 0zM7.27 20.1H3.65V9.24h3.62V20.1zM5.47 7.76h-.03c-1.22 0-2-.83-2-1.87 0-1.06.8-1.87 2.05-1.87 1.24 0 2 .8 2.02 1.87 0 1.04-.78 1.87-2.05 1.87zM20.34 20.1h-3.63v-5.8c0-1.45-.52-2.45-1.83-2.45-1 0-1.6.67-1.87 1.32-.1.23-.11.55-.11.88v6.05H9.28s.05-9.82 0-10.84h3.63v1.54a3.6 3.6 0 0 1 3.26-1.8c2.39 0 4.18 1.56 4.18 4.89v6.21z\"/\u003e\u003c/svg\u003e\n  \u003c/a\u003e\n\n  \u003c!-- GitHub Icon --\u003e\n  \u003ca href=\"https://github.com/aruiz-p\" target=\"_blank\" style=\"margin-right: 1px;\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" style=\"width: 30px; height: 30px; fill: var(--primary);\"\u003e\u003cpath d=\"M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577v-2.234c-3.338.724-4.033-1.415-4.033-1.415-.546-1.385-1.333-1.754-1.333-1.754-1.089-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.775.418-1.305.762-1.605-2.665-.3-5.466-1.333-5.466-5.93 0-1.31.465-2.381 1.235-3.221-.123-.303-.535-1.523.117-3.176 0 0 1.008-.322 3.3 1.23.957-.266 1.983-.398 3.003-.404 1.02.006 2.047.138 3.006.404 2.29-1.552 3.296-1.23 3.296-1.23.653 1.653.241 2.873.118 3.176.77.84 1.231 1.911 1.231 3.221 0 4.61-2.805 5.625-5.475 5.92.429.372.824 1.104.824 2.222v3.293c0 .322.218.694.825.576C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12\"/\u003e\u003c/svg\u003e  \n  \u003c/a\u003e\n\n  \u003c!-- Gmail Icon --\u003e\n\u003ca href=\"mailto:netwithalex@gmail.com\" target=\"_blank\" style=\"margin-right: 1px;\"\u003e\n  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" style=\"width: 30px; height: 30px;\"\u003e\n    \u003c!-- Background --\u003e\n    \u003crect width=\"24\" height=\"24\" fill=\"var(--theme)\" /\u003e\n    \u003c!-- Envelope Outline --\u003e\n    \u003cpath d=\"M12 12.713L.015 5.328V19.2A2.8 2.8 0 002.8 22h18.4a2.8 2.8 0 002.8-2.8V5.328L12 12.713zm11.985-7.385v-.2a2.8 2.8 0 00-2.8-2.8H2.8A2.8 2.8 0 000 5.328l12 7.679 12-7.679z\" fill=\"none\" stroke=\"var(--primary)\" stroke-width=\"2.5\" /\u003e\n  \u003c/svg\u003e\n\u003c/a\u003e\n\u003c/div\u003e\n\n\n    \u003c/div\u003e\n    \u003cdiv style=\"flex: 1;\"\u003e\n      \u003cimg src=\"/wp-content/uploads/2024/01/IMG_8522-e1704915321848.jpeg\" alt=\"Example Image\" style=\"max-width: 100%; height: auto;border: 5px solid transparent;border-radius: 20px;\"\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e","title":"Sobre mi."}]