[{"content":"Introduction ¿Alguna vez has usado una aplicación que se siente demasiado lenta? Tal vez las videollamadas se congelan o un portal web tarda una eternidad en cargar. Estos (y otros) son signos de que tu red WAN podría estar teniendo problemas.\n¿La buena noticia? Cisco SD-WAN incluye un conjunto de tecnologías diseñadas para mejorar el rendimiento en enlaces poco confiables o con alta latencia. En esta serie, desglosaremos tres funciones clave que pueden mejorar significativamente la experiencia de las aplicaciones en tu red: _Optimización TCP, Forward Error Correction (FEC) y Duplicación de Paquetes_.\nEn este primer post, exploraremos la Optimización TCP: cómo funciona, cuándo utilizarla y por qué puede marcar una gran diferencia para tus usuarios, especialmente en conexiones con alta latencia.\nDescripción de la Solución El objetivo de la Optimización TCP es ajustar finamente las conexiones TCP para mejorar su rendimiento. Esto es especialmente útil cuando hay enlaces con alta latencia involucrados.\nLos routers SD-WAN actuarán como proxies, lo que significa que interceptarán las conexiones TCP y las ajustarán para obtener un mejor desempeño. Veamos un ejemplo visual.\nSin la optimización TCP, el cliente y el servidor establecerán una sesión TCP directamente entre ellos.\nCuando se utiliza la Optimización TCP, el Router 1 interceptará y terminará la conexión TCP proveniente del cliente y establecerá una sesión TCP optimizada con el Router 2. De igual manera, el Router 2 creará una sesión TCP con el servidor.\nNota Todo este proceso es transparente para el cliente y el servidor, y los datos serán almacenados en caché en los routers para mantener activas las sesiones.\nLos equipos IOS-XE SD-WAN usan el algoritmo BBR el cual utiliza información sobre RTT (Round Trip Time) and ancho de banda disponible para optimizar la conexión. Si te gustaría profundizar en el tema te recomiendo ver este vídeo de Neal Cardwell.\nLa implementación actual de Optimization TCP tiene definidos dos roles:\nController Node: Equipo que intercepta y distribuye el trafico al Service Node. Service Node: Motores de optimización para la aceleración del tráfico. En un escenario de la vida real, la recomendación es tener servicios de optimización en las sedes y en los Data Centers. Hay requerimientos diferentes basados en el volumen de tráfico que los equipos van a procesar. Te sugiero leer la Documentación de Cisco para informarte sobre los requerimientos de hardware y más.\nEn las sedes pequeñas, es común utilizar un Integrated Service Node, es decir, un solo equipo puede interceptar, distribuir y optimizar el tráfico. Por otro lado, en el Data Cetner, un cluster de External Service Nodes es necesario para para lograr un mayor rendimiento y distribuir volúmenes más altos de tráfico entre los miembros del cluster.\nEn general, la Optimización TCP es un proceso intensivo para los dispositivos, por lo que es crucial confirmar los requisitos de la plataforma. Por ejemplo, mi entorno de demostración cuenta con dos Catalyst 8000V con 8 CPUs y 16 GB de RAM, requisitos adecuados para una implementación pequeña.\nVeamos en la práctica qué efecto tiene la optimización TCP en el tráfico. Para demostrarlo, voy a tomar una captura de paquetes en el lado WAN con y sin optimización.\nWindow Scaling Sin Optimización Veamos como se comporta el window scalind sin optimización\nNota como el window size se mantuvo estable alrededor de 1,000,000 Bytes después de aproximadamente 5 segundos\nWindow Scaling Con Optimización Veamos la misma información pero con la optimización activa.\nNota como el window size estuvo en constante cambio a lo largo de la sesión, recuperándose rápida y agresivamente después de caer.\nPor qué es tan importante este parámetro? Le pedí a ChatGPT que lo explicará de una manera simple y concisa.\nLa ampliación de ventana (window scaling) es crucial en redes con alta latencia o gran ancho de banda, ya que permite que TCP utilice una ventana de recepción más grande, lo cual impacta directamente en la cantidad de bytes in flight (datos no confirmados) que el emisor puede enviar. Sin esta opción, el tamaño máximo de la ventana es de 65,535 bytes —demasiado pequeño para enlaces de alta velocidad— lo que lleva a una infrautilización del enlace. Con window scaling, la ventana puede crecer hasta varios gigabytes, permitiendo al emisor mantener más datos \u0026ldquo;en vuelo\u0026rdquo; y sostener un alto rendimiento incluso con demoras.\nEn resumen, la sesión TCP se divide en tres segmentos, donde los routers que optimizan anuncian una mayor ampliación de ventana (window scaling) y gestionan las conexiones con el cliente y el servidor. El tráfico ahora se rige por el algoritmo BBR para maximizar el rendimiento.\nConfiguración Para configurar esta funcionalidad, se pueden utilizar Feature Templates o Configuration Groups (con la versión 20.15 o superior). En mi caso utilizaré Configuration Groups y voy a tener Internal Service Nodes en ambos lados\nPara empezar, añado la funcionalidad \u0026ldquo;App QoE\u0026rdquo; en el Service Profile con la siguiente configuración:\nService Node para hacer aceleración Forwarder para actuar como Controller Node Esta es la configuración que se enviará al equipo:\ninterface VirtualPortGroup2 no shutdown ip address 192.168.2.1 255.255.255.0 service-insertion appqoe ! service-insertion appnav-controller-group appqoe ACG-APPQOE appnav-controller 192.168.2.1 ! service-insertion service-node-group appqoe SNG-APPQOE service-node 192.168.2.2 ! service-insertion service-context appqoe/1 appnav-controller-group ACG-APPQOE service-node-group SNG-APPQOE cluster-type integrated-service-node enable vrf global ! El estatus debe ser \u0026ldquo;Running\u0026rdquo;\nLisbon_10-1#show sdwan appqoe tcpopt status ========================================================== TCP-OPT Status ========================================================== Status ------ TCP OPT Operational State : RUNNING TCP Proxy Operational State : RUNNING A continuación, creo una política de datos muy sencilla para hacer match del tráfico entre el cliente y el servidor y selecciono la acción de AppQoE Optimization y selecciono la casilla de TCP Optimization.\nvsmart_1# show running-config policy policy data-policy _VPN_10_AppQoE vpn-list VPN_10 sequence 1 match source-data-prefix-list BR10_172_16_10_0 destination-data-prefix-list DC_100_172_16_100_0 ! action accept tcp-optimization service-node-group SNG-APPQOE ! ! sequence 11 match source-data-prefix-list DC_100_172_16_100_0 destination-data-prefix-list BR10_172_16_10_0 ! action accept tcp-optimization service-node-group SNG-APPQOE ! ! default-action accept ! ! Nota la dirección en la cual se debe aplicar la política es ALL\nvsmart_1# show running-config apply-policy apply-policy site-list BR_10 data-policy _VPN_10_AppQoE all ! site-list DC_100 data-policy _VPN_10_AppQoE all ! ! Verificando la Optimización TCP Para verificar que el tráfico está siendo optimizado, podemos habilitar On-Demand Troubleshooting y seleccionar un periodo de tiempo.\nTambién, con la información en tiempo real podemos sacar la lista de flows que están siendo optimizados\nLa columna de Services indica que la Optimización TCP se está aplicando a esos flujos\nProbando el rendimiento de la Optimization TCP Para evaluar el impacto de la Optimización TCP, ejecuté pruebas con iperf utilizando diferentes valores de latencia para observar en qué condiciones la función ofrece mayores beneficios. Aunque no se trata de un entorno de laboratorio profesional, proporciona información valiosa sobre cómo se comporta la optimización en la práctica.\nNota Mi tráfico de iperf no está encriptado. No es posible optimizar tráfico encriptado sin antes desencriptarlo a través de TLS/SSL Decryption\nAlgunos detalles adicionales:\nEl ancho de banda está topado a 250 Mbps en los routers. Utilizo 4 flujos en paralelo, cada uno simulando una descarga de 100 MB: iperf -c 172.16.100.11 -n 100MB -P 4 -i 15 -R\nPara mantener consistencia, corro cada prueba 5 veces, descarto el resultado más alto y más bajo y al final saco un promedio de los tres restantes.\nLa siguiente tabla muestra los resultados obtenidos:\nDelay TCP Opt BW (Mbps) Time (s) 0 Disabled 248 ~ 13 0 Enabled 121,6 ~ 27 50 Disabled 99,7 ~ 33 50 Enabled 124 ~ 26 100 Disabled 71 ~ 46 100 Enabled 131 ~ 25 150 Disabled 66 ~ 49 150 Enabled 125 ~ 26 200 Disabled 59 ~ 56 200 Enabled 131 ~ 25 250 Disabled 63 ~ 52 250 Enabled 126 ~ 26 Aquí hay una representación visual de la misma información\nLo que puedo concluir de los resultados:\nCon un delay de 0 ms, la optimización reduce el rendimiento (121 Mbps frente a 248 Mbps), debido al procesamiento que introduce esta funcionalidad.\nA medida que aumenta el delay, la optimización mejora el rendimiento y reduce el tiempo de transferencia, lo cual ya es evidente a partir de un delay de 50 ms.\nEl rendimiento disminuye significativamente sin optimización TCP. El ancho de banda baja de 248 Mbps a 0 ms a ~59–63 Mbps con retrasos de 200–250 ms. El tiempo también aumenta proporcionalmente.\nEl rendimiento se mantiene estable a través de diferentes valores de delay con optimización TCP. El rendimiento se mantiene alrededor de 125–131 Mbps incluso con retrasos altos. El tiempo de transferencia también es consistente, alrededor de ~26s.\nConclusión La optimización TCP es altamente efectiva para mitigar el impacto de la latencia en el rendimiento de TCP. Si bien introduce algo de sobrecarga en condiciones de baja latencia, sus beneficios se vuelven más evidentes a medida que aumenta el retraso. En escenarios con retrasos de 100 ms o más, la optimización puede ayudar a duplicar el rendimiento y reducir el tiempo de transferencia. Si estás pensando en habilitarla, ten en cuenta que, dependiendo del modelo de router, obtendrás rendimientos diferentes.\nAdemás, esta función no debe habilitarse para todo el tráfico, sino que debe activarse para una aplicación específica o un conjunto de aplicaciones que necesiten aceleración. Finalmente, esta función ofrece mayores beneficios en líneas intercontinentales, transportes satelitales o enlaces de alta latencia similares.\n¡Espero que esta publicación haya sido útil y nos vemos en la próxima!\n","permalink":"http://localhost:1313/appqoe-opt-tcp/","summary":"Descubre cómo SD-WAN mejora el rendimiento de TCP. Conoce las principales técnicas de optimización que aumentan el rendimiento de las aplicaciones y mejoran la experiencia del usuario.","title":"Serie AppQoE: Optimización TCP"},{"content":"Introduction ¿Alguna vez has usado una aplicación que se siente demasiado lenta? Tal vez las videollamadas se congelan o un portal web tarda una eternidad en cargar. Estos (y otros) son signos de que tu red WAN podría estar teniendo problemas.\n¿La buena noticia? Cisco SD-WAN incluye un conjunto de tecnologías diseñadas para mejorar el rendimiento en enlaces poco confiables o con alta latencia. En esta serie, desglosaremos tres funciones clave que pueden mejorar significativamente la experiencia de las aplicaciones en tu red: _Optimización TCP, Forward Error Correction (FEC) y Duplicación de Paquetes_.\nEn este primer post, exploraremos la Optimización TCP: cómo funciona, cuándo utilizarla y por qué puede marcar una gran diferencia para tus usuarios, especialmente en conexiones con alta latencia.\nDescripción de la Solución El objetivo de la Optimización TCP es ajustar finamente las conexiones TCP para mejorar su rendimiento. Esto es especialmente útil cuando hay enlaces con alta latencia involucrados.\nLos routers SD-WAN actuarán como proxies, lo que significa que interceptarán las conexiones TCP y las ajustarán para obtener un mejor desempeño. Veamos un ejemplo visual.\nSin la optimización TCP, el cliente y el servidor establecerán una sesión TCP directamente entre ellos.\nCuando se utiliza la Optimización TCP, el Router 1 interceptará y terminará la conexión TCP proveniente del cliente y establecerá una sesión TCP optimizada con el Router 2. De igual manera, el Router 2 creará una sesión TCP con el servidor.\nNota Todo este proceso es transparente para el cliente y el servidor, y los datos serán almacenados en caché en los routers para mantener activas las sesiones.\nLos equipos IOS-XE SD-WAN usan el algoritmo BBR el cual utiliza información sobre RTT (Round Trip Time) and ancho de banda disponible para optimizar la conexión. Si te gustaría profundizar en el tema te recomiendo ver este vídeo de Neal Cardwell.\nLa implementación actual de Optimization TCP tiene definidos dos roles:\nController Node: Equipo que intercepta y distribuye el trafico al Service Node. Service Node: Motores de optimización para la aceleración del tráfico. En un escenario de la vida real, la recomendación es tener servicios de optimización en las sedes y en los Data Centers. Hay requerimientos diferentes basados en el volumen de tráfico que los equipos van a procesar. Te sugiero leer la Documentación de Cisco para informarte sobre los requerimientos de hardware y más.\nEn las sedes pequeñas, es común utilizar un Integrated Service Node, es decir, un solo equipo puede interceptar, distribuir y optimizar el tráfico. Por otro lado, en el Data Cetner, un cluster de External Service Nodes es necesario para para lograr un mayor rendimiento y distribuir volúmenes más altos de tráfico entre los miembros del cluster.\nEn general, la Optimización TCP es un proceso intensivo para los dispositivos, por lo que es crucial confirmar los requisitos de la plataforma. Por ejemplo, mi entorno de demostración cuenta con dos Catalyst 8000V con 8 CPUs y 16 GB de RAM, requisitos adecuados para una implementación pequeña.\nVeamos en la práctica qué efecto tiene la optimización TCP en el tráfico. Para demostrarlo, voy a tomar una captura de paquetes en el lado WAN con y sin optimización.\nWindow Scaling Sin Optimización Veamos como se comporta el window scalind sin optimización\nNota como el window size se mantuvo estable alrededor de 1,000,000 Bytes después de aproximadamente 5 segundos\nWindow Scaling Con Optimización Veamos la misma información pero con la optimización activa.\nNota como el window size estuvo en constante cambio a lo largo de la sesión, recuperándose rápida y agresivamente después de caer.\nPor qué es tan importante este parámetro? Le pedí a ChatGPT que lo explicará de una manera simple y concisa.\nLa ampliación de ventana (window scaling) es crucial en redes con alta latencia o gran ancho de banda, ya que permite que TCP utilice una ventana de recepción más grande, lo cual impacta directamente en la cantidad de bytes in flight (datos no confirmados) que el emisor puede enviar. Sin esta opción, el tamaño máximo de la ventana es de 65,535 bytes —demasiado pequeño para enlaces de alta velocidad— lo que lleva a una infrautilización del enlace. Con window scaling, la ventana puede crecer hasta varios gigabytes, permitiendo al emisor mantener más datos \u0026ldquo;en vuelo\u0026rdquo; y sostener un alto rendimiento incluso con demoras.\nEn resumen, la sesión TCP se divide en tres segmentos, donde los routers que optimizan anuncian una mayor ampliación de ventana (window scaling) y gestionan las conexiones con el cliente y el servidor. El tráfico ahora se rige por el algoritmo BBR para maximizar el rendimiento.\nConfiguración Para configurar esta funcionalidad, se pueden utilizar Feature Templates o Configuration Groups (con la versión 20.15 o superior). En mi caso utilizaré Configuration Groups y voy a tener Internal Service Nodes en ambos lados\nPara empezar, añado la funcionalidad \u0026ldquo;App QoE\u0026rdquo; en el Service Profile con la siguiente configuración:\nService Node para hacer aceleración Forwarder para actuar como Controller Node Esta es la configuración que se enviará al equipo:\ninterface VirtualPortGroup2 no shutdown ip address 192.168.2.1 255.255.255.0 service-insertion appqoe ! service-insertion appnav-controller-group appqoe ACG-APPQOE appnav-controller 192.168.2.1 ! service-insertion service-node-group appqoe SNG-APPQOE service-node 192.168.2.2 ! service-insertion service-context appqoe/1 appnav-controller-group ACG-APPQOE service-node-group SNG-APPQOE cluster-type integrated-service-node enable vrf global ! El estatus debe ser \u0026ldquo;Running\u0026rdquo;\nLisbon_10-1#show sdwan appqoe tcpopt status ========================================================== TCP-OPT Status ========================================================== Status ------ TCP OPT Operational State : RUNNING TCP Proxy Operational State : RUNNING A continuación, creo una política de datos muy sencilla para hacer match del tráfico entre el cliente y el servidor y selecciono la acción de AppQoE Optimization y selecciono la casilla de TCP Optimization.\nvsmart_1# show running-config policy policy data-policy _VPN_10_AppQoE vpn-list VPN_10 sequence 1 match source-data-prefix-list BR10_172_16_10_0 destination-data-prefix-list DC_100_172_16_100_0 ! action accept tcp-optimization service-node-group SNG-APPQOE ! ! sequence 11 match source-data-prefix-list DC_100_172_16_100_0 destination-data-prefix-list BR10_172_16_10_0 ! action accept tcp-optimization service-node-group SNG-APPQOE ! ! default-action accept ! ! Nota la dirección en la cual se debe aplicar la política es ALL\nvsmart_1# show running-config apply-policy apply-policy site-list BR_10 data-policy _VPN_10_AppQoE all ! site-list DC_100 data-policy _VPN_10_AppQoE all ! ! Verificando la Optimización TCP Para verificar que el tráfico está siendo optimizado, podemos habilitar On-Demand Troubleshooting y seleccionar un periodo de tiempo.\nTambién, con la información en tiempo real podemos sacar la lista de flows que están siendo optimizados\nLa columna de Services indica que la Optimización TCP se está aplicando a esos flujos\nProbando el rendimiento de la Optimization TCP Para evaluar el impacto de la Optimización TCP, ejecuté pruebas con iperf utilizando diferentes valores de latencia para observar en qué condiciones la función ofrece mayores beneficios. Aunque no se trata de un entorno de laboratorio profesional, proporciona información valiosa sobre cómo se comporta la optimización en la práctica.\nNota Mi tráfico de iperf no está encriptado. No es posible optimizar tráfico encriptado sin antes desencriptarlo a través de TLS/SSL Decryption\nAlgunos detalles adicionales:\nEl ancho de banda está topado a 250 Mbps en los routers. Utilizo 4 flujos en paralelo, cada uno simulando una descarga de 100 MB: iperf -c 172.16.100.11 -n 100MB -P 4 -i 15 -R\nPara mantener consistencia, corro cada prueba 5 veces, descarto el resultado más alto y más bajo y al final saco un promedio de los tres restantes.\nLa siguiente tabla muestra los resultados obtenidos:\nDelay TCP Opt BW (Mbps) Time (s) 0 Disabled 248 ~ 13 0 Enabled 121,6 ~ 27 50 Disabled 99,7 ~ 33 50 Enabled 124 ~ 26 100 Disabled 71 ~ 46 100 Enabled 131 ~ 25 150 Disabled 66 ~ 49 150 Enabled 125 ~ 26 200 Disabled 59 ~ 56 200 Enabled 131 ~ 25 250 Disabled 63 ~ 52 250 Enabled 126 ~ 26 Aquí hay una representación visual de la misma información\nLo que puedo concluir de los resultados:\nCon un delay de 0 ms, la optimización reduce el rendimiento (121 Mbps frente a 248 Mbps), debido al procesamiento que introduce esta funcionalidad.\nA medida que aumenta el delay, la optimización mejora el rendimiento y reduce el tiempo de transferencia, lo cual ya es evidente a partir de un delay de 50 ms.\nEl rendimiento disminuye significativamente sin optimización TCP. El ancho de banda baja de 248 Mbps a 0 ms a ~59–63 Mbps con retrasos de 200–250 ms. El tiempo también aumenta proporcionalmente.\nEl rendimiento se mantiene estable a través de diferentes valores de delay con optimización TCP. El rendimiento se mantiene alrededor de 125–131 Mbps incluso con retrasos altos. El tiempo de transferencia también es consistente, alrededor de ~26s.\nConclusión La optimización TCP es altamente efectiva para mitigar el impacto de la latencia en el rendimiento de TCP. Si bien introduce algo de sobrecarga en condiciones de baja latencia, sus beneficios se vuelven más evidentes a medida que aumenta el retraso. En escenarios con retrasos de 100 ms o más, la optimización puede ayudar a duplicar el rendimiento y reducir el tiempo de transferencia. Si estás pensando en habilitarla, ten en cuenta que, dependiendo del modelo de router, obtendrás rendimientos diferentes.\nAdemás, esta función no debe habilitarse para todo el tráfico, sino que debe activarse para una aplicación específica o un conjunto de aplicaciones que necesiten aceleración. Finalmente, esta función ofrece mayores beneficios en líneas intercontinentales, transportes satelitales o enlaces de alta latencia similares.\n¡Espero que esta publicación haya sido útil y nos vemos en la próxima!\n","permalink":"http://localhost:1313/appqoe-opt-tcp/","summary":"Descubre cómo SD-WAN mejora el rendimiento de TCP. Conoce las principales técnicas de optimización que aumentan el rendimiento de las aplicaciones y mejoran la experiencia del usuario.","title":"Serie AppQoE: Optimización TCP"},{"content":"Introducción La seguridad siempre ha sido una prioridad para las organizaciones, pero proteger cada ángulo de la red sigue siendo un desafío. Al mismo tiempo, garantizar una experiencia óptima para aplicaciones y usuarios es igualmente importante. Las organizaciones a menudo han tenido que elegir entre soluciones centradas en la seguridad o en el rendimiento, lo que aumenta la complejidad de gestión y operación.\nCisco Secure Access es una solución robusta que aborda estos desafíos. Ofrece una seguridad de primer nivel al integrar tecnologías avanzadas y controles de acceso. Esto significa que los usuarios pueden obtener una conectividad segura y directa desde los sitios SD-WAN hacia internet y aplicaciones SaaS.\nVeamos cómo funciona.\nSD-WAN se encuentra con Secure Access A partir de la versión 20.13/17.13 de SD-WAN, la integración con Secure Access está disponible de forma nativa.\nCon esta integración, se pueden establecer túneles IPSec automáticos hacia los Data Centers primarios y secundarios de Secure Access que estén mas cercanos a la ubicación de tu router, garantizando un rendimiento óptimo. Estos túneles enrutan el tráfico mientras aplican las políticas de seguridad de tu organización, proporcionando una forma sencilla y potente de mejorar tanto la seguridad como la conectividad a internet.\nEn el centro de Secure Access están los Network Tunnel Groups (NTGs), que gestionan las conexiones IPSec. Cada NTG incluye un Data Center de Secure Access primario y uno secundario. Aunque no es obligatorio configurar túneles hacia ambos, es altamente recomendable para garantizar alta disponibilidad en caso de que uno tenga algún problema\nEs posible configurar hasta 16 túneles, 8 activos y 8 backups, lo que permite hacer load balance entre los túneles activos para aumentar el ancho de banda disponible.\nPara establecer los túneles automáticamente, el Manager y el router necesitan conectividad a Internet y DNS habilitado. Esto permite que el router determine su propia dirección IP pública, se la comunique al Manager y se le asignen los Data Centers SSE primario y secundario más cercanos.\nUna vez que se establecen los túneles, el tráfico que los atraviesa está asegurado por las funcionalidades de seguridad principales de SSE FWAAS, CASB, ZTNA y SWG y más.\nPasos de configuración Crear clave API Para comenzar, en SSE crea una clave API para que el Manager se conecte de forma segura. Asegúrate de que se otorguen los siguientes privilegios:\nDeployment / Network Tunnel Group - Read/Write Deployment / Tunnels - Read/Write Deployment / Regions - Read Obtendrás el API Key y Key Secret\nIngrese credenciales en el Manager A continuación, ingresa la información en el Manager en Administration \u0026gt; Settings \u0026gt; Cloud Credentials \u0026gt; SSE\nCrear política SSE en el Manager Crea una nueva política de SSE. Aquí es donde ingresas la información sobre los túneles IPSec.\nDesde Configuration \u0026gt; Policy Groups \u0026gt; Secure Service Edge\nLo siguiente es lo mínimo que necesitas:\nTracker IP - Se utiliza para confirmar que el túnel está arriba. Tunnel - Al menos 1 túnel. Ingresa el nombre tunnel name, source interface y selecciona primary/secondary DC Interface Pair - Especifica los túneles Active y Backup. Selecciona none como backup si solo hay 1 túnel. Nota Puedes seleccionar la región SSE de tu preferencia o usar auto para seleccionarla automáticamente.\nLuego, crea un Policy Group, asocia un dispositivo y agrega la política de SSE\nRedirigir el tráfico del lado del servicio Ahora, necesitamos redirigir el tráfico de los usuarios al túnel. Hay dos opciones:\nRuta de servicio de tipo SSE En la funcionalidad service vpn, agrega una ruta service con el proveedor de SSE Cisco-Secure Access\nEsto se agregará de la siguiente manera:\nip sdwan route vrf 10 0.0.0.0/0 service sse Cisco-Secure-Access Puede seleccionar qué tráfico se reenvía a SSE modificando la ruta, sin embargo, este enfoque no es tan flexible comparado con la segunda opción.\nData Policy Las Data Policies proporcionan más flexibilidad para redirigir el tráfico. No solo podemos hacer match al destino, sino también a otros elementos útiles, como source, aplicaciones y más.\nEste ejemplo hace match a todo el tráfico que proviene de mis usuarios en la VPN 10 y establece una acción de |Secure Service Edge. Observa que podemos habilitar la opción de Fallback to Routing en caso de que los túneles no estén disponibles.\nValidaciones en el Manager Verifica el estado del túnel desde Monitor \u0026gt; Tunnels \u0026gt; SIG/SSE Tunnels\nLos logs están disponibles y son útiles para determinar si hay algún problema al establecer los túneles\nValidaciones del usuario Para verificar que los usuarios están utilizando SSE, tenemos un par de opciones\nLa primera es visitar policy.test.sse.com, si el tráfico se redirige correctamente, verás algo como esto:\nEn el lado de SSE, hay una política que niega el tráfico a las aplicaciones de redes sociales, veamos el resultado de tratar de acceder a x.com\nPor último, acceder a welcome.umbrella.com nos hará saber si el usuario está protegido\nConsideraciones adicionales ECMP está disponible cuando múltiples túneles están activos. Unequal Load Balance se puede lograr mediante la asignación de peso a los túneles IPSEC. El fallback to routing se activa cuando los túneles no están disponibles Los trackers son personalizables - Se puede definir una URL y thresholds personalizados para cumplir con los SLA deseados Mecanismo de dampening incorporado en túneles para evitar flapping entre túneles. La redirección de la política de datos proporciona una mayor flexibilidad que las rutas estáticas Usa interfaces Loopback para crear múltiples túneles hacia SSE ¡Espero que hayas aprendido algo útil! Nos vemos en el siguiente 👋\n","permalink":"http://localhost:1313/sdwan-sse-integracion/","summary":"Descubre cómo Cisco SD-WAN y Cisco Secure Access trabajan juntos para mejorar el rendimiento y la seguridad de los usuarios en internet.","title":"Asegurando el borde con Cisco SD-WAN y Secure Access"},{"content":"Introducción En mi anterior serie de publicaciones, exploré Application Aware Routing (AAR) en profundidad, una tecnología clave en SD-WAN que dirige el tráfico sobre los transportes con mejor rendimiento. Si bien AAR ha sido una capacidad fundamental durante años, la evolución de las redes trajo nuevas ideas para mejorar su efectividad. Esto condujo a la introducción de Enhanced Application Aware Routing (EAAR).\nLimitaciones de AAR Antes de sumergirnos en EAAR, entendamos por qué fue creado. 🤓\nLa implementación actual de AAR mide la calidad del transporte utilizando BFD, enviando probes a un intervalo definido (1s por defecto). La pérdida, la latencia y jitter se derivan de esos paquetes y estos valores se colocan en cubetas que van rotando para calcular una métrica promedio que representa la salud del túnel. Este proceso generalmente toma entre 10 y 60 minutos y con algunos ajustes de configuración es posible lograr tiempos de 2 a 10 minutos.\nPara aquellas redes que requieren una detección más rápida, surgen algunos desafíos:\nBajar el intervalo de hello a menos de 1 segundo afecta la escala de túneles del dispositivo Bajar el multiplicador de BFD y el poll interval podrían conducir a falsos positivos, moviendo el tráfico incluso con condiciones de red transitorias. Cambio constante del tráfico de un lado a otro, no hay un mecanismo para determinar si un transporte es estable nuevamente después de un evento de degradación de la red. Enhanced AAR Entonces, ¿qué es EAAR y cómo mejora a su predecesor? 🤔\nEn pocas palabras, estas son las ventajas:\nUtiliza inline data en lugar de BFD. En otras palabras, los paquetes de plano de datos se utilizan para medir la pérdida, la latencia y el jitter. Capacidad de mover el tráfico en segundos en lugar de minutos Amortiguación (Dampening) implementada para propósitos de estabilidad, asegurando que los transportes sean estables antes de reenviar el tráfico a través de ellos. Medición más precisa de pérdida, latencia y jitter Vamos por partes Cuando EAAR está habilitado, los paquetes de datos se utilizarán para medir la pérdida, la latencia y la jitter. Entendamos las diferencias clave:\nMedición de pérdida Los routeres SD-WAN utilizarán inline data junto con los números de secuencia IPSEC para medir la pérdida.\nHay un mecanismo incorporado que permite a los routers determinar si la pérdida es local para el router\nPérdida local - Por lo general, debido a caídas de QoS O externo al router\nPérdida de WAN - Cualquier pérdida de paquetes fuera del router Para calcular la pérdida local, el router determinará la cantidad de paquetes que generó en comparación con la cantidad de paquetes que realmente fueron enviados. Para obtener la pérdida en el WAN, los routers SD-WAN vecinos informarán la cantidad de paquetes recibidos y utilizarán BFD (TLVs de Monitoreo de Ruta) para enviar esta información de vuelta al router original.\nHasta este punto, existe una mejora importante en cómo se realiza la medición de pérdidas, sin embargo, esto podría mejorarse aún más al aprovechar mediciones per queue de QoS. Para lograr esto, necesitamos asociar una clase de SLA con una App Probe Class. Veamos un ejemplo.\nCon esta App Probe Class, el router utilizará (y generará paquetes de BFD) con DSCP 18, imitando el tráfico menos importante que estará sujeto a diferentes reglas y rutas en los routers locales y externos. Esto proporcionará una medición más precisa de la pérdida de paquetes para cada tipo de tráfico en los transportes especificados. Si no hay inline data, BFD se usa para obtener mediciones.\nNota Si usas GRE, la medición per queue no está disponible.\nAquí hay un visual para comprender mejor cómo se medirán la pérdida dependiendo de múltiples factores.\nEncapsulación App Probe Class Tipo de medición Túneles públicos Túneles privados IPsec Sí Por SLA total pérdida WAN + pérdida local por queue pérdida WAN per queue + pérdida local por queue IPsec No Todos los SLAs total pérdida WAN + total pérdida local total pérdida WAN + total pérdida local GRE - Todos los SLAs total pérdida WAN + total pérdida local total pérdida WAN + total pérdida local Latencia Para medir la latencia, el router simplemente calculará el tiempo necesario para enviar y recibir paquetes entre los dispositivos de origen y de destino. Se utiliza inline data y puede llegar a la granularidad de App Probe Class.\nJitter Vale la pena mencionar que el jitter se calcula por dirección (recibir o transmitir). El jitter se calcula en el receptor e informa al remitente usando TLV BFD. Se utiliza inline data y, en caso de no haber tráfico de datos, se usa BFD.\nSLA Dampening Uno de los beneficios de EAAR es dirigir el tráfico en segundos en lugar de minutos, pero ¿qué pasaría si hay condiciones de red transitorias que hacen que los transportes no cumplan con el SLA cada pocos minutos? El tráfico cambiaría constantemente entre los transportes, lo que no es un escenario deseable y la razón por la cual se introdujo el dampening.\nLa idea general es que cuando un enlace de transporte deja de cumplir con el SLA, el tráfico se redirige a una ruta alternativa. Una vez que el transporte vuelve a estar en cumplimiento, el dispositivo no mueve el tráfico de inmediato. En su lugar, inicia un temporizador para asegurarse de que el enlace permanezca estable durante un período determinado antes de reutilizarlo.\nAl final, el dampening ayuda a evitar cambios innecesarios en el tráfico, lo que podría afectar negativamente el rendimiento debido a la inestabilidad del transporte.\nConfiguración de EAAR Para habilitar EAAR tenemos tres opciones predefinidas:\nMode Poll Interval Poll Multiplier Dampening Multiplier Aggressive 10s 6 (10s-60s) 120 (20 mins) Moderate 60s 5 (60s-300s) 40 (40 mins) Conservative 300s 6 (300s-1800s) 12 (60 mins) Nota Para usar tiempos personalizados, la configuración debe hacerse a través de plantillas CLI.\nEAAR sigue el mismo principio fundamental que AAR, utilizando buckets que van rotando para calcular la pérdida promedio, la latencia y la jitter. Con el modo aggressive, el tráfico tomaría entre 10 y 60 segundos en cambiar, dependiendo de qué tan severo sea el deterioro.\nEl Dampening Multiplier (poll interval x Dampening Multiplier) es de 1200 segundos, lo que significa que antes de cambiar el tráfico a un transporte, debe ser estable durante 20 minutos.\nEn mi laboratorio, estoy usando Configuration Groups, sin embargo, esto está disponible a través de Templates también.\nPuedes usar una variable, en lugar de un valor global, para que sea aplicable también a los dispositivos que no correrán EAAR. En este caso, los dispositivos habilitados para EAAR harán fallback a AAR.\nLa siguiente configuración se agrega a los dispositivos:\nbfd enhanced-app-route enable bfd enhanced-app-route pfr-poll-interval 10000 bfd enhanced-app-route pfr-multiplier 6 bfd sla-dampening enable bfd sla-dampening multiplier 120 Veamos cómo funciona\nDemo En mi laboratorio, uso el Manager con versión 20.16.1 y mis dispositivos con 17.15.1a\nNota La versión mínima requerida es 20.12/17.12\nComencemos con algunas verificaciones después de aplicar la configuración.\nPara verificar los temporizadores y multiplicadores configurados\nBR10#show sdwan app-route params Enhanced Application-Aware routing Config: :Enabled Poll interval: :10000 Poll multiplier: :6 App route Poll interval: :120000 Poll multiplier: :5 SLA dampening Config: :Enabled Multiplier: :120 Para verificar qué sesiones de BFD están utilizando EAAR, busca la columna Flags\nBR10#show sdwan bfd sessions alt SOURCE TLOC REMOTE TLOC DST PUBLIC DST PUBLIC SYSTEM IP SITE ID STATE COLOR COLOR SOURCE IP IP PORT ENCAP BFD-LD FLAGS UPTIME ------------------------------------------------------------------------------------------------------------------------------------------------- 1.1.1.20 200 up biz-internet biz-internet 30.1.10.2 30.1.20.2 12406 ipsec 20006 EAAR 0:00:20:31 1.1.1.20 200 up mpls mpls 30.2.10.2 30.2.20.2 12366 ipsec 20002 EAAR 0:00:20:38 1.1.1.20 200 up private1 private1 30.3.10.2 30.3.20.2 12366 ipsec 20003 EAAR 0:00:20:37 Para obtener más detalles sobre un túnel específico.\nBR10#show sdwan app-route stats summary Generating output, this might take time, please wait ... app-route statistics 30.1.10.2 30.1.20.2 ipsec 12386 12406 remote-system-ip 1.1.1.20 local-color biz-internet remote-color biz-internet sla-class-index 0,1,2 fallback-sla-class-index None enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 0.000 mean-latency 0 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 0 0 0 0 0 0 0 0 1 64 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 5 64 0 0 0 0 0 0 0 Nota que no hay tráfico entre mis dispositivos, por lo que el recuento total de paquetes en cada bucket es bajo.\nLa misma información está disponible a través de la interfaz gráfica, utilizando la opción de Real Time \u0026gt; App Route Statistics\nEscenario 1 - Deterioro ligero Esta es la topología de mi laboratorio\nPara esta primera prueba, usaré los siguientes parámetros de SLA:\nSLA_Real-Time Loss: 3% Latency: 150ms Jitter: 100ms La política AAR indica que:\nUse MPLS como transporte principal Si ningún color cumple con el SLA y Private1 está disponible, usarlo. Si Private1 no está disponible, se hace load balance entre todos los colores restantes. Estoy haciendo match del tráfico entre 172.16.10.0/24 y 172.16.20.0/24.\nBR10#show sdwan policy from-vsmart from-vsmart app-route-policy app_route_AAR vpn-list vpn_Corporate_Users sequence 1 match source-data-prefix-list BR10 destination-data-prefix-list BR20 action backup-sla-preferred-color private1 sla-class SLA_Real-Time no sla-class strict sla-class preferred-color mpls sequence 11 match source-data-prefix-list BR20 destination-data-prefix-list BR10 action backup-sla-preferred-color private1 sla-class SLA_Real-Time no sla-class strict sla-class preferred-color mpls Estado inicial sin deterioro en la red\nBR10#show sdwan app-route stats summary | i color|damp|mean local-color biz-internet remote-color biz-internet sla-dampening-index None mean-loss 0.000 mean-latency 1 mean-jitter 0 local-color mpls remote-color mpls sla-dampening-index None mean-loss 1.212 mean-latency 1 mean-jitter 0 mean-loss 1.212 mean-latency 1 mean-jitter 0 local-color private1 remote-color private1 sla-dampening-index None mean-loss 0.000 mean-latency 0 mean-jitter 0 mean-loss 0.000 mean-latency 0 mean-jitter 0 Observa que el número de paquetes por bucket aumentó dramáticamente\nBR10#show sdwan app-route stats remote-color mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12366 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0,1 fallback-sla-class-index None enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 1.176 mean-latency 0 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 131136 1501 0 0 100084 20846 0 0 1 131072 1438 0 0 95287 19605 0 0 2 131072 1400 0 0 100985 20937 0 0 3 131072 1781 0 0 85553 18271 0 0 4 64 0 0 0 72618 15942 0 0 5 131072 1589 0 0 65198 14226 0 0 El tráfico está utilizando MPLS como transporte primario\nBR10# show sdwan policy service-path vpn 10 interface gigabitEthernet 4 source-ip 172.16.10.10 dest-ip 172.16.20.10 protocol 6 all Number of possible next hops: 1 Next Hop: IPsec Source: 30.2.10.2 12366 Destination: 30.2.20.2 12366 Local Color: mpls Remote Color: mpls Remote System IP: 1.1.1.20 Introduzco el 3% de pérdida de paquetes en el transporte MPLS y veré cuánto tiempo lleva cambiar el tráfico. Dado que ya hay alrededor del 1% de pérdida, el 3% debería ser suficiente para activar un cambio.\nEl transporte MPLS tiene más del 3% de pérdida\nBR10#show sdwan app-route stats remote-color mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12366 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0 fallback-sla-class-index 1 enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 3.125 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; mean-latency 0 mean-jitter 0 Después de 56 segundos, el tráfico cambió y cualquiera de los transportes que cumplen el SLA podría usarse\nBR10# show sdwan policy service-path vpn 10 interface gigabitEthernet 4 source-ip 172.16.10.10 dest-ip 172.16.20.10 protocol 6 all Number of possible next hops: 2 Next Hop: IPsec Source: 30.3.10.2 12366 Destination: 30.3.20.2 12366 Local Color: private1 Remote Color: private1 Remote System IP: 1.1.1.20 Next Hop: IPsec Source: 30.1.10.2 12386 Destination: 30.1.20.2 12366 Local Color: biz-internet Remote Color: biz-internet Remote System IP: 1.1.1.20 Si quito la pérdida, podemos ver que el mecanismo de dampening se activa. Entonces, si el transporte es estable durante 20 minutos, se volverá a utilizar como ruta preferida.\nBR10#show sdwan app-route stats remote-color mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12366 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0 fallback-sla-class-index 1 enhanced-app-route Enabled sla-dampening-index 1 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; app-probe-class-list None mean-loss 0.000 mean-latency 0 mean-jitter 0 Escenario 2 - Mayor deterioro En este caso, introduciré una pérdida de paquetes del 10% para el transporte de biz-internet, lo que hace que private1 sea el único transporte cumpliendo el SLA.\nDespués de alrededor de 45 segundos, la pérdida de Biz-Internet fue de 12%\nBR10#show sdwan app-route stats local-color biz-internet summary Generating output, this might take time, please wait ... app-route statistics 30.1.10.2 30.1.20.2 ipsec 12386 12366 remote-system-ip 1.1.1.20 local-color biz-internet remote-color biz-internet sla-class-index 0 fallback-sla-class-index 1 enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 12.500 mean-latency 0 mean-jitter 0 El tráfico cambió a private1 exclusivamente\nBR10#show sdwan policy service-path vpn 10 interface gigabitEthernet 4 source-ip 172.16.10.10 dest-ip 172.16.20.10 protocol 6 all Number of possible next hops: 1 Next Hop: IPsec Source: 30.3.10.2 12366 Destination: 30.3.20.2 12366 Local Color: private1 Remote Color: private1 Remote System IP: 1.1.1.20 Después de eliminar la pérdida de paquetes, Biz-Internet tiene el mecanismo de dampening activado\nBR10#show sdwan app-route stats local-color biz-internet summary Generating output, this might take time, please wait ... app-route statistics 30.1.10.2 30.1.20.2 ipsec 12386 12366 remote-system-ip 1.1.1.20 local-color biz-internet remote-color biz-internet sla-class-index 0 fallback-sla-class-index 1 enhanced-app-route Enabled sla-dampening-index 1 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; app-probe-class-list None mean-loss 1.562 mean-latency 0 mean-jitter 0 En este caso, el tiempo para cambiar el tráfico se redujo como consecuencia de un deterioro mayor.\nEscenario 3 - Múltiples App Probe Class Para este escenario final, veamos cómo obtener el mayor beneficio de EAAR.\nLa configuración es más compleja ya que involucra QoS, App Probe Class y política AAR.\nSe requiere QoS para clasificar y enviar tráfico en diferentes colas. App Probe Class para medir la pérdida, la latencia y el jitter en cada una de esas colas, de forma independiente. Mi configuración de QoS tiene 3 colas y la cola 2 manejará el tráfico menos importante.\ncola 0 para el tráfico de control cola 1 para tráfico en tiempo real (marcado DSCP 46) cola 2 para tráfico transaccional (marcado DSCP 18) Utilizo una política de datos para hacer match del tráfico en el lado del servicio, marcarlo con el DSCP correcto y ponerla en la clase de QoS correcta. También creé un shaper en mi interfaz MPLS.\nPara demostrar las cosas, tendré dos transferencias de datos:\nHTTP GET (puerto 8000) Copia SCP (puerto 22) Mis SLA tienen las siguientes configuraciones:\nSLA Class Name Loss Latency Jitter SLA_Real-Time 3 % 150 ms 100 ms SLA_Transactional 5 % 45 ms 150 ms Lo primero que hay que notar es que mis dos clases de sondeo de aplicaciones se miden de manera independiente. Observa cómo la pérdida media para Transactional-Probe_Class es 1, mientras que para Real_Time_Probe_Class es 0.\nBR10#show sdwan app-route stats local-color mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12366 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0,1,2 fallback-sla-class-index None enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 0.000 mean-latency 1 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 16384 0 0 0 35827 111807 0 0 1 49152 0 1 0 37788 118236 0 0 2 49216 0 1 0 36859 115551 0 0 3 16384 0 1 0 23894 77280 0 0 4 32768 0 1 1 33179 103759 0 0 5 32768 0 1 0 21485 71702 0 0 app-probe-class-list Real_Time_Probe_Class mean-loss 0.000 mean-latency 0 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 0 0 0 0 - - - - 1 32768 0 1 0 - - - - 2 32768 0 0 0 - - - - 3 0 0 0 0 - - - - 4 32768 0 1 2 - - - - 5 0 0 0 0 - - - - app-probe-class-list Transactional-Probe_Class mean-loss 0.000 mean-latency 1 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 16384 0 0 0 - - - - 1 49152 0 1 0 - - - - 2 49216 0 1 0 - - - - 3 16384 0 1 0 - - - - 4 32768 0 1 1 - - - - 5 32768 0 1 0 - - - - Ahora, he bajado mi shaper. EAAR fue rápido en detectar un cambio en la latencia para el SLA Transactional, ahora son 53 ms.\nBR10# show sdwan app-route stats local mpls summary Generating output, this might take time, please wait ... app-route statistics 30.2.10.2 30.2.20.2 ipsec 12386 12366 remote-system-ip 1.1.1.20 local-color mpls remote-color mpls sla-class-index 0,1,2 fallback-sla-class-index None enhanced-app-route Enabled sla-dampening-index None app-probe-class-list None mean-loss 0.000 mean-latency 53 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 2048 0 54 0 4396 8513 0 0 1 1024 0 55 0 4461 8534 0 0 2 8256 0 49 0 4429 8549 0 0 3 16384 0 54 0 4411 8549 0 0 4 0 0 53 0 4440 8549 0 0 5 0 0 54 0 4443 8549 0 0 app-probe-class-list Real_Time_Probe_Class mean-loss 0.000 mean-latency 0 mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 0 0 0 0 - - - - 1 0 0 0 0 - - - - 2 8192 0 0 0 - - - - 3 16384 0 0 0 - - - - 4 0 0 0 0 - - - - 5 0 0 0 0 - - - - app-probe-class-list Transactional-Probe_Class mean-loss 0.000 mean-latency 53 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; mean-jitter 0 TOTAL AVERAGE AVERAGE TX DATA RX DATA IPV6 TX IPV6 RX INDEX PACKETS LOSS LATENCY JITTER PKTS PKTS DATA PKTS DATA PKTS ------------------------------------------------------------------------------------------------------------- 0 2048 0 54 0 - - - - 1 1024 0 55 0 - - - - 2 8256 0 49 0 - - - - 3 16384 0 54 0 - - - - 4 0 0 53 0 - - - - 5 0 0 54 0 - - - - Ahora que no se cumple mi SLA Transactional con una latencia máxima de 45 ms, usaré NWPI para comprender cómo se envía el tráfico. Examinemos el tráfico HTTP con el puerto 80000\nObserva que, en la dirección upstream, el color local y remote es private1, lo que indica que el tráfico se ha alejado de MPLS y su latencia de 53 ms. Justo lo que esperábamos ✅\nAhora, veamos cómo está fluyendo el tráfico en el puerto 22\nUna vez más, observa el local y Remote Color en la dirección upstream, observa cómo MPLS todavía está en uso para este tráfico, ya que no hay problemas en los transportes para este tipo de tráfico.\nEn resumen, el tráfico con DSCP 46 funciona perfectamente bien en el transporte MPLS, sin embargo, el tráfico con DSCP 18 estaba teniendo más latencia que el SLA configurado, por lo que se trasladó a Private1 ya que cumple con el SLA.\nPodemos confirmar que estamos midiendo y tomando decisiones de ruteo per queue, esta es una gran diferencia 🤯!\nLecciones aprendidas Utilizando inline data, el número de muestras aumenta dramáticamente en comparación con el tamaño de muestra de BFD. 📈 EAAR puede redirigir el tráfico en segundos, en lugar de minutos. ⏩ EAAR ofrece los mayores beneficios en los transportes con QoS, como MPLS. 🚀 Incluso en los transportes sin QoS, las mediciones de inline data aumentan el tamaño y la precisión de las muestras. ⏳ El temporizador de dampening es útil para garantizar que los transportes sean estables antes de marcarlos como válidos. ✅ La interoperabilidad entre dispositivos que ejecutan EAAR y dispositivos que ejecutan AAR es posible 🔄 ¡Espero que hayas aprendido algo útil! Nos vemos en el siguiente 👋\n","permalink":"http://localhost:1313/mejorado-aar/","summary":"Aprende los beneficios de EAAR y cómo implementarlo en tu red","title":"Enhanced App Aware Routing"},{"content":"Introducción En mi Última publicación, creé un asistente de IA de Cisco SD-WAN para ayudarme a ejecutar trazas NWPI y solucionar problemas en la red. La interacción con el asistente requería que el usuario respondiera preguntas hasta obtener información sobre un flujo particular y posibles problemas. En esta publicación, mi objetivo es usar múltiples agentes y ver si puedo llegar a la misma conclusión con menos interacción humana. Se puede encontrar el repositorio aquí\nPrimeros Pasos Para lograr esto, usaré LangGraph oficialmente definido como:\nUna biblioteca para construir aplicaciones de actores múltiples estatales con LLMS, utilizada para crear flujos de trabajo de agentes y múltiples agentes\nHay diferentes enfoques, pero decidí construir una estructura donde hay un supervisor que orquesta el flujo de trabajo y decide quién debe actuar a continuación. La idea es construir un gráfico que represente a los agentes y cómo están conectados. El gráfico ilustra el orden en el que los agentes pueden ejecutarse.\nEn mi caso tengo 3 agentes:\nSupervisor - Este agente está a cargo de recibir input del usuario y decidir quién debe actuar a continuación. Además, una vez que otros agentes terminen sus tareas, le informarán y se tomará una nueva decisión de enrutamiento. El supervisor es el único agente que puede decidir cuándo volver al usuario con una respuesta. Reviewer - Este agente revisará la información que se enviará al usuario, realiza algunas preguntas o resúmenes y resuelve preguntas o situaciones que el tracer pueda plantear. Tracer - Este es el agente que ejecutará las trazas y recuperará la información que el usuario está buscando. Se informará al supervisor cuando se haga o si se debe responder alguna pregunta. Tuve que modificar un poco el prompt del tracer, para poder obtener un comportamiento que sea mejor para este enfoque. Además, cada agente puede tener sus propias herramientas. Actualmente, el Tracer tiene más herramientas que el resto de los agentes.\nVisualizado, el gráfico se ve así:\nLa flecha punteada indica un borde condicional, lo que significa que el supervisor puede decidir cuál debe ser el próximo agente o si terminar es apropiado.\nLa flecha continua indica el siguiente paso que debe seguirse Por ejemplo, después de \u0026ldquo;START\u0026rdquo;, el siguiente agente debe ser el supervisor. Tracer y Reviewer deben ir al Supervisor.\nAunque este es un gráfico simple, este enfoque es muy poderoso.\n¿Cómo decide el supervisor? El supervisor juega un papel fundamental, ya que determina quién debe actuar a continuación. Esto se define en la siguiente función:\noptions = [\u0026#34;FINISH\u0026#34;] + members function_def = { \u0026#34;name\u0026#34;: \u0026#34;route\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Select the next role.\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;routeSchema\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;next\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Next\u0026#34;, \u0026#34;anyOf\u0026#34;: [ {\u0026#34;enum\u0026#34;: options}, ], } }, \u0026#34;required\u0026#34;: [\u0026#34;next\u0026#34;], }, } Con esto, cada vez que el supervisor reciba cualquier input, obtendrá un valor de \u0026ldquo;next\u0026rdquo; de las opciones disponibles y esto representará el siguiente nodo en el gráfico.\nDemo Usaremos la siguiente topología para probar\nLe doy información al asistente sobre el problema e informo que ya hay tráfico en la red (se requiere tráfico para que NWPI genere los insights que estamos buscando).\nEsto es con lo que regresó el asistente\nLa respuesta presenta información de manera condensada, que indica el flujo y el camino que el tráfico está tomando y algunos eventos detectados para esta comunicación. Los detalles de uno de los flujos también están presentes, sin embargo, tiene menos información que antes. Esto se debe a que he pedido al agente reviewer que mantenga lo que considera más relevante y lo envíe al usuario. Al final, podemos ver que se menciona el Drop Report y hay una sugerencia para revisar las ACL 🎉\nPodemos jugar con el reviewer para mostrar más información sobre los detalles del flujo.\nDetrás de cámaras Ok, el asistente regresó con una buena respuesta, pero veamos con más detalle lo que sucedió. Usando LangSmith podemos obtener detalles e insights sobre el workflow. Aquí está el proceso completo.\nPrimero, el supervisor recibe la consulta del usuario y la pasa al Tracer.\nA continuación, el Tracer utiliza las herramientas disponibles para iniciar la traza, espera capturar algunos flujos y recupera información. Informa al Supervisor. Ten en cuenta que el orden en que se ejecutan las herramientas depende del agente.\nLuego, el supervisor recibe la información y decide que el reviewer debería actuar a continuación.\nA continuación, el reviewer recibe la información y reescribe lo que se recibió del tracer. Informa al supervisor.\nFinalmenete, el supervisor decide que la información está lista para enviarse al usuario. Esto es cuando recibimos el mensaje en Webex.\nLecciones aprendidas Dado que los agentes pueden tomar decisiones, no siempre es fácil entender lo que están haciendo o por qué devuelven lo que devuelven, usando LangSmith definitivamente ayudó con esto. No solo podemos ver el request y las herramientas utilizadas, sino que también hay algunos metadatos que proporcionan información valiosa adicional. Llegué a algunas situaciones en las que el supervisor llamaba al tracer varias veces debido a algún error al recuperar la información. Al final, esto fue causado por un error en el código y, afortunadamente, mi asistente no es costoso. Sin embargo, si tu caso de uso consume muchos tokens, debes considerar agregar algún tipo de protección para evitar un loop que aumente el consumo de APIs. Hablando de costos, los modelos de lenguaje pequeño (SLM) son una buena alternativa. Después de quedarme sin cuota, recordé que el modelo GPT-4o-mini está disponible y decidí intentarlo. Después de algunas pruebas, vi que funcionó muy bien y era mucho más barato, así que continué con ese. Conclusión Usando la estrategia de múltiples agentes, podemos lograr tareas más complejas y tener más flexibilidad. Si es necesario, la interacción del usuario se puede agregar en ciertas decisiones que son importantes. Además, existe cierta complejidad adicional, ya que prompts deben refinarse para lograr los resultados que esperamos. En mi caso, tuve que hacer múltiples iteraciones y refinamientos a los prompts de todos los agentes antes de obtener un resultado que consideraba lo suficientemente bueno.\nMe interesa probar otros enfoques para las implementaciones de múltiples agentes y agregar información adicional para que los agentes proporcionen información más precisa a través de RAG.\n","permalink":"http://localhost:1313/mejorando-mi-asistente-sd-wan-multiples-agentes/","summary":"Aprende cómo utilizar un enfoque \u0026ldquo;agentic\u0026rdquo; para hacer troubleshooting de tu red SD-WAN con LLMs","title":"Mejora de mi asistente de SD-WAN - Múltiples agentes"},{"content":"Introducción Hace tiempo que quería subirme al tren de los LLM y aprender a usar uno de los frameworks más populares. Hace unos meses, vi una excelente presentación en Cisco Live de mi buen amigo Jesús, y eso me dio la determinación que necesitaba para finalmente profundizar en el tema.\nDesde entonces, he estado investigando y pensando en un buen caso de uso que pudiera servir como objetivo para mi proceso de aprendizaje. Después de considerar diferentes opciones, decidí construir un asistente de IA para SD-WAN que pudiera ayudarme a solucionar problemas relacionados con esta tecnología. Aprovechando las herramientas disponibles, decidí que mi asistente sería un experto en la funcionalidad de Network Wide Rath Insights.\nEn esta publicación, quiero compartir un poco de mi experiencia para construirlo y, por supuesto, mostrar algunos de los resultados. Para entenderlo mejor, sugiero tener el repositorio de Github abierto y consultarlo a medida que avanzas por la publicación.\nSobre la configuración Mi laboratorio SD-WAN está corriendo la versión 20.12.3 y WAN edges están utilizando 17.9.4a. Tengo una topología muy simple:\nEl lenguaje de programación utilizado es Python y el framework que elegí para interactuar con el LLM es Langchain. Utilicé OpenAI Model GPT-4o y un bot de webex para la interacción. El repositorio se puede encontrar aquí.\nMi objetivo Para dar contexto, la solución de problemas dentro de una infraestructura SD-WAN no es sencilla debido a que el tráfico está cifrado, las políticas dictan cómo fluirá el tráfico, pueden existir múltiples caminos hacia un destino, los siguientes saltos pueden cambiar según las políticas, hay múltiples saltos involucrados, entre otros factores. Determinar toda esta información lleva tiempo y no es un proceso directo.\nNWPI Trace es una herramienta que mejora significativamente el proceso de troubleshooting, ya que proporciona información y visibilidad salto a salto. Se puede iniciar fácilmente desde la interfaz del Manager, detecta flujos según filtros especificados y permite explorar la red para obtener toda la visibilidad necesaria. Es una herramienta muy completa y avanzada.\nComo mencioné antes, quería utilizar este proyecto como un campo de prueba para aprender, y dado que no tenía experiencia previa con LLMs o LangChain, establecí un objetivo sencillo:\nConstruir un asistente que pueda iniciar una traza NWPI y darme detalles de los flujos\nPlanificación y construcción Ok, tengo mi objetivo, pero ¿cómo comienzo?\nTomé un enfoque práctico que significaba que no aprendí Langchain desde cero y en su lugar tomé el repositorio de la sesión de Cisco Live como base y construí sobre eso. Las razones para elegir este repositorio fueron simples:\nSe explicó en las sesiones, así que tuve una idea general de las tecnologías y su propósito. Pensé que sería fácil ajustar a mi caso de uso (por ejemplo, también uso webex, interactuaré con dispositivos de red, vi cómo las herramientas podrían reemplazarse con la mías) Tuve que limpiar un poco antes de comenzar, esto me requirió que entendiera lo que era esencial para hostear el LLM e interactuar con él. Afortunadamente, el repositorio tiene una estructura organizada que facilita la comprensión.\nDe la sesión, aprendí sobre [Langchain Tools] (https://python.langchain.com/v0.1/docs/modules/tools/), así que sabía que podría crear funciones que mi agente podría usar para realizar diferentes acciones. En este caso, las acciones serían algo así como comenzar trazas y leer la información obtenida.\nDesafío 1 Necesitaba familiarizarme con la APIs de NWPI. En este punto, sabía que en algún lugar de la documentación de la API había visto que algunas operaciones estaban disponibles, pero nunca me había tomado el tiempo de analizarlas en detalle. Para mi sorpresa, las acciones específicas de iniciar un trace y obtener sus detalles no estaban incluidas… En su lugar, encontré información sobre cómo iniciar una \u0026ldquo;tarea\u0026rdquo; o \u0026ldquo;Auto-on Task\u0026rdquo;, que no es lo mismo que el \u0026ldquo;Trace\u0026rdquo; que tenía en mente.\nEn este punto, tenía que decidir si seguir el camino \u0026ldquo;oficial\u0026rdquo; (quizás más fácil) o explorar una alternativa para lograr exactamente lo que quería.\nSabiendo que casi todo en SD-WAN es impulsado por APIs, usé la pestaña de inspección de mi navegador y comencé a explorar las APIs que se activaban cuando iniciaba un trace desde la UI. Después de una primera revisión rápida, determiné que era factible y comencé a recopilar la información que necesitaba.\nDesafío 2 Ya sabía que tendría que hacer algo de análisis para convertir mi idea en realidad, pero subestimé cuánto tendría que hacer. De hecho, la dificultad de esta tarea me alejó del proyecto por un tiempo, ya que se volvió cada vez más compleja.\nEn mi mente solo había 3 tareas \u0026ldquo;simples\u0026rdquo;:\nEncontrar la API para iniciar el trace Encontrar la API para confirmar que el trace está en ejecución Encontrar la API que me dé detalles de los flujos API para iniciar la traza Iniciar la traza desde la interfaz de usuario es muy sencillo, solo necesitas un Site ID y un VPN ID. Sin embargo, hay verificaciones subyacentes que damos por sentadas.\nEl Site ID realmente es necesario para identificar los dispositivos en los que iniciar la traza Hay una serie de opciones (informes de QoS, visibilidad ART, visibilidad de aplicaciones, DIA, etc.) que dependen de la versión La VPN debe existir Para realizar esto, creé la función get_device_details_from_site para poder encontrar la información relacionada con los dispositivos en los que iniciar el trace. Necesitaba:\nversiones números de serie nombres estado de conectividad Luego, creé la función start_trace que recibiría la información obtenida previamente y otros filtros. Mantuve los filtros lo más simples posible, dejando solo la opción de especificar una subred de origen y destino. Hay muchas opciones para la traza para las cuales no realicé ninguna verificación de versión antes de ejecutarla, solo lo hice para los informes de QoS, que requieren la versión 17.9 o posterior. Esta función devuelve información necesaria más adelante para verificar el estado.\nAPI para confirmar que la traza se está ejecutando Esta fue probablemente la tarea más fácil. Creé la función verify_trace_state y con la ayuda del LLM se puede ejecutar unos segundos después de comenzar la traza. Devuelve el estado, que también es necesario para obtener información más adelante.\nAPI para darme detalles de los flujos Esta fue la tarea más compleja y tardada. En mi mente, verificar el resultado de una traza es muy simple, sin embargo, cuando recibimos la información en pedazos, a través de diferentes llamadas comienza a ser complicado.\nIntenté replicar el proceso que sigo en la interfaz de usuario:\nVer las estadísticas del trace y comprobar los flujos que fueron capturados (si es que hay alguno). Para la lista de flujos, buscar el que tiene el botón \u0026ldquo;readout\u0026rdquo; en rojo (problema detectado) y hacer clic para obtener más detalles. Expandir la vista del flujo para acceder a las funcionalidades avanzadas y así determinar las características por las que el paquete pasa en cada uno de los saltos. Para obtener los flujos capturados en el trace, creé la función get_flow_summary. Esta función devolverá la lista de los flujos capturados. Verás detalles como origen/destino, aplicación y protocolo. Esto es útil para identificar el flujo cuyo id te interesa para obtener más detalles.\nCreé la función trace_readout para obtener un resumen de los eventos que el trace capturó junto con el camino afectado. Por ejemplo, podrías ver que un flujo SSH no está funcionando entre el Dispositivo X y el Dispositivo Y.\nUna vez que hayas identificado el flujo y los eventos que te interesan, puedes obtener información detallada del flujo con la función get_flow_detai. Esto te proporcionará información como:\nHops Eventos Colores locales/remotos Interfaces de entrada/salida Funcionalidades de entrada/salida aplicadas a los paquetes Funcionalidad que determina decisión de ruteo Con esta información es posible ver todo tipo de cosas, como ACLs, tipo de políticas aplicadas, por qué un paquete fue enviado a través de un color específico, caídas, confirmar que tu política está funcionando como se espera, etc.\nOk, creo que eso es todo\nDemo Comencé creando un ACL para bloquear la comunicación y la apliqué en el lado de DC.\nMunich_DC100-1 - ACL configuration sdwan interface GigabitEthernet2 access-list ACL_Drop_172_16_10_0 out policy access-list ACL_Drop_172_16_10_0 sequence 1 match source-ip 172.16.10.0/24 destination-ip 172.16.100.0/24 ! action drop count dropCounter ! ! default-action accept ! ¿Mi asistente detectará esto? 🤔\nA continuación, comienzo la aplicación y solicito que el LLM inicie una traza. Puedo confirmar en la UI que se crea.\nLanzo un par de conexiones SSH de Branch a DC\nDespués, le pregunto al asistente si se han capturado flujos, responde con esto\nPodemos ver que los flujos fueron capturados y también me dio más información sobre los eventos detectados y el camino que tomaron los paquetes incluyendo los nombres de los dispositivos. El primer evento parece estar relacionado con nuestro problema. Hasta ahora, la información parece precisa, voy a pedir más detalles.\nCon esto, podemos ver que el cliente envió múltiples intentos de SSH, podemos profundizar en uno de los flujos. Veamos qué más da.\nFinalmente, el asistente proporciona información detallada sobre las funcionalidades que se aplican a cada uno de los flujos. En el segundo salto, en Munich DC, podemos ver que las funcionalidades de salida muestran el SD-WAN ACL y un \u0026lsquo;Drop Report\u0026rsquo;. El asistente proporciona su propia conclusión y también sospecha que el router de Munich está tirando el tráfico.\nCon un poco más de trabajo, el agente podría decir el nombre del ACL y el número de secuencia responsable de tirar el tráfico. ¡Hemos identificado con éxito la raíz del problema! 😀 🎉\nLecciones aprendidas Cuando comencé, quería ser súper cauteloso con los créditos ($$), así que estaba usando GPT-3.5-Turbo-16k que es más barato pero también menos inteligente. En algún momento, enfrenté problemas con el LLM entrando en un loop, decidí probar GPT-4O y sentí una diferencia en la forma en que el agente estaba razonando. Inicialmente, estaba usando una temperatura LLM = 0, esto estaba bien, pero las respuestas carecían de variedad y detalles, necesitaba hacerlo más hablador. Ajustar la temperatura = 0.9 me dio un buen equilibrio entre la charla y la corrección (aunque a veces el agente todavía proporciona información que es cuestionable en función de las salidas) Hacer troubleshooting puede ser difícil a veces, principalmente me basé en imprimir los resultados de las funciones mientras estas se ejecutaban y el agente imprimía en la terminal. Esto me permitió entender qué herramientas estaba utilizando el agente y el orden en que las utilizaba. Además, pude ver qué estaban devolviendo esas herramientas. Aquí tienes un ejemplo: El texto en verde indica las herramientas a las que está accediendo al agente. El texto amarillo es la información devuelta por una función. En este caso, podemos ver que el agente llamó la función \u0026quot;get_entry_time_and_state\u0026quot; para que obtener información necesaria para llamar a la siguiente función \u0026quot;get_flow_detail\u0026quot;\nHay mejores herramientas disponibles para ayudar con la resolución de problemas como LangSmith Tracing, lo voy a explorar en el futuro.\nEl prompts de mi agente tuvo que ser refinado varias veces, a menudo me di cuenta de que necesitaba proporcionar más detalles para manejar ciertas situaciones correctamente, especialmente cuando la salida de una función era necesaria para llamar a otra o para manejar situaciones inesperadas. Creo que aún puede mejorarse, de hecho, quiero escribir un prompt completamente diferente para intentar hacer que el agente ejecute todas las herramientas por sí mismo y solo devuelva una conclusión después de analizar todas las salidas. Conclusión En general, fue un buen y largo ejercicio de aprendizaje esto de construir mi primer asistente. Me siento contento con el resultado, ya que logré alcanzar mi objetivo. Al mismo tiempo, reconozco que hay muchas cosas que se pueden mejorar para hacer que los resultados sean más confiables y significativos. Además, hay mucha más información que NWPI puede mostrar, por lo que las herramientas definitivamente se pueden ampliar.\nComo siguiente paso, planeo aprender LangChain adecuadamente y entender cómo puedo implementar múltiples agentes para mejorar la funcionalidad y confiabilidad de mi asistente.\n¡Espero que este post te ayude de la misma manera que la presentación de Cisco Live me ayudó a mí!\n","permalink":"http://localhost:1313/creando-mi-primer-asistente-ai-con-langchain/","summary":"Descubre cómo los LLMs se pueden integrar con Cisco SD-WAN para hacer troubleshooting de manera sencilla y sin estrés","title":"Creando mi primer asistente de AI SD-WAN con Langchain"},{"content":"Introducción A medida que las redes evolucionan para ofrecer una mejor experiencia de usuario y se introducen nuevas tecnologías para gestionar la red, mantener todo funcionando sin problemas se ha vuelto cada vez más difícil. Una de las responsabilidades más críticas del equipo de operaciones es hacer un seguimiento de los problemas que ocurren en toda la red. Identificarlos es solo el comienzo, luego deben ser registrados y gestionados hasta su resolución. ¡Multiplica la cantidad de acciones por incidente y tendrás suficiente para mantener ocupado a tu equipo de TI todo el día!\nEn este post, te mostraré lo que necesitas saber para integrar el SD-WAN Manager con ServiceNow para la gestión de incidentes. Veremos algunos de los problemas más comunes en SD-WAN.\nConfiguración de laboratorio Estoy utilizando la versión 20.12.1 de SD-WAN Manager y tengo una instancia de desarrollador de ServiceNow. Mi servidor de Webhook funciona en Ubuntu 20.04 LTS y construí el receptor de Webhook en lenguaje Go.\nPara simplificar las cosas, tengo comunicación directa entre todos los elementos de mi laboratorio.\nWebhooks Los Webhooks son una manera en que las aplicaciones web se comunican entre sí en tiempo real. Permiten que una aplicación envíe notificaciones automáticas a otra aplicación cuando ocurre un evento específico, lo que se conoce como el modelo push. Esto facilita la integración entre diferentes sistemas y puede usarse para activar actividades automatizadas posteriores. Los Webhooks típicamente utilizan callbacks HTTP para compartir notificaciones/información.\nEn nuestro escenario, el SD-WAN Manager monitoreará eventos en BR10 y enviará solicitudes HTTP POST a nuestro servidor de Webhook cuando ocurran eventos específicos. Esto nos permitirá gestionar los incidentes en ServiceNow.\nAnatomía de una notificación webhook Comprendamos la estructura y la información que el SD-WAN Manager compartirá con nuestro servidor Webhook.\nEste es un ejemplo de la información enviada cuando alguna interfaz va abajo\n{ \u0026#34;suppressed\u0026#34;: false, \u0026#34;devices\u0026#34;: [ { \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34; } ], \u0026#34;eventname\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;rulename\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;component\u0026#34;: \u0026#34;VPN\u0026#34;, \u0026#34;entry_time\u0026#34;: 1709277345253, \u0026#34;statcycletime\u0026#34;: 1709277345253, \u0026#34;message\u0026#34;: \u0026#34;The interface oper-state changed to down\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Critical\u0026#34;, \u0026#34;severity_number\u0026#34;: 1, \u0026#34;uuid\u0026#34;: \u0026#34;9e2f7630-d504-4cdf-b808-fc8e29a6dd47\u0026#34;, \u0026#34;values\u0026#34;: [ { \u0026#34;host-name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;if-name\u0026#34;: \u0026#34;GigabitEthernet2\u0026#34;, \u0026#34;new-state\u0026#34;: \u0026#34;down\u0026#34;, \u0026#34;vpn-id\u0026#34;: \u0026#34;0\u0026#34; } ], \u0026#34;rule_name_display\u0026#34;: \u0026#34;Interface_State_Change\u0026#34;, \u0026#34;receive_time\u0026#34;: 1708843127894, \u0026#34;values_short_display\u0026#34;: [ { \u0026#34;host-name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;if-name\u0026#34;: \u0026#34;GigabitEthernet2\u0026#34;, \u0026#34;new-state\u0026#34;: \u0026#34;down\u0026#34; } ], \u0026#34;system_ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;host_name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;acknowledged\u0026#34;: false, \u0026#34;active\u0026#34;: true } Veamos la información más importante para nosotros:\n\u0026quot;active\u0026quot;: true - ¿Tenemos un problema? Sí, indicado por el estado activo \u0026quot;message\u0026quot;: \u0026quot;The interface oper...\u0026quot; - ¿Qué está pasando? \u0026quot;severity_number\u0026quot;: 1 - ¿Qué tan malo es? (escogí el numero y no el string a propósito) \u0026quot;uuid\u0026quot;: \u0026quot;9e2f7630-d504...d47\u0026quot; - Identificador del evento usado por el SD-WAN Manager \u0026quot;system_ip\u0026quot;: \u0026quot;1.1.10.1\u0026quot; - ¿Qué equipo originó la alerta? \u0026quot;host_name\u0026quot;: \u0026quot;BR10\u0026quot; - Identificador de equipo más amigable para los humanos Veamos la notificación cuando la interfaz se va arriba\n{ \u0026#34;suppressed\u0026#34;: false, \u0026#34;devices\u0026#34;: [ { \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34; } ], \u0026#34;eventname\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;rulename\u0026#34;: \u0026#34;interface-state-change\u0026#34;, \u0026#34;component\u0026#34;: \u0026#34;VPN\u0026#34;, \u0026#34;entry_time\u0026#34;: 1709277482508, \u0026#34;statcycletime\u0026#34;: 1709277482508, \u0026#34;message\u0026#34;: \u0026#34;The interface oper-state changed to up\u0026#34;, \u0026#34;severity\u0026#34;: \u0026#34;Medium\u0026#34;, \u0026#34;severity_number\u0026#34;: 3, \u0026#34;uuid\u0026#34;: \u0026#34;5486325c-d189-4467-9b5a-16acb1f28ec9\u0026#34;, \u0026#34;values\u0026#34;: [ { \u0026#34;host-name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;if-name\u0026#34;: \u0026#34;GigabitEthernet2\u0026#34;, \u0026#34;new-state\u0026#34;: \u0026#34;up\u0026#34;, \u0026#34;vpn-id\u0026#34;: \u0026#34;0\u0026#34; } ], \u0026#34;rule_name_display\u0026#34;: \u0026#34;Interface_State_Change\u0026#34;, \u0026#34;receive_time\u0026#34;: 1708843265147, \u0026#34;values_short_display\u0026#34;: [ { \u0026#34;host-name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;system-ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;if-name\u0026#34;: \u0026#34;GigabitEthernet2\u0026#34;, \u0026#34;new-state\u0026#34;: \u0026#34;up\u0026#34; } ], \u0026#34;system_ip\u0026#34;: \u0026#34;1.1.10.1\u0026#34;, \u0026#34;host_name\u0026#34;: \u0026#34;BR10\u0026#34;, \u0026#34;acknowledged\u0026#34;: false, \u0026#34;cleared_events\u0026#34;: [ \u0026#34;9e2f7630-d504-4cdf-b808-fc8e29a6dd47\u0026#34; ], \u0026#34;active\u0026#34;: false } Las dos cosas más importantes son:\n\u0026quot;active\u0026quot;: false - ya no está activo o presente \u0026quot;cleared_events\u0026quot;: [\u0026quot;9e2f7630-d504...d47]\u0026quot; - ID del evento que se resuelve Una cosa que debe saber es que no todos los eventos se comportarán de la misma manera. Algunos de ellos no tendrán una entrada de cleared_events, por lo que tendríamos que manejarlos de manera diferente si queremos cerrarlos automáticamente. Otros pueden carecer de cierta información dependiendo de lo que estemos monitoreando.\nAntes de codificar cualquier tipo de aplicación, es importante saber lo que deseas monitorear y lo que obtendrás del SD-WAN Manager para que puedas manejarlo correctamente.\nConfiguración de Webhooks en SD-WAN Manager El 20.12, es muy simple configurarlos, primero habilita la configuración de notificación desde Administration \u0026gt; Settings \u0026gt; Alarm Notifications\nDefinamos las reglas para activar nuestros webhooks. Desde Monitor \u0026gt; Logs \u0026gt; Alarm notification \u0026gt; Add Alarm Notification\nCosas que tienes que saber:\nPuedes elegir monitorear sitios o dispositivos. La severidad es crucial. Para abrir incidentes, generalmente querrás monitorear incidentes de severidad crítica o alta, y para cerrarlos necesitarás monitorear severidades más bajas. Las alarmas para las que deseas generar webhooks, en nuestro caso: BFD nodo fuera de servicio/activo Omp nodo fuera de servicio/activo Nodo de control fuera de servicio/activo Interfaz fuera de servicio/activa Ten en cuenta que solo estoy usando HTTP en mi URL de webhook, se recomienda usar HTTPS para mayor seguridad. El 8080:/webhook proviene de la aplicación que construimos. El threshold limitará la cantidad de notificaciones enviadas por minuto a esta URL. 15 es suficiente para mí, pero probablemente no lo sea para un entorno de producción. Por último, el usuario y la contraseña en caso de que tu aplicación de webhook lo requiera. Estos valores se codificarían y se enviarían en los encabezados. Usa valores ficticios si no son necesarios. Construyendo el servidor webhook El código que uso esta publicado en el siguiente Repo de Github, aquí lo explicaré de una manera más simple.\nPaso 1: Las solicitudes se esperan en el puerto 8080 al endpoint /webhook.\n// Listen upcoming requests http.HandleFunc(\u0026#34;/webhook\u0026#34;, handleWebhook) fmt.Println(\u0026#34;Server listening on port 8080...\u0026#34;) if err := http.ListenAndServe(\u0026#34;0.0.0.0:8080\u0026#34;, nil); err != nil { fmt.Printf(\u0026#34;Failed to start server: %v\u0026#34;, err) } Paso 2. Comprobar si la solicitudes tiene un estado activo. En caso afirmativo, creo un incidente en ServiceNow.\n//Verify if issue is active and create incident if data[\u0026#34;active\u0026#34;] == true { fmt.Println(\u0026#34;Opening Service Now incident...\u0026#34;) err := createIncident(data) Paso 2.1 Para abrir un incidente en ServiceNow, necesitamos reformatear la información que se enviará allí.\nfunc createIncident(data map[string]interface{}) error { // Retrieve information to open incident issueId := data[\u0026#34;uuid\u0026#34;].(string) ruleName := data[\u0026#34;rule_name_display\u0026#34;].(string) title := data[\u0026#34;message\u0026#34;].(string) severity := data[\u0026#34;severity_number\u0026#34;].(float64) severityStr := strconv.FormatFloat(severity, \u0026#39;f\u0026#39;, -1, 64) device := \u0026#34;. Device \u0026#34; + data[\u0026#34;host_name\u0026#34;].(string) + \u0026#34;, System-ip \u0026#34; + data[\u0026#34;system_ip\u0026#34;].(string) // Construct JSON payload for creating incident in SNOW incidentData := map[string]interface{}{ \u0026#34;category\u0026#34;: \u0026#34;network\u0026#34;, \u0026#34;caller_id\u0026#34;: \u0026#34;vManage\u0026#34;, \u0026#34;short_description\u0026#34;: issueId, \u0026#34;description\u0026#34;: ruleName + \u0026#34; - \u0026#34; + title + device, \u0026#34;urgency\u0026#34;: severityStr, \u0026#34;impact\u0026#34;: severityStr, } ... Observa que almaceno el uuid proveniente de vManage y lo usamos como short_description para ServiceNow.\nPaso 3.a Si el estado no es activo, verificamos si hay algún cleared_events incluido, esto nos dará una alta precisión al cerrar incidentes.\nif _, ok := data[\u0026#34;cleared_events\u0026#34;]; ok { ... clearedEvents, ok := data[\u0026#34;cleared_events\u0026#34;].([]interface{}) eventId := clearedEvents[0].(string) incidentExists, incident_id, err := getIncidentWithId(eventId) ... if incidentExists { err := closeIncident(incident_id) Para cerrar un caso, necesitamos tener el identificador de ServiceNow llamado sys_id. Para obtenerlo, usamos la función getIncidentWithId.\nfunc getIncidentWithId(issueId string) (bool, string, error) { ... // Store Service Now \u0026#34;short_description\u0026#34; shortDescription, ok := incidentMap[\u0026#34;short_description\u0026#34;].(string) // Compare the short_description with the issueId if strings.Contains(shortDescription, issueId) { // If the short_description matches the issueId, return the incident id sys_id, ok := incidentMap[\u0026#34;sys_id\u0026#34;].(string) if !ok { continue } return true, sys_id, nil Paso 3.b Si el estado no es activo y no hay _cleared events_ incluidos, vamos a intentar encontrar el incidente que se abrió. Hay tres cosas que verificamos:\nRule Name - Los nombres de reglas para los eventos que estamos monitoreando tendrán la siguiente estructura _node_. Por ejemplo, BFD_Node_Down. Si estamos viendo BFD_Node_Up, cambiaremos \u0026ldquo;Up\u0026rdquo; por \u0026ldquo;Down\u0026rdquo; y buscaremos BFD_Node_Down en los incidentes devueltos desde ServiceNow. System Ip - Almacene el System-IP contenido en la notificación y coincida con la descripción de cada incidente devuelto. Time - Almaceno el opened_at y verificamos si tiene menos de 12 horas. Esta es una medida totalmente subjetiva, pero mi idea es que los problemas que tardan más de 12 horas en resolverse, tendrían que ser verificados por algún humano. func getIncidentWoutId(ruleName, sysIp string, openTime float64) (bool, string, error) { ... // IncidentMap holds the incidents from Service Now description := incidentMap[\u0026#34;description\u0026#34;].(string) snowTime := incidentMap[\u0026#34;opened_at\u0026#34;].(string) newRuleName := strings.Replace(ruleName, \u0026#34;Up\u0026#34;, \u0026#34;Down\u0026#34;, -1) // Compare Rule Name, system ip and time if strings.Contains(description, newRuleName) \u0026amp;\u0026amp; strings.Contains(description, sysIp) \u0026amp;\u0026amp; diffHours \u0026lt; 12 { sys_id, ok := incidentMap[\u0026#34;sys_id\u0026#34;].(string) sys_id, ok := incidentMap[\u0026#34;sys_id\u0026#34;].(string) if !ok { continue } return true, sys_id, nil Paso 4. Cierra el caso con el sys_id obtenido a través de la función getIncidentWoutId.\nif incidentExists { err := closeIncident(incident_id) if err != nil { fmt.Printf(\u0026#34;Error closing incident: %v\\n\u0026#34;, err) // Handle the error accordingly (e.g., log it, return, etc.) return } } else { fmt.Printf(\u0026#34;Incident doesn\u0026#39;t exist or is older than 12 hours\u0026#34;) } Demo Comenzaremos ejecutando la aplicación en Go. Nota que no estoy usando VS Code para ejecutarla (Ctrl + F5), sino la terminal para permitir las conexiones entrantes.\nNotificación de interfaz Apagamos una de las interfaces de servicio en el router:\nBR10-1#config-transaction BR10-1(config)# interface GigabitEthernet 2 BR10-1(config-if)# shutdown BR10-1(config-if)# commit Commit complete. El servidor recibe la notificación y abre el incidente. El número de incidente es el identificador ServiceNow (sys_id)\nTraigo la interfaz arriba y el incidente se cierra\nObserve que esta notificación tiene la información de cleared_events, por lo que es muy fácil encontrar ese incidente en ServiceNow. Además, la severidad es \u0026lsquo;Medium\u0026rsquo;, por eso es importante establecer el valor correcto en la configuración de Alarm Notifications.\nObserva que State es Resolved y Resolution Notes indica que el incidente se cerró automáticamente a través de Webhooks.\nNotificaciones de BFD y Control Connections Bajemos las sesiones de control y BFD cerrando la apagando la interfaz de transporte\nBR10-1(config)# interface GigabitEthernet 1 BR10-1(config-if)# sh BR10-1(config-if)# commit Commit complete. Se reciben notificaciones y se crean incidentes\nCuando volvemos a habilitar la interfaz, recibimos las notificaciones y también registramos el estado de la interfaz para la interfaz Gig 1 y Tunnel1. Todo esto se refleja en ServiceNow. Estas notificaciones de interfaz no fueron entregadas antes porque se perdió la conectividad con el SD-WAN Manager.\nLecciones aprendidas Es muy importante monitorear el nivel de severidad correcto, de lo contrario podríamos perder notificaciones necesarias para cerrar los incidentes adecuadamente. El SD-WAN Manager puede generar muchas alertas, por lo que el umbral del webhook se vuelve muy importante. Deberías probar para encontrar el número que funcione para tu entorno. ServiceNow asignará una prioridad en función de la urgencia e impacto utilizados para crear el ticket. ServiceNow puede tener políticas que te impidan cerrar incidentes si cierta información no está presente en la interfaz. Familiarízate un poco con las políticas en la interfaz gráfica y Data Policies. Aunque puedes establecer manualmente el \u0026ldquo;sys_id\u0026rdquo; en ServiceNow mediante APIs, sugiero dejarlo como está, ya que poner valores manuales podría causar problemas en el futuro, y este campo debe ser único en tu instancia. Te recomiendo usar el valor generado automáticamente. Puedes usar sitios públicos como este para ver fácilmente el contenido de las notificaciones mientras planificas tus casos de uso. Conclusión Los webhooks son una excelente manera de monitorear nuestro entorno. Al ser notificado exactamente cuándo ocurre un problema en lugar de confiar en encuestas continuas, aumente nuestra capacidad de iniciar sesión y reaccionar rápidamente a lo que esté sucediendo. Puede combinar webhooks con otro tipo de alertas, como correos electrónicos o incluso chat (webex, holgura, etc.) en caso de que necesite alertar a diferentes equipos. Espero que esta publicación te haya dado algunas ideas o active tu curiosidad.\n¡Gracias por leerme!\n","permalink":"http://localhost:1313/rastreando-incidentes-de-sdwan-con-servicenow/","summary":"Aprenda a integrar Cisco SD-WAN con ServiceNow y automatiza la gestión de incidentes","title":"Seguimiento de incidentes SD-WAN con ServiceNow"},{"content":"Introducción Las Redes Definidas por Software (SDN) llegaron con la promesa de simplificar la administración de la red, permitiendo a los equipos de redes automatizar y adoptar un enfoque programático. Cisco creó soluciones como Catalyst Center, ACI, Meraki y Viptela SD-WAN. Esta última introdujo nuevos controladores que cambiaron las reglas que rigen el funcionamiento de la red WAN.\nLas organizaciones que no estaban listas para dar el salto completo a SD-WAN, pero que aún deseaban los beneficios de los principios de SDN, tenían opciones limitadas, como integrarse con sistemas de terceros o depender de Catalyst Center. Aunque estas soluciones resolvían algunos desafíos, quedó una brecha significativa sin cubrir hasta que llegó\u0026hellip; ¡SD-Routing!\n¿Qué es SD-Routing? En términos simples, SD-Routing es el punto medio entre SDN y SD-WAN. Con SD-Routing, las organizaciones pueden adoptar de manera gradual el enfoque de redes definidas por software en su infraestructura existente.\nLa idea detrás de esto es administrar la red no-SD-WAN (también conocida como \u0026ldquo;tradicional\u0026rdquo;) desde un Single Pane of Glass llamado SD-WAN Manager (anteriormente vManage). ¡Por supuesto, también es posible gestionar dispositivos SD-WAN al mismo tiempo!\nA diferencia de SD-WAN, no es necesario conectarse al SD-WAN Controller (anteriormente vSmart), por lo que los protocolos de ruteo existentes se mantienen. Además, se obtiene una capa de seguridad adicional con el SD-WAN Validator (anteriormente vBond), que se encarga de permitir la conexión solo a los dispositivos autorizados.\nBeneficios Algunos de los beneficios de SD-Routing incluyen:\nOnboarding – Los nuevos dispositivos pueden integrarse de forma fácil y rápida utilizando SD-WAN Manager. Configuración – Administra la configuración de tus dispositivos desde un único lugar mediante un método reutilizable llamado Configuration Groups, que permite escalar más rápido. Además, cuenta con workflows optimizados para políticas de seguridad y conectividad a la nube. Monitoreo – Supervisa tus dispositivos, sitios y aplicaciones. Recibe alertas y eventos, y aprovecha las capacidades de notificación de SD-WAN Manager. Gestión de software – Distribuye, instala y activa imágenes de software de manera sencilla y rápida en uno o varios dispositivos. Troubleshooting – Ejecuta diversas operaciones desde vManage, como sesiones SSH, pruebas de velocidad, traceroutes y más. Transición a SD-WAN – Si planeas implementar SD-WAN, SD-Routing es un excelente punto de partida para familiarizarte con SD-WAN Manager y simplificar la migración. 🚀 Descripción general del SD-WAN Manager Déjame darte un recorrido rápido por el SD-WAN Manager y un vistazo a algunas de las características. Si ya lo conoces, probablemente aún te sorprenderá el nuevo aspecto del 20.13. ¡Te lo enseño!\nDescripción general de la red Cuando iniciamos sesión por primera vez, se presenta un overview de la red para que podamos determinar rápidamente cuántos dispositivos y controladores están conectados, información de las aplicaciones, salúd de los equipos y más.\nOye, ¿a dónde se fue el Controller (vSmart)?\nSD-WAN Manager 20.13\nLa apariencia magnética te recordará a otros productos de seguridad de Cisco o Meraki, esto es genial para mantener la experiencia consistente. Observe que arriba a la derecha hay un botón que te permite activar el modo SD-Routing, esto es muy útil para mostrar la información referente a SD-Routing y la razón por la que no vemos el Controller.\nMonitoreo de red Si queremos ver información más detallada del dispositivo, podemos visitar la pestaña devices. SD-WAN Manager está constantemente actualizando esta información, por lo que tenemos una vista precisa. Nota como los dispositivos se muestran como SD-Ruting.\nBR20 no tiene una buena salud debido a la alta utilización de la memoria, ¿podríamos saber cuándo comenzó esto? Hagamos doble clic en él.\nComenzó a ir más allá del 75% alrededor de las 12:30, esto se debió a que activé Performance Monitor para obtener información del rendimiento de las aplicaciones.\nCentrémonos en el menú izquierdo, mira las opciones de monitoreo disponibles que incluyen aplicaciones, funciones de seguridad e información en tiempo real. La sección Troubleshooting es el lugar para usar las herramientas que mencioné anteriormente.\nConfiguración En las versiones 20.13/17.13 se agregó soporte para SD-Routing Configuration Groups. Con ellos, puedes crear Feature Profiles basados en parcels, que son elementos individuales que, en conjunto, conforman toda la configuración del router.\nEn la versión 20.13, los siguientes parcels están disponibles:\nTenemos el CLI Configuration Profile para aplicar cualquier configuración que no esté disponible a través de parcels. Podemos definir variables para hacer nuestro Profile reutilizable en múltiples dispositivos. También es posible usar un CLI Profile completo en lugar de parcels.\nPor cierto, si tienes una combinación de dispositivos SD-WAN y SD-Routing, verás ambos Configuration Groups en la lista. Actualmente, SD-WAN tiene un conjunto más amplio de parcels, pero con el tiempo, SD-Routing también recibirá más configuraciones sin depender de CLI.\nWorkflows La workflows library nos ayudará a realizar fácilmente ciertas acciones como onboarding, configuración de seguridad, actualizaciones de software, entre otras.\nEn lugar de hacer clic en múltiples páginas, podemos seguir un flujo paso a paso con toda la información necesaria en un solo lugar. Personalmente, me gusta cómo los workflows simplifican las cosas.\nConectividad con la nube Es muy probable que tu organización utilice algún tipo de conectividad a la nube, ya sea para acceder a aplicaciones o ejecutar cargas de trabajo. SD-Routing cubre esta necesidad.\nPuedes automatizar la conexión con el proveedor de nube, extendiendo tu red para acceder a esos recursos sin complicaciones.\nHay múltiples opciones. También se proporciona algo de esto para SD-WAN, por lo que recomiendo verificar la Guía de configuración de SD-Routing.\nConclusión El propósito de esta publicación es mostrar lo que es posible con SD-Routing y el vacío que busca llenar. Adoptar esta tecnología puede impactar positivamente los flujos de trabajo operativos, mejorar la agilidad de la red y optimizar la utilización de recursos.\nSi tu organización aún no ha adoptado ninguna forma de SDN, te invito a reflexionar sobre tus procesos diarios, identificar los principales desafíos y pensar en cómo SD-Routing podría ayudarte a resolverlos.\n¡Déjame saber qué opinas y nos vemos en el próximo post! 🚀\n","permalink":"http://localhost:1313/sd-routing-revoluciona-la-gestion-de-red/","summary":"Explora cómo SD-Ruting puede ayudarte de manera simple y efectiva a administrar y monitorear equipos autónomos (IOX-XE regular, sin SD-WAN).","title":"Un nuevo capítulo: SD-Routing revoluciona la gestión de red"},{"content":"Introducción Para la publicación final de esta serie, exploremos la opción restante para manejar el tráfico cuando no se cumple SLA: Fallback a Best Path. Se introdujo en 20.5/17.5 y proporciona más flexibilidad y selección de ruta mejorada en comparación con las otras opciones. Entendamos por qué fue creado.\nMotivación Con los [métodos anteriores] (/desmitificación-AAR-Enderstanding-Diferent-SceneRios/), el tráfico lo haría:\nse eliminará, rara vez se usan casos de uso específicos que se aplican a una pequeña cantidad de entornos. Esté equilibrado en las rutas disponibles, ampliamente utilizada, sin embargo, el tráfico podría estar utilizando la ruta de peor desempeño. Tome el siguiente ejemplo\nTunnel 2 claramente tiene el peor rendimiento, sin embargo, con el método load balance, el tráfico aún podría usarlo en función del algoritmo de hash. ¿Cómo superamos esta situación? Probablemente lo hayas adivinado: _ ** Falta a la mejor ruta ** _\nFuerte a la mejor ruta Veamos cómo lo describe la documentación:\nCuando el tráfico de datos no cumple con ninguno de los requisitos de la clase SLA, esta característica le permite seleccionar la mejor secuencia de criterios de ruta del túnel utilizando el túnel mejor alternativo.\nEl gerente de Cisco SD-WAN usa Best of Weor (Bow) para encontrar el mejor túnel cuando ningún túnel cumple con ninguno de los requisitos de la clase SLA.\nhttps://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-ware-routing.html\nlo mejor de lo peor Veamos cómo funciona Bow con el siguiente ejemplo:\nEl requisito de latencia de SLA se establece en 8. Ninguno de los túneles lo satisface, pero el túnel 1 es el más cercano, lo que lo convierte en lo mejor de peor con una latencia de 10.\nLos criterios para elegir el arco son extremadamente flexibles, en este ejemplo utilizamos latencia, otras opciones podrían ser:\nLatencia - Solo latencia Jitter - Solo jitter Pérdida - Solo pérdida Latencia/Jitter - Primera latencia, si son iguales, entonces Jitter Latencia/pérdida - Primera latencia, si son iguales, entonces pérdida Jitter/Latencia - Primer jitter, si son iguales, entonces latencia -. . . pérdida/jitter/latencia - Primera pérdida, luego fase, luego latencia Varianza Vamos un paso más allá, el túnel 3 también está muy cerca de la latencia 8 ms, no sería una mala idea enviar tráfico también en ese túnel. ¿Cómo logramos esto? Bueno, podemos implementar un variance para acomodar pequeñas variaciones al elegir las mejores rutas.\nContinuando con este ejemplo, echemos un vistazo a la selección de arco con una `varianza de 5 ms \u0026lsquo;.\nBow Range = (mejor latencia, mejor latencia + varianza) Rango de arco = (10, 15) La mejor latencia en los túneles es 10 (Túnel 1), observe que esto ** no es ** la latencia configurada en el SLA. Con esta varianza, si algún otro túnel tiene una latencia entre 10 y 15, también se eligirá para enviar tráfico. En nuestro ejemplo, el túnel 3 satisface la condición, por lo que ahora el túnel 1 y el túnel 3 se utilizarán como túneles fallback.\nComo puede ver, el túnel 2 ya no se considera. ¡Excelente!\nConfiguración Clase SLA Para usar este método, lo primero que debemos hacer es modificar nuestra clase SLA para indicar que debe buscar la ruta de mejor rendimiento cuando no se cumple SLA. Nuestra configuración se ve así:\nSLA-CLASS Custom-SLA Pérdida 1 Latencia 250 Jitter 100 alero-mejor túnel pérdida de criterios Varianza de pérdidas 2 Observe que seleccionamos el criteria para ser pérdida 'y un _variance_ de 2`. La varianza es un parámetro ** opcional **.\nPolítica AAR A continuación, en la política de AAR especificamos la acción cuando no se cumple SLA: Fallback a Best Path\nsecuencia 1 fósforo Fuente-IP 172.16.10.0/24 Destino-IP 172.16.20.0/24 acción SLA-CLASS Custom-SLA No hay clase SLA estricta MPLS de color de clase SLA SLA-Class Fallback-to-Best-Path Mantengamos la misma dinámica y construamos un diagrama:\nEscenarios Usando la misma topología exploremos algunas situaciones\nMPLS compatible, biz-internet/private1 no conforme Iniciaré el tráfico de Branch10 -\u0026gt; Branch 20 y lo capturaré con NWPI. MPLS tiene métricas KPI perfectas (0, 0, 0)\nObserve cómo fallback to Best Path se establece en `no \u0026lsquo;y el tráfico coincide con el SLA y el color preferido. Veamos también el siguiente comando de verificación de BR10. `` BR10#show sdwan tunnel sla \u0026lt;. . .\u0026gt; Túnel SLA-Class 1 SLA-NAME Custom-SLA SLA-Loss 1 SLA-Latencia 250 sla-jitter 100 RETROCEDER Remoto t sla sla Sistema DST SRC Local t remota media media media clase de clase PROTO SRC IP DST Puerto IP Puerto IP Color Pérdida de color Pérdida de latencia Jitter Índice SLA Nombre de clase Índice Gre 21.1.10.2 21.1.20.2 0 0 1.1.0.20 MPLS MPLS 0 0 0 0,1 all_tunnels, Custom-SLA Ninguno Gre 21.1.10.2 31.1.20.2 0 0 1.1.0.20 MPLS Biz-Internet 0 0 0 0,1 all_tunnels, Custom-SLA Ninguno GRE 21.1.10.2 41.1.20.2 0 0 1.1.0.20 MPLS Private1 0 0 0 0,1 all_tunnels, Custom-SLA Ninguno ``\nAlgunos comentarios sobre este resultado:\nEl hecho de que veamos túneles enumerados en Custom-SLA, nos dice que hay túneles que cumplen con la pérdida, la latencia y la fluctuación. Esto se espera ya que nuestro MPLS está teniendo métricas perfectas. Vea que esta clase SLA tiene un identificador numérico de 1-Túnel SLA-Class 1. Verá referencia a este número en breve. Fallback SLA Class Index está configurado en Ninguno, esto significa que estos túneles no se están utilizando como túneles de respaldo, esto quedará claro en un segundo. mpls/biz-inernet/private1 no conforma pero varianza de reunión Ahora que no tenemos transportes que cumplan con el SLA, verifiquemos cómo lo mostrará NWPI:\nObserve que ahora NWPI está indicando que fallback a la mejor ruta está en uso.\nPrivate1 fue elegido para enviar este flujo en particular, pero ¿hay otros túneles que pudieran usarse? Vamos a ver BR10 nuevamente.\n`` BR10# show sdwan tunnel sla Túnel SLA-Class 0 sla-name all_tunnels SLA-Loss 0 SLA-Latencia 0 sla-jitter 0 RETROCEDER SLA SLA remoto Sistema DST SRC T Local T Remote media media media clase PROTO SRC IP DST Puerto IP Puerto IP Color Pérdida de color Pérdida de latencia Jitter Índice SLA Nombre de clase Índice Gre 21.1.10.2 21.1.20.2 0 0 1.1.0.20 MPLS MPLS 18 0 0 0 0 all_tunnels Ninguno GRE 21.1.10.2 31.1.20.2 0 0 1.1.0.20 MPLS Biz-Internet 9 0 0 0 all_tunnels Ninguno Gre 21.1.10.2 41.1.20.2 0 0 1.1.0.20 MPLS Private1 11 0 0 0 all_tunnels Ninguno Gre 31.1.10.2 21.1.20.2 0 0 1.1.0.20 Biz-Internet Mpls 4 0 0 0 all_tunnels 1 Gre 31.1.10.2 31.1.20.2 0 0 1.1.0.20 Biz-Internet Biz-Internet 2 0 0 0 0 all_tunnels 1 Gre 31.1.10.2 41.1.20.2 0 0 1.1.0.20 Biz-Internet Private1 4 0 0 0 all_tunnels 1 GRE 41.1.10.2 21.1.20.2 0 0 1.1.0.20 Private1 MPLS 3 0 0 0 0 all_tunnels 1 GRE 41.1.10.2 31.1.20.2 0 0 1.1.0.20 Private1 Biz-Internet 6 0 0 0 all_tunnels Ninguno GRE 41.1.10.2 41.1.20.2 0 0 1.1.0.20 Private1 Private1 3 0 0 0 0 all_tunnels 1\nTúnel SLA-Class 1 SLA-NAME Custom-SLA SLA-Loss 1 SLA-Latencia 250 sla-jitter 100\nBR10# ``\nComentarios sobre este resultado:\nHay ** no ** túneles que cumplen con nuestro custom-sla Incluso si MPLS es el color preferido, ** no es ** considerado porque no cumple con el rango de varianza de pérdida. Hay 5 túneles que satisfacen la varianza. Observe cómo algunos túneles tienen una clase SLA de Fallback SLA Index establecido en 1, lo que significa que están sirviendo como alternativos para SLA-Class 1 (Custom-SLA). En este caso, el ** arco ** es biz-instantet-biz-insternet tunnel con una pérdida media de 2. El variance se establece en 2, por lo que el rango de arco es 2-4. Los túneles que satisfacen la gama de arco también se utilizarán para reenviar el tráfico. Dependiendo del hash de equilibrio de carga, se eligirán diferentes túneles `` BR10#show Sdwan Policy Service-Path VPN 10 Interfaz GigabitEthernet 3 Fuente-IP 172.16.10.2 Dest-IP 172.16.20.2 Protocolo 6 Dest-Port 22 Siguiente salto: Gre Fuente: 31.1.10.2 Destino: 21.1.20.2 Color local: Biz-Internet Color remoto: Sistema remoto MPLS IP: 1.1.0.20\nBR10#show SDWAN Policy Service-Path VPN 10 Interfaz GigabitEthernet 3 Fuente-IP 172.16.10.56 Dest-IP 172.16.20.2 Protocolo 6 Dest-Port 24 Siguiente salto: Gre Fuente: 31.1.10.2 Destino: 41.1.20.2 Color local: Biz-Internet Color remoto: Private1 Sistema remoto IP: 1.1.0.20 ``\nPodemos ver dos túneles diferentes biz -internet - mpls y biz -internet - privado\nLatencia fuera de cumplimiento Hasta ahora hemos estado jugando solo con pérdida, porque los criterios de alojamiento estaban establecidos en la pérdida. Veamos qué sucede cuando un criterio diferente no se cumple. Estableceré la latencia del SLA a 15 ms. .\n`` BR10#show sdwan política de vsmart From-vsmart SLA-Class Custom-SLA Pérdida 1 latencia 15 Jitter 100 alero-mejor túnel pérdida de criterios Varianza de pérdidas 2\n``\nDespués de presentar algo de latencia, vemos algo interesante:\n`` BR10#show sdwan tunnel sla Túnel SLA-Class 0 sla-name all_tunnels SLA-Loss 0 SLA-Latencia 0 sla-jitter 0 RETROCEDER SLA SLA remoto Sistema DST SRC T Local T Remote media media media clase PROTO SRC IP DST Puerto IP Puerto IP Color Pérdida de color Pérdida de latencia Jitter Índice SLA Nombre de clase Índice Gre 21.1.10.2 21.1.20.2 0 0 1.1.0.20 MPLS MPLS 0 20 1 0 all_tunnels 1 GRE 21.1.10.2 31.1.20.2 0 0 1.1.0.20 MPLS Biz-Internet 0 20 1 0 all_tunnels 1 Gre 21.1.10.2 41.1.20.2 0 0 1.1.0.20 MPLS Private1 0 20 0 0 all_tunnels 1 Gre 31.1.10.2 21.1.20.2 0 0 1.1.0.20 Biz-Internet Mpls 0 21 2 0 all_tunnels 1 Gre 31.1.10.2 31.1.20.2 0 0 1.1.0.20 Biz-Internet Biz-Internet 0 21 2 0 all_tunnels 1 Gre 31.1.10.2 41.1.20.2 0 0 1.1.0.20 Biz-Internet Private1 0 21 2 0 all_tunnels 1 Gre 41.1.10.2 21.1.20.2 0 0 1.1.0.20 Private1 MPLS 0 16 1 0 all_tunnels 1 GRE 41.1.10.2 31.1.20.2 0 0 1.1.0.20 Privado1 Biz-Internet 0 16 0 0 all_tunnels 1 GRE 41.1.10.2 41.1.20.2 0 0 1.1.0.20 Private1 Private1 0 16 0 0 all_tunnels 1\nTúnel SLA-Class 1 SLA-NAME Custom-SLA SLA-Loss 1 SLA-Latencia 15 sla-jitter 100\nBR10# ``\n¡Todos los túneles se usan como túneles respaldados porque todos tienen un 0% de pérdida! ¿Es esta la situación ideal? Esto es discutible, tal vez para algunos tipos de tráfico está bien, pero para otros probablemente desee tener un segundo o tercer criterio para elegir los mejores túneles de respaldo.\nCriterios de arco múltiple Para la última prueba, veamos qué sucede cuando seleccionamos múltiples criterios para seleccionar el arco. Agregaré latencia a los criterios de SLA.\nBR10#show sdwan política de vsmart From-vsmart SLA-Class Custom-SLA Pérdida 1 latencia 15 Jitter 100 alero-mejor túnel latencia de pérdida de criterios Varianza de pérdidas 2 Lo que esperamos es que si alguno de los KPI no cumple, el arco se decidirá en base a:\nPérdida media más baja. Si hay un empate, entonces Latencia más baja Verifiquemos `` BR10#show sdwan tunnel sla Túnel SLA-Class 0 sla-name all_tunnels SLA-Loss 0 SLA-Latencia 0 sla-jitter 0 RETROCEDER SLA SLA remoto Sistema DST SRC T Local T Remote media media media clase PROTO SRC IP DST Puerto IP Puerto IP Color Pérdida de color Pérdida de latencia Jitter Índice SLA Nombre de clase Índice Gre 21.1.10.2 21.1.20.2 0 0 1.1.0.20 MPLS MPLS 0 20 1 0 all_tunnels Ninguno Gre 21.1.10.2 31.1.20.2 0 0 1.1.0.20 MPLS Biz-Internet 0 20 1 0 all_tunnels Ninguno Gre 21.1.10.2 41.1.20.2 0 0 1.1.0.20 MPLS Private1 0 20 1 0 all_tunnels Ninguno Gre 31.1.10.2 21.1.20.2 0 0 1.1.0.20 Biz-Internet Mpls 0 20 1 0 all_tunnels Ninguno Gre 31.1.10.2 31.1.20.2 0 0 1.1.0.20 Biz-Internet Biz-Internet 0 20 1 0 all_tunnels Ninguno Gre 31.1.10.2 41.1.20.2 0 0 1.1.0.20 Biz-Internet Private1 0 21 1 0 all_tunnels Ninguno GRE 41.1.10.2 21.1.20.2 0 0 1.1.0.20 Private1 Mpls 0 16 0 0 all_tunnels 1 GRE 41.1.10.2 31.1.20.2 0 0 1.1.0.20 Privado1 Biz-Internet 0 16 0 0 all_tunnels 1 GRE 41.1.10.2 41.1.20.2 0 0 1.1.0.20 Private1 Private1 0 16 0 0 all_tunnels 1\nTúnel SLA-Class 1 SLA-NAME Custom-SLA SLA-Loss 1 SLA-Latencia 15 sla-jitter 100\nBR10# ``\nEstá claro que la pérdida no se usó para elaborar el arco, de lo contrario, veríamos todos los túneles actuando como respaldo para el índice de clase SLA 1. En cambio, se seleccionaron túneles con latencia más baja. Tenga en cuenta que podría haber agregado una varianza de latencia para incluir otros túneles con números similares.\nConclusión A través de las últimas tres publicaciones, hemos sido testigos de AAR como una funcionalidad crítica de SD-WAN para proteger el SLA de nuestras aplicaciones. Espero que después de explicar y verificar diferentes escenarios, ahora tenga una mejor comprensión y se sienta más seguro de probar AAR dentro de su infraestructura SD-WAN. Guía] (https://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-ware-routing.html#config-variance-best-tunnel-path) es muy completo, lo que está familiarizado con it y use lo necesita.\nDéjame saber tus pensamientos en los comentarios.\n¡Nos vemos pronto!\n","permalink":"http://localhost:1313/simplificando-aar-3-3-fallback-to-best-path/","summary":"Aprende cómo AAR puede ayudarte a mejorar la experiencia del usuario y aplicación con Cisco SD-WAN","title":"Simplificando AAR: 3/3 Fallback to Best Path"},{"content":"Introducción Bienvenido de nuevo a la segunda entrega de mi serie en Application Aware Routing (AAR). En mi publicación anterior, discutimos los conceptos básicos de BFD y SLAs, estableciendo las bases para comprender cómo AAR optimiza el rendimiento de la red en función de los requisitos de las aplicaciones. También tocamos brevemente la configuración de AAR con un ejemplo simple.\nAhora, vamos a ver en profundidad diferentes configuraciones de AAR cuando no hay túneles que cumplan con los SLAs, más específicamente nos concentraremos en el comportamiento de strict/drop y Preferred Backup SLA.\nTopología y configuración inicial Comencemos con una topología simple\nNo estoy limitando los túneles entre los colores, por lo que tenemos un total de 4 túneles en cada borde WAN.\nmpls - mpls mpls - biz-inet biz-inet- mpls biz-inet - biz-inet Este es el Hello interval de BFD y la configuración de app-route para todos los dispositivos; esto es lo más relevante para AAR. Si no estás familiarizado con ello, te recomiendo que revises mi última publicación antes de continuar.\nhello-interval 1000 bfd app-route multiplier 3 bfd app-route poll-interval 120000 Escenario 1: SLA not met - Strict/Drop Nuestra política de AAR está usando el SLA Business-Critical. Vou a introducir pérdida de paquetes para demostrar cómo cambia el tráfico.\nBR10#show sdwan policy from-vsmart from-vsmart sla-class Business-Critical loss 1 latency 250 jitter 100 from-vsmart app-route-policy _VPN10_AAR vpn-list VPN10 sequence 1 match source-ip 172.16.10.0/24 destination-ip 172.16.20.0/24 action sla-class Business-Critical sla-class strict sla-class preferred-color mpls sequence 11 match source-ip 172.16.20.0/24 destination-ip 172.16.10.0/24 action sla-class Business-Critical sla-class strict sla-class preferred-color mpls from-vsmart lists vpn-list VPN10 vpn 10 Leamos lo que dice la documentación sobre nuestra configuración:\nsla-class preferred-color mpls\nsla-class sla-class-name preferred-color color - Para configurar un túnel específico para el tráfico de datos que cumpla con una clase de SLA, incluye la opción preferred-color, especificando el color del túnel preferido. Si más de un túnel cumple con el SLA, el tráfico se enviará a través del túnel preferido. Si no hay un túnel del color preferido disponible, el tráfico se enviará a través de cualquier túnel que cumpla con la clase de SLA. Si ningún túnel cumple con el SLA, el tráfico de datos se enviará a través de cualquier túnel disponible.\nhttps://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-aware-routing.html\nAquí hay un diagrama para visualizarlo mejor:\nTen en cuenta que incluso si tanto Biz-Internet como MPLS cumplen con el SLA, solo se utilizará MPLS.\nSí, Biz-Internet se utilizará incluso si no está especificado como un color preferido si el color preferido no cumple con el SLA. Desde mi experiencia, esta es una fuente frecuente de confusión, ya que la expectativa suele ser que, si MPLS no cumple con el SLA, se ejecutará la acción de SLA not met sin considerar el resto de los colores.\nsla-class strict\nHaz clic en Strict/Drop para hacer un match estricto de la clase SLA. Si no hay un túnel de plano de datos disponible que satisfaga los criterios de SLA, se tira el tráfico.\nhttps://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-ware-routing.html\nAhora el diagrama se ve así:\nPrueba 1 - MPLS/Biz-internet cumplen SLA Inicio el tráfico de Branch 10 -\u0026gt; Branch 20 y lo capturo con NWPI. Tanto MPLS como Biz-Internet están teniendo métricas de KPI perfectas (0 pérdida, 0 latencia, 0 jitter)\nBR10-PC1#ssh -l admin 172.16.20.2 Password: Podemos ver que el color Actual Color mpls y Tunnel Match Reason is Matched sla and pref encap color. Todo funcionando de acuerdo con nuestra definición de política.\nPrueba 2- Biz-internet cumple, MPLS no cumple con SLA Introduzco el 3% de pérdida de paquetes en el enlace MPLS. Veamos qué pasa.\nAhora, nuestro túnel MPLS está por encima del 1% de pérdida, por lo que ya no es elegible. Confirmamos que el túnel biz-internet se usa porque cumple con el sla - Tunnel match reason es matched sla and color any\nPrueba 3-MPLS/Biz-internet no cumplen SLA Nuestra última prueba para este escenario será estropear los SLA para ambos transportes. Nuevamente, introduzco el 3% de pérdida de paquetes en ambos MPLS y Biz-internet.\nComo se esperaba, ahora el tráfico se está tirando en BR10, ya que no hay transportes que coincidan con el SLA. Nota como DROP_REPORT indica SdwanDataPolicyDrop\nEscenario 2: Backup SLA Preferred Color Exploremos un nuevo escenario, agregaremos un transporte adicional.\nNuestra configuración de políticas tendrá ligeros cambios. Es importante destacar que, al usar la opción Backup SLA preferred color, la única acción disponible cuando el SLA no se cumple será Load Balance.\nBR10#show sdwan policy from-vsmart from-vsmart sla-class Business-Critical loss 1 latency 250 jitter 100 from-vsmart app-route-policy _VPN10_AAR vpn-list VPN10 sequence 1 match source-ip 172.16.10.0/24 destination-ip 172.16.20.0/24 action backup-sla-preferred-color private1 sla-class Business-Critical no sla-class strict sla-class preferred-color mpls sequence 11 match source-ip 172.16.20.0/24 destination-ip 172.16.10.0/24 action backup-sla-preferred-color private1 sla-class Business-Critical no sla-class strict sla-class preferred-color mpls from-vsmart lists vpn-list VPN10 vpn 10 Nuevamente, veamos qué dice la documentación:\nbackup-sla-preferred-color private1\nCuando ningún túnel cumple con el SLA, se puede elegir cómo manejar el tráfico:\nbackup-sla-preferred-color colors: Dirige el tráfico de datos a un túnel específico. El tráfico de datos se envía a través del túnel configurado si la interfaz de dicho túnel está disponible; si no lo está, el tráfico se enviará por otro túnel disponible. Se pueden especificar uno o más colores.\nhttps://www.cisco.com/c/en/us/td/docs/routers/sdwan/configuration/policies/ios-xe-17/policies-book-xe/application-aware-routing.html\nPara ponerlo visualmente\nPrueba 1- MPLS/Private1 complen con el SLA, Biz-Internet no cumple Comenzaremos con la suposición de que Biz-Internet no cumple con el SLA, por lo que tenemos dos transportes disponibles: MPLS y Private1. Inicio el tráfico.\nBR10-PC1#ssh -l admin 172.16.20.2 Password: Nota como SLA Strict tiene un varlo de No y el MPLS cumple con el SLA y se usa.\nPrueba 2 - Private1 cumple con el SLA, MPLS/Biz-internet no cumplen Para la segunda prueba, estamos introduciendo pérdida en el transporte MPLS. Con esto, el único transporte que cumple con el SLA es Private1, que también es el color preferido de respaldo para el SLA. Veamos cómo se ve.\nEn el Tunnel Match Reason podemos ver claramente que el SLA se cumple a través de un color que no es el preferido (Private1). ¿Qué crees que sucederá si Private1 no cumple con el SLA?\nPrueba 3 - MPLS/Private1/Biz-Internet No confunde Private1 es el único transporte que cumple con el SLA, me encargaré de eso al introducir la pérdida de paquetes.\nDe nuevo (!) Private1 se usa, pero ahora el tráfico coincide con el SLA por defecto, en otras palabras, no hay túneles que coincidan con el SLA, por lo que se utilizará el túnel marcado backup preferred.\nBono Private1 no disponible\nEl resultado después de apagar la interfaz Private1, aún sin ningún túnel que cumpla con el SLA. Podemos ver que se realiza una coincidencia flexible en los túneles (se puede elegir cualquier túnel disponible).\nBiz-internet cumple, MPLS/Private1 no cumplen\nEl resultado después de que biz-internet vuelve a tener valores de pérdida cero, mientras que private1 no cumple con el SLA. Aunque no sea el color preferido, aún cumple con el SLA, por lo que es seleccionado.\nComo nota final, ten en cuenta que AAR siempre intentará usar los túneles que cumplan con el SLA especificado, no te confundas solo porque los nombres de los colores no están explícitamente mencionados en la configuración.\nEn la Siguiente publicación, exploraremos la opción restante Fallback to Best Path. ¡Nos vemos allí!\n","permalink":"http://localhost:1313/simplificando-aar-analizando-diferentes-escenarios/","summary":"Aprende cómo AAR puede ayudarte a mejorar la experiencia del usuario y aplicación con Cisco SD-WAN","title":"Simplificando AAR: 2/3 Analizando diferentes escenarios"},{"content":"Introducción Piensa en las tecnologías de enrutamiento que existen; la mayoría de ellas han mejorado mucho en reaccionar ante fallos de enlaces y cortes de energía mediante protocolos como OSPF LFA/FRR, EIGRP Feasible Successor, BGP PIC, etc.\nSin embargo, estos protocolos no son tan eficaces cuando se trata de abordar problemas como la degradación del rendimiento de la red durante brownouts, que pueden ser causados por fluctuaciones de energía o congestión en los enlaces. Estos escenarios presentan nuevos desafíos para los cuales los protocolos de enrutamiento tradicionales no tienen herramientas adecuadas.\nAquí es donde Application Aware Routing llega al rescate.\nA pesar de generar cierta confusión entre los clientes y quienes están aprendiendo sobre SD-WAN, Application Aware Routing (AAR) representa una ventaja fundamental de esta tecnología.\nEn esta serie, exploraremos los conceptos básicos para comprender los principios y comportamientos clave que nos permitirán analizar diferentes escenarios.\nUsaremos NWPI para entender mejor cómo funciona todo. Si no estás familiarizado con NWPI, te recomiendo leer este post que escribí sobre el tema.\nAAR explicado en 5 líneas Using IPSec tunnels formed between WAN Edges, BFD packets will be sent across them to measure the **loss, latency Utilizando túneles IPSec formados entre los WAN Edges, se enviarán paquetes BFD a través de ellos para medir la pérdida, latencia y jitter (KPIs).\nLos usuarios pueden definir SLAs para distintos tipos de tráfico (voz, web, video, etc.) y configurar políticas de AAR para garantizar que el tráfico se envíe a través de rutas que cumplan con el SLA.\nSi en algún momento la ruta deja de cumplir con el SLA, el tráfico será redirigido automáticamente a una ruta que sí lo haga.\nSencillo, ¿verdad? 😃\nSLAs El Service Level Agreement (SLA) se refiere a la cantidad de pérdida, latencia y jitter que una aplicación puede tolerar mientras sigue funcionando correctamente. Su definición debe ser precisa y realista según el tipo de tráfico y el entorno de la red.\nPor ejemplo, si estamos definiendo un SLA para voz, debemos conocer los valores aceptables de pérdida, latencia y jitter.\nSi nuestro SLA de voz tuviera estos valores:\nPérdida: 5% Latencia: 350 ms Jitter: 200 ms Es muy probable que las llamadas tengan una mala calidad.\nEn cambio, estos valores serían mucho mejores:\nPérdida: 1% Latencia: 150 ms Jitter: 50 ms También es importante considerar la naturaleza del entorno al definir estos valores. Hay lugares donde los proveedores pueden ser menos confiables, el tráfico puede recorrer grandes distancias y los tipos de transporte pueden variar (satélite vs. fibra, por ejemplo).\nPuedes utilizar los datos históricos de KPIs en SD-WAN Manager para construir una línea base y definir un SLA adecuado.\nLa definición de SLA se verá así:\nsla-class Custom-SLA loss 1 latency 250 jitter 100 BFD El protocolo Bidirectional Forwarding Detection (BFD) se usa para detectar rápidamente fallas entre dos dispositivos de red. En SD-WAN, también se usa para medir la pérdida, la latencia y el jitter. Los parámetros que usamos para configurar BFD dictarán qué tan rápido SD-WAN detectará y reaccionará a los problemas de red.\nHello Interval Este intervalo representa la frecuencia con la que se enviará un paquete de BFD. Está configurado por color en milisegundos; El valor predeterminado por defecto es 1000 ms. Este paquete viajará hasta el WAN Edge del otro extremo y regresará. De esta manera, se medirán los KPIs para cada paquete.\nsdwan interface GigabitEthernetX tunnel-interface color mpls hello-interval 1000 \u0026lt;\u0026lt;\u0026lt; Cada modelo de router tiene una capacidad definida de túneles (cantidad de túneles que puede formar). Reducir el hello interval por debajo de 1 segundo disminuye la capacidad de túneles.\nTen esto en cuenta para evitar posibles problemas por exceder la capacidad del hardware.\nApp route poll interval Digamos que tenemos un intervalo de votación de 4000 ms. Cada 4 segundos se construye un nuevo cubo, este cubo tendrá su propio índice. ** El intervalo de encuesta predeterminado ** es de 600,000 ms (10 minutos).\nA medida que el WAN Edge sigue enviando paquetes, el poll interval es el temporizador que ayuda a organizarlos en buckets. Estos buckets se utilizan para calcular las estadísticas del túnel.\nEl poll interval se configura a nivel de dispositivo (per box basis), lo que significa que se aplica de la misma manera para todos los colores.\nPor ejemplo, si el poll interval es de 4000 ms, cada 4 segundos se crea un nuevo bucket, y cada uno tendrá su propio índice.\nEl valor por defecto del poll interval es 600,000 ms (10 minutos).\nPara configurar el poll interval\nbfd app-route poll-interval 60000 La pérdida promedio, la latencia y el jitter, se calcularán para cada poll interval. Podemos verificar esto directamente en SD-WAN Manager -\u0026gt; Monitor -\u0026gt; Real Time -\u0026gt; App Route Statistics\nMultiplicador de ruta de la aplicación Para configurar el multiplicador\nbfd app-route multiplier 3 El multiplicador indica la cantidad de buckets que se utilizarán para calcular las estadísticas del túnel, lo que influirá en la decisión de redirigir el tráfico cuando las condiciones de la red empeoren.\nPara esta ilustración, se usa un multiplicador de 3.\nPor defecto, el multiplicador está configurado en 6.\nObserva que cada bucket contiene 4 paquetes.\nhello interval (s) x Poll interval (s)\nEn el mundo real, 4 paquetes serían ** demasiado bajo **. Si tomamos todos los valores predeterminados, terminaríamos con un cubo de 600 paquetes. Consulte la [Guía de implementación de AAR] (https://www.cisco.com/c/en/us/td/docs/solutions/cvd/sdwan/cisco-sdwan-application-ware-routing-deploy-guide.html) para obtener más detalles y opciones.\nDespués de llenar todos los buckets, se calcularán las estadísticas del túnel.\nPodemos visualizar los buckets y los cálculos de la media. Fíjate que los valores son los mismos para todos los buckets. No te confundas con las columnas de avg loss, latency y jitter que se mostraron antes.\nEste mecanismo actúa como una ventana deslizante que descartará el bucket más antiguo para hacer espacio al nuevo, recalculando las estadísticas del túnel cada poll interval.\nConfiguración de la política AAR Ahora que tenemos una mejor comprensión sobre SLA y BFD, podemos crear las reglas que gobernarán el comportamiento de nuestra política AAR. Así es como se verá en SD-WAN Manager.\nEsta es probablemente la forma más simple que podemos configurar. El tráfico de Google Apps será matcheado y se utilizarán los transportes que coincidan con nuestro Custom-SLA de manera indiferente.\nEn otras palabras, si tenemos 3 transportes diferentes y todos cumplen con el SLA, el tráfico se balanceará entre ellos.\n¿Qué pasa si queremos que el tráfico prefiera uno de los transportes? Bueno, podemos especificar un Prefered Color como se muestra a continuación:\nEn esta secuencia, las aplicaciones de voz se emparejan, y el SLA de los transportes debe coincidir con el de Bussiness-Critical. Se dará preferencia a MPLS si cumple con el SLA. La acción cuando no se cumple el SLA se configura en Load Balance entre los colores disponibles.\nA primera vista, esto parece muy simple, pero hay algunos detalles que debemos conocer si queremos entender completamente cómo se comportará el tráfico bajo diferentes circunstancias.\nTe invito a leer mi próximo post donde exploraremos algunos escenarios para tener un mejor entendimiento de esta tecnología. ¡Nos vemos allá!\n","permalink":"http://localhost:1313/simplificando-aar-1-3-las-bases/","summary":"Aprende cómo AAR puede ayudarte a mejorar la experiencia del usuario y aplicación con Cisco SD-WAN","title":"Simplificando AAR: 1/3 Las bases"},{"content":"Motivación: El escenario clásico de crisis Imagina comenzar el día en el equipo de redes, solo para ser bombardeado con quejas sobre la principal aplicación interna. Empiezas a investigar. ¿Dónde se encuentra el problema? ¿Está aislado o afectando múltiples lugares? ¿Cuándo comenzó el problema? ¿Cuál es el impacto?\nA continuación, intentas conectar con alguien que te ayude a verificar los conceptos básicos. DHCP y DNS funcionan. Gateway es accesible. ¡La conectividad a otros objetivos en el mismo DC es intermitente! Está empezando a ser raro \u0026hellip;\nEn este punto, cada minuto cuenta y un proceso de solución de problemas adecuado debe implementarse para verificar todos los dispositivos involucrados y aislar la raíz del problema. Comienza a tomar capturas de paquetes y trazas en diferentes puntos de la red, verificas los contadores, las sesiones BFD e IPSEC, buscas inconsistencias en la tabla OMP y enrutamiento, verificas largas configuraciones de políticas y parámetros de puerto, una cosa a la vez. Dos horas más tarde (¡con suerte!) tú y tu equipo finalmente llegan a la causa raíz\u0026hellip;\n¿Qué hizo Cisco al respecto? Teniendo en cuenta el nivel de complejidad y los esfuerzos necesarios para resolver los problemas de la red, Cisco creó - Network Wide Path Insights (NWPI) - para facilitar la solución de problemas de nuestra WAN. NWPI se introdujo por primera vez la versión 20.4 y con cada lanzamiento siguió mejorando. En la versión 20.9 hay varias mejoras importantes que lo ayudarán a determinar rápidamente lo que está sucediendo. ¿Quieres verlo en acción? ¡Vamos!\n** Topología ** Usaremos este escenario para ejecutar nuestro traza NWPI. No existe una política centralizada, como resultado, tenemos un full mesh y el tráfico podría fluir en cualquiera de los túneles disponibles.\n** Comprensión de NWPI ** En VManage, navegue a la sección Tools para encontrar esta característica. Para comenzar a usarlo, la información mínima que necesita es:\nDonde se genera el tráfico (Site`` ID) segmento de la red (VPN) Device se determina automáticamente. Puedes refinar aún más los filtros para capturar exactamente lo que está buscando.\n20.12.2 NWPI\nUna vez que los filtros estén en su lugar, comienza la traza y observa la magia.\nInsight - Vista básica Veamos los resultados de una pequeña transferencia SCP entre sitios 10 y 20. Esta es la primera información que veremos.\nDe lo anterior, podemos determinar:\n** Dirección de flujo ** - Tráfico que fluye del sitio 10 a 20 ** Equipos edges tocando el tráfico ** - BR10-1 y BR20-2 ** Información de flujo ** - src/dst ips, puertos, protocolo, aplicación, etc. ** Colores involucrados ** - MPLS -\u0026gt; Biz- Internet ** KPIs SD-WAN específicos del flujo ** - Pérdida de paquetes, latencia y jitter ** Porcentaje de pérdida de paquetes ** - en los dispositivos WAN y en los dispositivos Hagamos clic en readout para obtener más información\nLeer Una nueva información está disponible para nosotros:\n** Entrada coincidente en la tabla de enrutamiento ** - 172.10.20.0/24 Provenía de OMP y sus respectivas métricas. ** Candidato y ruta elegida ** - Rutas disponibles que se muestran y elegidas una resaltada en verde. ** Interfaces físicas involucradas ** - tanto para el servicio como para el transporte ** Razón para elegir esta ruta ** - Enrutamiento, sin embargo, tenga en cuenta que las políticas pueden anular la tabla de enrutamiento. Si nos detenemos aquí, ya tenemos mucha información muy útil para comprender el flujo del tráfico, pero ¿qué pasa si necesitamos profundizar? Bueno, ahora exploremos las vistas Advanced\nVistas avanzadas Si conoce [DataPath Packet Trace] (https://www.cisco.com/c/en/us/support/docs/content-networking/adaptive-session-redundancy-asr/117858-technote-asr-00.html#toc-hid-180344474), esta información será familiar. Esencialmente, nos dirá todas las funcionalidades que ejecuta el dispositivo a medida que se procesa el paquete. Algunos ejemplos podrían ser ACL, políticas, reglas FW, DPI, Netflow y mucho más. Hay casos en los que necesitamos determinar si o por qué el dispositivo está dejando caer paquetes, ¡este es el lugar para verificar!\nEn resumen aquí está la información adicional que podemos obtener:\nFuncionalidades - Algunas de ellas dependerán de la configuración, otras siempre estarán allí en un entorno SD-WAN. Drops - Si una característica está dejando caer el tráfico, tiene la información para saber exactamente por qué. Detalles de bajo nivel sobre las funcionalidades - La mayoría de las veces no tendrá que lidiar con esto, pero puede ser útil cuando se comunica con el soporte técnico. Hay mucho más que hacer con esta herramienta, pero creo que esto es suficiente como introducción. Sin embargo, antes de llegar a la conclusión, me gustaría mencionar algunos de los casos de uso en los que esta herramiento es extremadamente útil.\nMal rendimiento de la aplicación Validación de políticas Aislamiento del problema Validación/solución de problemas DIA y SaaS (sí, también puede brindar información sobre el tráfico destinado a Internet) ¿En qué otros escenarios podrías pensar?\nConclusión NWPI es un gran ejemplo del esfuerzo de Cisco para crear una herramienta que puede ayudar a solucionar problemas más rápido y de manera simple y eficiente. Consulte esta guía para saber más sobre las características introducidas y más.\nEn mi experiencia, NWPI no se usa lo suficiente principalmente porque todavía es desconocido para muchos. Te animo a que lo pruebes y eventualmente lo incorpores a su conjunto de herramientas de solución de problemas, estoy seguro de que encontrará algún beneficio.\n","permalink":"http://localhost:1313/introduccion-network-wide-path-insights/","summary":"Aprende a usar la herramienta de troubleshooting más avanzada para tu red Cisco SD-WAN.","title":"Cisco SD-WAN Network Wide Path Insights (NWPI)"},{"content":" ¡Hola! Soy Alex y me encanta compartir mi conocimiento sobre redes y tecnología. He estado en el campo de networking durante los últimos años. Actualmente, aporto mi experiencia en Cisco, donde comencé en el equipo de soporte TAC de R\u0026S. Después de un par de años, hice la transición al equipo de soporte TAC de SD-WAN. Ahora soy Customer Success Specialist para tecnologías como DNA Center y SD-WAN. Obtuve mi CCIE Enterprise en 2022. También me interesa la automatización, la inteligencia artificial y la tecnología en general. Gracias por estar aquí. Espero que encuentres mi blog útil y entretenido. ¡Conectemos! 👇 ","permalink":"http://localhost:1313/es/sobre-mi/","summary":"\u003cdiv style=\"display: flex; align-items: center;\"\u003e\n    \u003cdiv style=\"flex: 1; padding-right: 20px;font-size: 17px;\"\u003e\n        \u003cdiv style=\"line-height: 1; margin-bottom: 1em; \"\u003e\u003c/div\u003e\n      \n\n¡Hola! Soy Alex y me encanta compartir mi conocimiento sobre redes y tecnología. He estado en el campo de networking durante los últimos años.\n\u003cbr\u003e\u003cbr\u003e\nActualmente, aporto mi experiencia en Cisco, donde comencé en el equipo de soporte TAC de R\u0026S. Después de un par de años, hice la transición al equipo de soporte TAC de SD-WAN.\n\u003cbr\u003e\u003cbr\u003e\nAhora soy Customer Success Specialist para tecnologías como DNA Center y SD-WAN. Obtuve mi CCIE Enterprise en 2022. También me interesa la automatización, la inteligencia artificial y la tecnología en general.\n\u003cbr\u003e\u003cbr\u003e\nGracias por estar aquí. Espero que encuentres mi blog útil y entretenido. ¡Conectemos! 👇\n\u003cbr\u003e\u003cbr\u003e\n\u003cdiv style=\"display: flex; gap: 30px; align-items: center;\"\u003e\n\n  \u003ca href=\"https://www.linkedin.com/in/alexruizs/\" target=\"_blank\" style=\"margin-right: 1px;\"\u003e\n\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" style=\"width:30px; height:30px; fill: var(--primary);\"\u003e\u003cpath d=\"M22.23 0H1.77C.8 0 0 .77 0 1.72v20.56C0 23.23.8 24 1.77 24h20.46c.98 0 1.77-.77 1.77-1.72V1.72C24 .77 23.2 0 22.23 0zM7.27 20.1H3.65V9.24h3.62V20.1zM5.47 7.76h-.03c-1.22 0-2-.83-2-1.87 0-1.06.8-1.87 2.05-1.87 1.24 0 2 .8 2.02 1.87 0 1.04-.78 1.87-2.05 1.87zM20.34 20.1h-3.63v-5.8c0-1.45-.52-2.45-1.83-2.45-1 0-1.6.67-1.87 1.32-.1.23-.11.55-.11.88v6.05H9.28s.05-9.82 0-10.84h3.63v1.54a3.6 3.6 0 0 1 3.26-1.8c2.39 0 4.18 1.56 4.18 4.89v6.21z\"/\u003e\u003c/svg\u003e\n  \u003c/a\u003e\n\n  \u003c!-- GitHub Icon --\u003e\n  \u003ca href=\"https://github.com/aruiz-p\" target=\"_blank\" style=\"margin-right: 1px;\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" style=\"width: 30px; height: 30px; fill: var(--primary);\"\u003e\u003cpath d=\"M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577v-2.234c-3.338.724-4.033-1.415-4.033-1.415-.546-1.385-1.333-1.754-1.333-1.754-1.089-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.775.418-1.305.762-1.605-2.665-.3-5.466-1.333-5.466-5.93 0-1.31.465-2.381 1.235-3.221-.123-.303-.535-1.523.117-3.176 0 0 1.008-.322 3.3 1.23.957-.266 1.983-.398 3.003-.404 1.02.006 2.047.138 3.006.404 2.29-1.552 3.296-1.23 3.296-1.23.653 1.653.241 2.873.118 3.176.77.84 1.231 1.911 1.231 3.221 0 4.61-2.805 5.625-5.475 5.92.429.372.824 1.104.824 2.222v3.293c0 .322.218.694.825.576C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12\"/\u003e\u003c/svg\u003e  \n  \u003c/a\u003e\n\n  \u003c!-- Gmail Icon --\u003e\n\u003ca href=\"mailto:netwithalex@gmail.com\" target=\"_blank\" style=\"margin-right: 1px;\"\u003e\n  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" style=\"width: 30px; height: 30px;\"\u003e\n    \u003c!-- Background --\u003e\n    \u003crect width=\"24\" height=\"24\" fill=\"var(--theme)\" /\u003e\n    \u003c!-- Envelope Outline --\u003e\n    \u003cpath d=\"M12 12.713L.015 5.328V19.2A2.8 2.8 0 002.8 22h18.4a2.8 2.8 0 002.8-2.8V5.328L12 12.713zm11.985-7.385v-.2a2.8 2.8 0 00-2.8-2.8H2.8A2.8 2.8 0 000 5.328l12 7.679 12-7.679z\" fill=\"none\" stroke=\"var(--primary)\" stroke-width=\"2.5\" /\u003e\n  \u003c/svg\u003e\n\u003c/a\u003e\n\u003c/div\u003e\n\n\n    \u003c/div\u003e\n    \u003cdiv style=\"flex: 1;\"\u003e\n      \u003cimg src=\"/wp-content/uploads/2024/01/IMG_8522-e1704915321848.jpeg\" alt=\"Example Image\" style=\"max-width: 100%; height: auto;border: 5px solid transparent;border-radius: 20px;\"\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e","title":"Sobre mi."}]